[{"path":"https://docs.ropensci.org/ohun/CONTRIBUTING.html","id":null,"dir":"","previous_headings":"","what":"Contributing","title":"Contributing","text":"First , thanks taking time contribute! types contributions encouraged valued. See Table Contents different ways help details project handles . Please make sure read relevant section making contribution. make lot easier us maintainers smooth experience involved. community looks forward contributions. like project, just don’t time contribute, ’s fine. easy ways support project show appreciation, also happy : - Star project - Tweet - Refer project project’s readme - Mention project local meetups tell friends/colleagues","code":""},{"path":"https://docs.ropensci.org/ohun/CONTRIBUTING.html","id":"table-of-contents","dir":"","previous_headings":"","what":"Table of Contents","title":"Contributing","text":"Code Conduct Question Want Contribute Reporting Bugs Suggesting Enhancements","code":""},{"path":"https://docs.ropensci.org/ohun/CONTRIBUTING.html","id":"code-of-conduct","dir":"","previous_headings":"","what":"Code of Conduct","title":"Contributing","text":"Please note ohun released Contributor Code Conduct. contributing project agree abide terms. See rOpenSci contributing guide details.","code":""},{"path":"https://docs.ropensci.org/ohun/CONTRIBUTING.html","id":"i-have-a-question","dir":"","previous_headings":"","what":"I Have a Question","title":"Contributing","text":"want ask question, assume read available Documentation. ask question, best search existing Issues might help . case found suitable issue still need clarification, can write question issue. also advisable search internet answers first. still feel need ask question need clarification, recommend following: Open https://github.com/ropensci/ohun/issues/. Provide much context can ’re running . Provide project platform versions (nodejs, npm, etc), depending seems relevant. take care issue soon possible.","code":""},{"path":"https://docs.ropensci.org/ohun/CONTRIBUTING.html","id":"i-want-to-contribute","dir":"","previous_headings":"","what":"I Want To Contribute","title":"Contributing","text":"contributing project, must agree authored 100% content, necessary rights content content contribute may provided project license.","code":""},{"path":[]},{"path":"https://docs.ropensci.org/ohun/CONTRIBUTING.html","id":"before-submitting-a-bug-report","dir":"","previous_headings":"I Want To Contribute > Reporting Bugs","what":"Before Submitting a Bug Report","title":"Contributing","text":"good bug report shouldn’t leave others needing chase information. Therefore, ask investigate carefully, collect information describe issue detail report. Please complete following steps advance help us fix potential bug fast possible. Make sure using latest version. Determine bug really bug error side e.g. using incompatible environment components/versions (Make sure read documentation. looking support, might want check section). see users experienced (potentially already solved) issue , check already bug report existing bug erro. Also make sure search internet (including Stack Overflow) see users outside GitHub community discussed issue. Collect information bug: Stack trace (Traceback) OS, Platform Version (Windows, Linux, macOS, x86, ARM) Version interpreter, compiler, SDK, runtime environment, package manager, depending seems relevant. Possibly input output Can reliably reproduce issue? can also reproduce older versions?","code":""},{"path":"https://docs.ropensci.org/ohun/CONTRIBUTING.html","id":"how-do-i-submit-a-good-bug-report","dir":"","previous_headings":"I Want To Contribute > Reporting Bugs","what":"How Do I Submit a Good Bug Report?","title":"Contributing","text":"must never report security related issues, vulnerabilities bugs including sensitive information issue tracker, elsewhere public. Instead sensitive bugs must sent email <>. use GitHub issues track bugs errors. run issue project: Open Issue. (Since can’t sure point whether bug , ask talk bug yet label issue.) Explain behavior expect actual behavior. Please provide much context possible describe reproduction steps someone else can follow recreate issue . usually includes code. good bug reports isolate problem create reduced test case. Provide information collected previous section. ’s filed: project team label issue accordingly. team member try reproduce issue provided steps. reproduction steps obvious way reproduce issue, team ask steps mark issue needs-repro. Bugs needs-repro tag addressed reproduced. team able reproduce issue, marked needs-fix, well possibly tags (critical), issue left implemented someone.","code":""},{"path":"https://docs.ropensci.org/ohun/CONTRIBUTING.html","id":"suggesting-enhancements","dir":"","previous_headings":"I Want To Contribute","what":"Suggesting Enhancements","title":"Contributing","text":"section guides submitting enhancement suggestion, including completely new features minor improvements existing functionality. Following guidelines help maintainers community understand suggestion find related suggestions.","code":""},{"path":"https://docs.ropensci.org/ohun/CONTRIBUTING.html","id":"before-submitting-an-enhancement","dir":"","previous_headings":"I Want To Contribute > Suggesting Enhancements","what":"Before Submitting an Enhancement","title":"Contributing","text":"Make sure using latest version. Read documentation carefully find functionality already covered, maybe individual configuration. Perform search see enhancement already suggested. , add comment existing issue instead opening new one. Find whether idea fits scope aims project. ’s make strong case convince project’s developers merits feature. Keep mind want features useful majority users just small subset. ’re just targeting minority users, consider writing add-/plugin library.","code":""},{"path":"https://docs.ropensci.org/ohun/CONTRIBUTING.html","id":"how-do-i-submit-a-good-enhancement-suggestion","dir":"","previous_headings":"I Want To Contribute > Suggesting Enhancements","what":"How Do I Submit a Good Enhancement Suggestion?","title":"Contributing","text":"Enhancement suggestions tracked GitHub issues. Use clear descriptive title issue identify suggestion. Provide step--step description suggested enhancement many details possible. Describe current behavior explain behavior expected see instead . point can also tell alternatives work . may want include screenshots animated GIFs help demonstrate steps point part suggestion related . can use tool record GIFs macOS Windows, tool tool Linux. Explain enhancement useful users. may also want point projects solved better serve inspiration.","code":""},{"path":"https://docs.ropensci.org/ohun/CONTRIBUTING.html","id":"attribution","dir":"","previous_headings":"","what":"Attribution","title":"Contributing","text":"guide based contributing.md. Make !","code":""},{"path":"https://docs.ropensci.org/ohun/articles/energy_based_detection.html","id":"how-it-works","dir":"Articles","previous_headings":"","what":"How it works","title":"Energy-based detection","text":"function ernergy_detector() performs type detection. can understand use ernergy_detector() using simulated sound events. using function simulate_songs() warbleR. example simulate recording 10 sounds two different frequency ranges durations: function call saves ‘.wav’ sound file temporary directory (tempdir()) also returns wave object R environment. outputs used run energy-based detection creating plots, respectively. spectrogram amplitude envelope simulated recording look like:  Note amplitude envelope shows high signal--noise ratio sound events, ideal energy-based detection. can conducted using ernergy_detector() follows:  output selection table: Now make use additional arguments filter specific sound events based structural features. instance can use argument minimum.duration provide time treshold (ms) exclude short sound events keep longest sound events:  can use argument max.duration (also ms) exclude long sound events keep short ones:  can also focus detection specific frequency ranges using argument bp (bandpass). setting bp = c(5, 8) sound events found within frequency range (5-8 kHz) detected, excludes sound events 5 kHz:  logic can applied detect sound events found 5 kHz. just need set upper bound band pass filter range higher frequency sound events (instance bp = (0, 5)):  Amplitude modulation (variation amplitude across sound event) can problematic detection based amplitude envelopes. can also simulate amplitude modulation using warbleR::simulate_songs():  sound events strong amplitude modulation can split detection:  two arguments can deal : holdtime smooth. hold.time allows merge split sound events found within given time range (ms). time range high enough merge things belonging sound event high merges different sound events. example hold.time 200 ms can trick (know gaps sound events ~0.5 s long):  smooth works merging amplitude envelope ‘hills’ split sound events . smooths envelopes applying sliding window averaging amplitude values. ’s given ms window size. smooth 350 ms can merged back split sound events example:  function additional arguments filtering detections (peak.amplitude) speeding analysis (thinning parallel).","code":"# install this package first if not installed # install.packages(\"Sim.DiffProc\")  #Creating vector for duration  durs <- rep(c(0.3, 1), 5)  set.seed(123) freqs <- sample(c(3, 6), 10, replace = TRUE)  #Creating simulated song set.seed(12) simulated_1 <-   warbleR::simulate_songs(     n = 10,     durs = durs,     freqs = freqs,     sig2 = 0.1,     gaps = 0.5,     harms = 1,     bgn = 0.1,     freq.range = 2,     path = tempdir(),     file.name = \"simulated_1\",     selec.table = TRUE,     shape = \"cos\",     fin = 0.3,     fout = 0.35,     samp.rate = 18   )$wave # plot spectrogram and envelope label_spectro(wave = simulated_1,               env = TRUE,               fastdisp = TRUE) # run detection detection <-   energy_detector(     files = \"simulated_1.wav\",     bp = c(2, 8),     threshold = 50,     smooth = 150,     path = tempdir()   )  [30mdetecting sound events (step 0 of 0): [39m # plot spectrogram and envelope label_spectro(   wave = simulated_1,   envelope = TRUE,   detection = detection,   threshold = 50 ) detection  [30mObject of class  [1m'selection_table' [22m [39m  [90m* The output of the following call: [39m  [90m [3menergy_detector(files = \"simulated_1.wav\", path = tempdir(),  [23m [39m [90m [3mbp = c(2, 8), smooth = 150, threshold = 50) [23m [39m  [90m [1m Contains: [22m  *  A selection table data frame with 10 rows and 5 columns: [39m  [90m|sound.files     | duration| selec|  start|    end| [39m  [90m|:---------------|--------:|-----:|------:|------:| [39m  [90m|simulated_1.wav |   0.2325|     1| 0.5314| 0.7639| [39m  [90m|simulated_1.wav |   0.7943|     2| 1.3955| 2.1898| [39m  [90m|simulated_1.wav |   0.2332|     3| 2.8308| 3.0640| [39m  [90m|simulated_1.wav |   0.7942|     4| 3.6957| 4.4899| [39m  [90m|simulated_1.wav |   0.2330|     5| 5.1310| 5.3640| [39m  [90m|simulated_1.wav |   0.7942|     6| 5.9957| 6.7899| [39m  [90m... and 4 more row(s) [39m  [90m * A data frame (check.results) with 10 rows generated by check_sels() (as an attribute) [39m  [90mcreated by warbleR 1.1.35 [39m # run detection detection <-   energy_detector(     files = \"simulated_1.wav\",     bp = c(1, 8),     threshold = 50,     min.duration = 500,     smooth = 150,     path = tempdir()   )  # plot spectrogram label_spectro(wave = simulated_1, detection = detection) # run detection detection <- energy_detector(files = \"simulated_1.wav\", bp = c(1, 8),  threshold = 50, smooth = 150, max.duration = 500, path = tempdir())  # plot spectrogram label_spectro(wave = simulated_1,  detection = detection) # Detecting  detection <- energy_detector(files = \"simulated_1.wav\", bp = c(5, 8), threshold = 50, smooth = 150, path = tempdir())  # plot spectrogram label_spectro(wave = simulated_1,  detection = detection) # Detect detection <-   energy_detector(     files = \"simulated_1.wav\",     bp = c(0, 5),     threshold = 50,     min.duration = 1,     smooth = 150,     path = tempdir()   )  # plot spectrogram label_spectro(wave = simulated_1,  detection = detection) #Creating simulated song set.seed(12)  #Creating vector for duration durs <- rep(c(0.3, 1), 5)  # and a frequency vector set.seed(123) freqs <- sample(c(3, 6), 10, replace = TRUE)   sim_2 <-   simulate_songs(     n = 10,     durs = durs,     freqs = freqs,     sig2 = 0.01,     gaps = 0.5,     harms = 1,     bgn = 0.1,     freq.range = 2,         path = tempdir(),     file.name = \"simulated_2\",     selec.table = TRUE,     shape = \"cos\",     fin = 0.3,     fout = 0.35,     samp.rate = 18,     am.amps = c(1, 2, 3, 2, 0.1, 2, 3, 3, 2, 1)   )  # extract wave object and selection table simulated_2 <- sim_2$wave sim2_sel_table <- sim_2$selec.table  # plot spectrogram label_spectro(wave = simulated_2, envelope = TRUE) # detect sounds detection <- energy_detector(files = \"simulated_2.wav\", threshold = 50, path = tempdir())  # plot spectrogram label_spectro(wave = simulated_2, envelope = TRUE, threshold = 50, detection = detection) # detect sounds detection <-   energy_detector(     files = \"simulated_2.wav\",     threshold = 50,     min.duration = 1,     path = tempdir(),     hold.time = 200   )  # plot spectrogram label_spectro(   wave = simulated_2,   envelope = TRUE,   threshold = 50,   detection = detection ) # detect sounds detection <-   energy_detector(     files = \"simulated_2.wav\",     threshold = 50,     min.duration = 1,     path = tempdir(),     smooth = 350   )  # plot spectrogram label_spectro(   wave = simulated_2,   envelope = TRUE,   threshold = 50,   detection = detection,   smooth = 350 )"},{"path":"https://docs.ropensci.org/ohun/articles/energy_based_detection.html","id":"optimizing-energy-based-detection","dir":"Articles","previous_headings":"","what":"Optimizing energy-based detection","title":"Energy-based detection","text":"last example using smooth can used showcase tunning parameters can optimized. explained , need reference table contains time position target sound events. function optimize_energy_detector() can used finding optimal parameter values. must provide range parameter values evaluated: output contains combination parameters used iteration well corresponding diagnose indices. case combinations generate good detection (recall & precision = 1). However, routine highest smooth (last row) split sound events (‘split.positive’ column). also shows better overlap reference sound events (‘overlap’ closer 1). addition, two complementary functions optimizing energy-based detection routines: summarize_reference() merge_overlaps(). summarize_reference() allow user get sense time frequency characteristics reference table. information can used determine range tuning parameter values optimization. output function applied lbh_reference: Features related selection duration can used set ‘max.duration’ ‘min.duration’ values, frequency related features can inform banpass values, gap related features inform hold time values duty cycle can used evaluate performance. Peak amplitude can used keep sound events highest intensity, mostly useful routines subset target sound events present recordings needed. merge_overlaps() finds time-overlapping selections reference tables collapses single selection. Overlapping selections likely appear single amplitude ‘hill’ thus detected single sound event. merge_overlaps() can useful prepare references format representing realistic expectation pefect energy detection routine look like. Please cite ohun like : Araya-Salas, M. (2021), ohun: diagnosing optimizing automated sound event detection. R package version 0.1.0.","code":"optim_detection <-   optimize_energy_detector(     reference = sim2_sel_table,     files = \"simulated_2.wav\",     threshold = 50,     min.duration = 1,     path = tempdir(),     smooth = c(100, 250, 350)   ) 3 combinations will be evaluated: optim_detection[, c(1, 2:5, 7:12, 17:18)] threshold peak.amplitude smooth hold.time min.duration thinning detections 1        50              0    100         0            1        1         20 2        50              0    250         0            1        1         15 3        50              0    350         0            1        1         10   true.positives false.positives false.negatives splits   overlap 1              0              20              10      0        NA 2              5              10               5      0 0.5023727 3             10               0               0      0 0.7224533   proportional.duration.true.positives 1                                   NA 2                            0.5023727 3                            0.7843797 summarize_reference(reference = lbh_reference, path = tempdir()) min   mean    max sel.duration   117.96 142.60 163.73 gap.duration   322.16 396.43 514.08 annotations      9.00   9.50  10.00 duty.cycle       0.24   0.27   0.31 peak.amplitude  73.76  81.58  88.03 bottom.freq      1.81   2.11   2.37 top.freq         8.49   8.82   9.53"},{"path":"https://docs.ropensci.org/ohun/articles/energy_based_detection.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Energy-based detection","text":"Araya-Salas, M., Smith-Vidaurre, G., Chaverri, G., Brenes, J. C., Chirino, F., Elizondo-Calvo, J., & Rico-Guevara, . (2023). ohun: R package diagnosing optimizing automatic sound event detection. Methods Ecology Evolution, 14, 2259–2271. https://doi.org/10.1111/2041-210X.14170 Araya-Salas M, Smith-Vidaurre G (2017) warbleR: R package streamline analysis animal acoustic signals. Methods Ecology Evolution, 8:184-191. Knight, E.C., Hannah, K.C., Foley, G.J., Scott, C.D., Brigham, R.M. & Bayne, E. (2017). Recommendations acoustic recognizer performance assessment application five common automated signal recognition programs. Avian Conservation Ecology, Macmillan, N. ., & Creelman, C.D. (2004). Detection theory: user’s guide. Psychology press. Session information","code":"R version 4.5.1 (2025-06-13) Platform: aarch64-apple-darwin20 Running under: macOS Sonoma 14.7.6  Matrix products: default BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib  LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1  locale: [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8  time zone: UTC tzcode source: internal  attached base packages: [1] stats     graphics  grDevices utils     datasets  methods   base       other attached packages: [1] warbleR_1.1.35     NatureSounds_1.0.5 knitr_1.50         seewave_2.2.3      [5] tuneR_1.4.7        ohun_1.0.3          loaded via a namespace (and not attached):  [1] gtable_0.3.6       rjson_0.2.23       xfun_0.52          bslib_0.9.0         [5] ggplot2_3.5.2      vctrs_0.6.5        tools_4.5.1        bitops_1.0-9        [9] curl_6.4.0         parallel_4.5.1     tibble_3.3.0       proxy_0.4-27       [13] pkgconfig_2.0.3    KernSmooth_2.23-26 checkmate_2.3.2    RColorBrewer_1.1-3 [17] desc_1.4.3         lifecycle_1.0.4    compiler_4.5.1     farver_2.1.2       [21] textshaping_1.0.1  brio_1.1.5         htmltools_0.5.8.1  class_7.3-23       [25] sass_0.4.10        RCurl_1.98-1.17    yaml_2.3.10        pkgdown_2.1.3      [29] pillar_1.11.0      jquerylib_0.1.4    MASS_7.3-65        classInt_0.4-11    [33] cachem_1.1.0       viridis_0.6.5      Deriv_4.2.0        digest_0.6.37      [37] sf_1.0-21          fastmap_1.2.0      grid_4.5.1         cli_3.6.5          [41] magrittr_2.0.3     e1071_1.7-16       scales_1.4.0       backports_1.5.0    [45] rmarkdown_2.29     httr_1.4.7         Sim.DiffProc_4.9   signal_1.8-1       [49] igraph_2.1.4       gridExtra_2.3      ragg_1.4.0         pbapply_1.7-4      [53] evaluate_1.0.4     dtw_1.23-1         fftw_1.0-9         testthat_3.2.3     [57] viridisLite_0.4.2  rlang_1.1.6        Rcpp_1.1.0         glue_1.8.0         [61] DBI_1.2.3          jsonlite_2.0.0     R6_2.6.1           systemfonts_1.2.3  [65] fs_1.6.6           units_0.8-7"},{"path":"https://docs.ropensci.org/ohun/articles/intro_to_ohun.html","id":"automatic-sound-event-detection","dir":"Articles","previous_headings":"","what":"Automatic sound event detection","title":"Optimizing sound event detection","text":"Finding position sound events sound file challenging task. ohun offers two methods automated sound event detection: template-based energy-based detection. methods better suited highly stereotyped good signal--noise ratio (SNR) sounds, respectively. target sound events don’t fit requirements, elaborated methods (.e. machine learning approaches) warranted: Diagram depicting target sound event features can used tell adequate sound event detection approach. Steps ‘ohun’ can helpful shown color. (SNR = signal--noise ratio) Also note presence sounds overlapping target sound events time frequency can strongly affect detection performance two methods ohun. Still, detection run using software can optimized tools provided ohun.","code":""},{"path":"https://docs.ropensci.org/ohun/articles/intro_to_ohun.html","id":"signal-detection-theory-applied-to-bioacoustics","dir":"Articles","previous_headings":"","what":"Signal detection theory applied to bioacoustics","title":"Optimizing sound event detection","text":"Broadly speaking, signal detection theory deals process recovering signals (.e. target signals) background noise (necessarily acoustic noise) ’s widely used optimizing decision making process presence uncertainty. detection routine, detected ‘items’ can classified 4 classes: True positives (TPs): signals correctly identified ‘signal’ False positives (FPs): background noise incorrectly identified ‘signal’ False negatives (FNs): signals incorrectly identified ‘background noise’ True negatives (TNs): background noise correctly identified ‘background noise’ Several additional indices derived indices used evaluate performance detection routine. three useful indices context sound event detection included ohun: Recall: correct detections relative total references (.k.. true positive rate sensitivity; TPs / (TPs + FNs)) Precision: correct detections relative total detections (TPs / (TPs + FPs)). F score: combines recall precision harmonic mean two, provides single value evaluating performance (.k.. F-measure Dice similarity coefficient). (Metrics make use ‘true negatives’ easily applied context sound event detection noise always partitioned discrete units) perfect detection false positives false negatives, result recall precision equal 1. However, perfect detection always reached compromise detecting target signals plus noise (recall = 1 & precision < 1) detecting target signals (recall < 1 & precision = 1) warranted. right balance two extremes given relative costs missing signals mistaking noise signals. Hence, indices provide useful framework diagnosing optimizing performance detection routine. package ohun provides set tools evaluate performance sound event detection based indices described . accomplish , result detection routine compared reference table containing time position target sound events sound files. package comes example reference table containing annotations long-billed hermit hummingbird songs two sound files (also supplied example data: ‘lbh1’ ‘lbh2’), can used illustrate detection performance evaluation. example data can explored follows: ‘selection table’, object class provided package warbleR (see selection_table() details). Selection tables basically data frames contained information double-checked (using warbleR’s check_sels()). behave pretty much data frames can easily converted data frames: ohun functions work kind data can take selection tables data frames. Spectrograms highlighted sound events selection table can plotted function label_spectro() (function plots one wave object time, really useful long files):   function diagnose_detection() evaluates performance detection routine comparing reference table. instance, perfect detection given comparing lbh_reference : work mostly single sound file convenience functions can work several sound files time. files found single working directory. Although example bit silly, shows basic diagnostic indices, include basic detection theory indices (‘true.positives’, ‘false.positives’, ‘false.negatives’, ‘recall’ ‘precision’) mentioned . can play around reference table see indices can used spot imperfect detection routines (hopefully improve !). instance, can remove sound events see reflected diagnostics. Getting rid rows ‘detection’, simulating detection false negatives, affect recall precision:  additional sound events reference opposite, reducing precision recall. can simply switching tables:  function offers three additional diagnose metrics: Splits: detections share overlapping reference sounds detections Merges: detections overlap two reference sounds Proportional overlap true positives: ratio time overlap true positives corresponding sound event reference table perfect detection routine split merged positives 0 proportional overlap 1. can shift start sound events bit reflect detection mismatch reference table regarding time location sound events:  addition, following diagnostics related duration sound events can also returned setting time.diagnostics = TRUE. tweak reference detection data just false positives false negatives: additional metrics can used filter undesired sound events based duration (instance energy-based detection energy_detector(), explained ). Diagnostics can also detailed sound file: diagnostics can summarized (default diagnose_detection() output) function summarize_diagnostic(): match reference detection annotations can also visually inspected using function plot_detection():  function flexible label_spectro() can easily plot annotations several sound files (include long sound files):","code":"# load example data data(\"lbh1\", \"lbh2\", \"lbh_reference\")  lbh_reference  [30mObject of class  [1m'selection_table' [22m [39m  [90m* The output of the following call: [39m  [90m [3mwarbleR::selection_table(X = lbh_reference) [23m [39m  [90m [1m Contains: [22m  *  A selection table data frame with 19 rows and 6 columns: [39m  [90m|sound.files | selec|  start|    end| bottom.freq| top.freq| [39m  [90m|:-----------|-----:|------:|------:|-----------:|--------:| [39m  [90m|lbh2.wav    |     1| 0.1092| 0.2482|      2.2954|   8.9382| [39m  [90m|lbh2.wav    |     2| 0.6549| 0.7887|      2.2954|   9.0426| [39m  [90m|lbh2.wav    |     3| 1.2658| 1.3856|      2.2606|   9.0774| [39m  [90m|lbh2.wav    |     4| 1.8697| 2.0053|      2.1911|   8.9035| [39m  [90m|lbh2.wav    |     5| 2.4418| 2.5809|      2.1563|   8.6600| [39m  [90m|lbh2.wav    |     6| 3.0368| 3.1689|      2.2259|   8.9382| [39m  [90m... and 13 more row(s) [39m  [90m * A data frame (check.results) with 19 rows generated by check_sels() (as an attribute) [39m  [90mcreated by warbleR 1.1.27 [39m # convert to data frame as.data.frame(lbh_reference) sound.files selec    start       end bottom.freq top.freq 1     lbh2.wav     1 0.109161 0.2482449      2.2954   8.9382 2     lbh2.wav     2 0.654921 0.7887232      2.2954   9.0426 3     lbh2.wav     3 1.265850 1.3855678      2.2606   9.0774 4     lbh2.wav     4 1.869705 2.0052678      2.1911   8.9035 5     lbh2.wav     5 2.441769 2.5808529      2.1563   8.6600 6     lbh2.wav     6 3.036825 3.1688667      2.2259   8.9382 7     lbh2.wav     7 3.628617 3.7465742      2.3302   8.6252 8     lbh2.wav     8 4.153288 4.2818085      2.2954   8.4861 9     lbh2.wav     9 4.723673 4.8609963      2.3650   8.6948 10    lbh1.wav    10 0.088118 0.2360047      1.9824   8.4861 11    lbh1.wav    11 0.572290 0.7201767      2.0520   9.5295 12    lbh1.wav    12 1.056417 1.1972614      2.0868   8.4861 13    lbh1.wav    13 1.711338 1.8680274      1.9824   8.5905 14    lbh1.wav    14 2.190249 2.3416568      2.0520   8.5209 15    lbh1.wav    15 2.697143 2.8538324      1.9824   9.2513 16    lbh1.wav    16 3.181315 3.3344833      1.9129   8.4861 17    lbh1.wav    17 3.663719 3.8133662      1.8781   8.6948 18    lbh1.wav    18 4.140816 4.3045477      1.8433   9.2165 19    lbh1.wav    19 4.626712 4.7851620      1.8085   8.9035 # save sound file tuneR::writeWave(lbh1, file.path(tempdir(), \"lbh1.wav\"))  # save sound file tuneR::writeWave(lbh2, file.path(tempdir(), \"lbh2.wav\"))  # print spectrogram label_spectro(wave = lbh1, reference = lbh_reference[lbh_reference$sound.files == \"lbh1.wav\", ], hop.size = 10, ovlp = 50, flim = c(1, 10)) # print spectrogram label_spectro(wave = lbh2, reference = lbh_reference[lbh_reference$sound.files == \"lbh2.wav\", ], hop.size = 10, ovlp = 50, flim = c(1, 10)) lbh1_reference <-   lbh_reference[lbh_reference$sound.files == \"lbh1.wav\",]  # diagnose diagnose_detection(reference = lbh1_reference, detection = lbh1_reference)[, c(1:3, 7:9)]  [30mlabeling detections (step 0 of 0): [39m detections true.positives false.positives overlap recall precision 1         10             10               0       1      1         1 # create new table lbh1_detection <- lbh1_reference[3:9,]  # print spectrogram label_spectro(   wave = lbh1,   reference = lbh1_reference,   detection = lbh1_detection,   hop.size = 10,   ovlp = 50,   flim = c(1, 10) ) # diagnose diagnose_detection(reference = lbh1_reference, detection = lbh1_detection)[, c(1:3, 7:9)] detections true.positives false.positives overlap recall precision 1          7              7               0       1    0.7         1 # print spectrogram label_spectro(   wave = lbh1,   detection = lbh1_reference,   reference = lbh1_detection,   hop.size = 10,   ovlp = 50,   flim = c(1, 10) ) # diagnose diagnose_detection(reference = lbh1_detection, detection = lbh1_reference)[, c(1:3, 7:9)] detections true.positives false.positives overlap recall precision 1         10              7               3       1      1       0.7 # create new table lbh1_detection <- lbh1_reference  # add 'noise' to start set.seed(18) lbh1_detection$start <-   lbh1_detection$start + rnorm(nrow(lbh1_detection), mean = 0, sd = 0.1)  ## print spectrogram label_spectro(   wave = lbh1,   reference = lbh1_reference,   detection = lbh1_detection,   hop.size = 10,   ovlp = 50,   flim = c(1, 10) ) # diagnose diagnose_detection(reference = lbh1_reference, detection = lbh1_detection) detections true.positives false.positives false.negatives splits merges   overlap 1         10              5               5               5      0      0 0.7849767   recall precision f.score 1    0.5       0.5     0.5 # diagnose with time diagnostics diagnose_detection(reference = lbh1_reference[-1, ], detection = lbh1_detection[-10, ], time.diagnostics = TRUE) detections true.positives false.positives false.negatives splits merges 1          9              5               4               4      0      0   mean.duration.true.positives mean.duration.false.positives 1                          187                            58   mean.duration.false.negatives   overlap proportional.duration.true.positives    recall 1                           149 0.7849767                             1.194993 0.5555556   precision   f.score 1 0.5555556 0.5555556 # diagnose by sound file diagnostic <-   diagnose_detection(reference = lbh1_reference,                      detection = lbh1_detection,                      by.sound.file = TRUE)  diagnostic sound.files detections true.positives false.positives false.negatives splits merges 1    lbh1.wav         10              5               5               5      0      0     overlap recall precision f.score 1 0.7849767    0.5       0.5     0.5 # summarize summarize_diagnostic(diagnostic) detections true.positives false.positives false.negatives splits merges   overlap 1         10              5               5               5      0      0 0.7849767   recall precision f.score 1    0.5       0.5     0.5 # ggplot detection and reference plot_detection(reference = lbh1_reference, detection = lbh1_detection) # ggplot detection and reference plot_detection(reference = lbh_reference, detection = lbh_reference)"},{"path":"https://docs.ropensci.org/ohun/articles/intro_to_ohun.html","id":"improving-detection-speed","dir":"Articles","previous_headings":"","what":"Improving detection speed","title":"Optimizing sound event detection","text":"Detection routines can take long time working large amounts acoustic data (e.g. large sound files /many sound files). useful points keep mine trying make routine time-efficient: Always test procedures small data subsets template_detector() faster energy_detector() Parallelization (see parallel argument functions) can significantly speed-routines, works better Unix-based operating systems (linux mac OS) Sampling rate matters: detecting sound events low sampling rate files goes faster, avoid nyquist frequencies (sampling rate / 2) way higher highest frequency target sound events (sound files can downsampled using warbleR’s fix_sound_files()) Large sound files can make routine crash, use split_acoustic_data() split reference tables files shorter clips. Think using computer lots RAM memory computer cluster working large amounts data thinning argument (reduces size amplitude envelope) can also speed-energy_detector()","code":""},{"path":"https://docs.ropensci.org/ohun/articles/intro_to_ohun.html","id":"additional-tips","dir":"Articles","previous_headings":"","what":"Additional tips","title":"Optimizing sound event detection","text":"Use knowledge sound event structure determine initial range tuning parameters detection optimization routine people hard time figuring target sound event occurs recording, detection algorithms also hard time Several templates representing range variation sound event structure can used detect semi-stereotyped sound events Make sure reference tables contain target sound events target sound events. performance detection better reference . Avoid overlapping sound events several sound events single one (like multi-syllable vocalization) reference table running energy-based detector Low-precision can improved training classification model (e.g. random forest) tell sound events noise Please cite ohun like : Araya-Salas, M. (2021), ohun: diagnosing optimizing automated sound event detection. R package version 0.1.0.","code":""},{"path":"https://docs.ropensci.org/ohun/articles/intro_to_ohun.html","id":"references","dir":"Articles","previous_headings":"Additional tips","what":"References","title":"Optimizing sound event detection","text":"Araya-Salas, M. (2021), ohun: diagnosing optimizing automated sound event detection. R package version 0.1.0. Araya-Salas M, Smith-Vidaurre G (2017) warbleR: R package streamline analysis animal acoustic signals. Methods Ecology Evolution, 8:184-191. Khanna H., Gaunt S.L.L. & McCallum D.. (1997). Digital spectrographic cross-correlation: tests sensitivity. Bioacoustics 7(3): 209-234. Knight, E.C., Hannah, K.C., Foley, G.J., Scott, C.D., Brigham, R.M. & Bayne, E. (2017). Recommendations acoustic recognizer performance assessment application five common automated signal recognition programs. Avian Conservation Ecology, Macmillan, N. ., & Creelman, C.D. (2004). Detection theory: user’s guide. Psychology press. Session information","code":"R version 4.5.1 (2025-06-13) Platform: aarch64-apple-darwin20 Running under: macOS Sonoma 14.7.6  Matrix products: default BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib  LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1  locale: [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8  time zone: UTC tzcode source: internal  attached base packages: [1] stats     graphics  grDevices utils     datasets  methods   base       other attached packages: [1] ggplot2_3.5.2      warbleR_1.1.35     NatureSounds_1.0.5 knitr_1.50         [5] seewave_2.2.3      tuneR_1.4.7        ohun_1.0.3          loaded via a namespace (and not attached):  [1] gtable_0.3.6       rjson_0.2.23       xfun_0.52          bslib_0.9.0         [5] vctrs_0.6.5        tools_4.5.1        bitops_1.0-9       curl_6.4.0          [9] parallel_4.5.1     tibble_3.3.0       proxy_0.4-27       pkgconfig_2.0.3    [13] KernSmooth_2.23-26 checkmate_2.3.2    RColorBrewer_1.1-3 desc_1.4.3         [17] lifecycle_1.0.4    compiler_4.5.1     farver_2.1.2       textshaping_1.0.1  [21] brio_1.1.5         htmltools_0.5.8.1  class_7.3-23       sass_0.4.10        [25] RCurl_1.98-1.17    yaml_2.3.10        pkgdown_2.1.3      pillar_1.11.0      [29] jquerylib_0.1.4    MASS_7.3-65        classInt_0.4-11    cachem_1.1.0       [33] viridis_0.6.5      digest_0.6.37      sf_1.0-21          labeling_0.4.3     [37] fastmap_1.2.0      grid_4.5.1         cli_3.6.5          magrittr_2.0.3     [41] e1071_1.7-16       withr_3.0.2        scales_1.4.0       backports_1.5.0    [45] rmarkdown_2.29     httr_1.4.7         signal_1.8-1       igraph_2.1.4       [49] gridExtra_2.3      ragg_1.4.0         pbapply_1.7-4      evaluate_1.0.4     [53] dtw_1.23-1         fftw_1.0-9         testthat_3.2.3     viridisLite_0.4.2  [57] rlang_1.1.6        Rcpp_1.1.0         glue_1.8.0         DBI_1.2.3          [61] jsonlite_2.0.0     R6_2.6.1           systemfonts_1.2.3  fs_1.6.6           [65] units_0.8-7"},{"path":"https://docs.ropensci.org/ohun/articles/template_based_detection.html","id":"optimizing-template-based-detection","dir":"Articles","previous_headings":"","what":"Optimizing template-based detection","title":"Template-based detection","text":"function optimize_template_detector() allows evaluate performance different correlation thresholds: Additional threshold values can evaluated without run . just need supplied output previous run argument previous.output (trick can done optimizing energy-based detection): case 2 threshold values (0.5 0.6) can achieve optimal detection.","code":"# run optimization optimization <-   optimize_template_detector(     template.correlations = correlations,     reference = lbh1_reference,     threshold = seq(0.1, 0.5, 0.1)   ) 5 thresholds will be evaluated: # print output optimization threshold   templates detections true.positives false.positives false.negatives splits 1       0.1 lbh1.wav-10         89             10              79               0      0 2       0.2 lbh1.wav-10         54             10              44               0      0 3       0.3 lbh1.wav-10         17             10               7               0      0 4       0.4 lbh1.wav-10         10             10               0               0      0 5       0.5 lbh1.wav-10         10             10               0               0      0   merges   overlap recall precision   f.score 1      0 0.9241771      1 0.1123596 0.2020202 2      0 0.9241771      1 0.1851852 0.3125000 3      0 0.9241771      1 0.5882353 0.7407407 4      0 0.9241771      1 1.0000000 1.0000000 5      0 0.9241771      1 1.0000000 1.0000000 # run optimization optimize_template_detector(   template.correlations = correlations,   reference = lbh1_reference,   threshold = c(0.6, 0.7),   previous.output = optimization ) 2 thresholds will be evaluated: threshold   templates detections true.positives false.positives false.negatives splits 1       0.1 lbh1.wav-10         89             10              79               0      0 2       0.2 lbh1.wav-10         54             10              44               0      0 3       0.3 lbh1.wav-10         17             10               7               0      0 4       0.4 lbh1.wav-10         10             10               0               0      0 5       0.5 lbh1.wav-10         10             10               0               0      0 6       0.6 lbh1.wav-10         10             10               0               0      0 7       0.7 lbh1.wav-10          6              6               0               4      0   merges   overlap recall precision   f.score 1      0 0.9241771    1.0 0.1123596 0.2020202 2      0 0.9241771    1.0 0.1851852 0.3125000 3      0 0.9241771    1.0 0.5882353 0.7407407 4      0 0.9241771    1.0 1.0000000 1.0000000 5      0 0.9241771    1.0 1.0000000 1.0000000 6      0 0.9241771    1.0 1.0000000 1.0000000 7      0 0.9184415    0.6 1.0000000 0.7500000"},{"path":"https://docs.ropensci.org/ohun/articles/template_based_detection.html","id":"detecting-several-templates","dir":"Articles","previous_headings":"","what":"Detecting several templates","title":"Template-based detection","text":"Several templates can used within call. correlate two templates two example sound files, taking one template sound file: Note cases can get sound event detected several times (duplicates), one template. can check case just diagnosing detection: got perfect recall, low precision. due fact reference events picked templates. can actually diagnose detection template see clearly: see independently template achieved good detection. can create consensus detection leaving detections highest correlation across templates. first need label row detection using label_detection() remove duplicates using consensus_detection(): Now can filter duplicates diagnose detection , telling function select single row per duplicate using correlation score criterium (= \"scores\", column part template_detector() output): successfully get rid duplicates detected every single target sound event. Please cite ohun like : Araya-Salas, M. (2021), ohun: diagnosing optimizing automated sound event detection. R package version 0.1.0.","code":"# get correlations correlations <-   template_correlator(     templates = lbh1_reference[c(1, 10),],     files = \"lbh1.wav\",     path = tempdir()   )  # run detection detection <-   template_detector(template.correlations = correlations, threshold = 0.6) #diagnose diagnose_detection(reference = lbh1_reference, detection = detection) detections true.positives false.positives false.negatives splits merges   overlap 1         20             10              10               0      0      0 0.9306396   recall precision   f.score 1      1       0.5 0.6666667 #diagnose diagnose_detection(reference = lbh1_reference, detection = detection, by = \"template\") template detections true.positives false.positives false.negatives splits merges 1 lbh1.wav-10         10             10               0               0      0      0 2 lbh1.wav-19         10             10               0               0      0      0     overlap recall precision f.score 1 0.9241771      1         1       1 2 0.8789903      1         1       1 # labeling detection labeled <-   label_detection(reference = lbh_reference, detection = detection, by = \"template\") # filter consensus <- consensus_detection(detection = labeled, by = \"scores\")  # diagnose diagnose_detection(reference = lbh1_reference, detection = consensus) detections true.positives false.positives false.negatives splits merges   overlap 1         10             10               0               0      0      0 0.9046387   recall precision f.score 1      1         1       1"},{"path":"https://docs.ropensci.org/ohun/articles/template_based_detection.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Template-based detection","text":"Araya-Salas, M., Smith-Vidaurre, G., Chaverri, G., Brenes, J. C., Chirino, F., Elizondo-Calvo, J., & Rico-Guevara, . (2023). ohun: R package diagnosing optimizing automatic sound event detection. Methods Ecology Evolution, 14, 2259–2271. https://doi.org/10.1111/2041-210X.14170 Araya-Salas M, Smith-Vidaurre G (2017) warbleR: R package streamline analysis animal sound events. Methods Ecology Evolution, 8:184-191. Khanna H., Gaunt S.L.L. & McCallum D.. (1997). Digital spectrographic cross-correlation: tests sensitivity. Bioacoustics 7(3): 209-234. Knight, E.C., Hannah, K.C., Foley, G.J., Scott, C.D., Brigham, R.M. & Bayne, E. (2017). Recommendations acoustic recognizer performance assessment application five common automated signal recognition programs. Avian Conservation Ecology, Macmillan, N. ., & Creelman, C.D. (2004). Detection theory: user’s guide. Psychology press. Session information","code":"R version 4.5.1 (2025-06-13) Platform: aarch64-apple-darwin20 Running under: macOS Sonoma 14.7.6  Matrix products: default BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib  LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1  locale: [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8  time zone: UTC tzcode source: internal  attached base packages: [1] stats     graphics  grDevices utils     datasets  methods   base       other attached packages: [1] warbleR_1.1.35     NatureSounds_1.0.5 knitr_1.50         seewave_2.2.3      [5] tuneR_1.4.7        ohun_1.0.3          loaded via a namespace (and not attached):  [1] gtable_0.3.6       rjson_0.2.23       xfun_0.52          bslib_0.9.0         [5] ggplot2_3.5.2      vctrs_0.6.5        tools_4.5.1        bitops_1.0-9        [9] curl_6.4.0         parallel_4.5.1     tibble_3.3.0       proxy_0.4-27       [13] pkgconfig_2.0.3    KernSmooth_2.23-26 checkmate_2.3.2    RColorBrewer_1.1-3 [17] desc_1.4.3         lifecycle_1.0.4    compiler_4.5.1     farver_2.1.2       [21] textshaping_1.0.1  brio_1.1.5         htmltools_0.5.8.1  class_7.3-23       [25] sass_0.4.10        RCurl_1.98-1.17    yaml_2.3.10        pkgdown_2.1.3      [29] pillar_1.11.0      jquerylib_0.1.4    MASS_7.3-65        classInt_0.4-11    [33] cachem_1.1.0       viridis_0.6.5      digest_0.6.37      sf_1.0-21          [37] fastmap_1.2.0      grid_4.5.1         cli_3.6.5          magrittr_2.0.3     [41] e1071_1.7-16       scales_1.4.0       backports_1.5.0    rmarkdown_2.29     [45] httr_1.4.7         signal_1.8-1       igraph_2.1.4       gridExtra_2.3      [49] ragg_1.4.0         pbapply_1.7-4      evaluate_1.0.4     dtw_1.23-1         [53] fftw_1.0-9         testthat_3.2.3     viridisLite_0.4.2  rlang_1.1.6        [57] Rcpp_1.1.0         glue_1.8.0         DBI_1.2.3          jsonlite_2.0.0     [61] R6_2.6.1           systemfonts_1.2.3  fs_1.6.6           units_0.8-7"},{"path":"https://docs.ropensci.org/ohun/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Marcelo Araya-Salas. Author, maintainer. Alec L. Robitaille. Reviewer. Sam Lapp. Reviewer.","code":""},{"path":"https://docs.ropensci.org/ohun/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Araya-Salas, M., Smith-Vidaurre, G., Chaverri, G., Brenes, J. C., Chirino, F., Elizondo-Calvo, J., & Rico-Guevara, . 2023. ohun: R package diagnosing optimizing automatic sound event detection. Methods Ecology Evolution. https://doi.org/10.1111/2041-210X.14170","code":"@Article{,   entry = {MISC},   title = {ohun: automatic detection of acoustic signals},   author = {M. Araya-Salas and G. Smith-Vidaurre and {Brenes} and {J.C.} and F. Chirino and J Elizondo-Calvo and A. Rico-Guevara},   year = {2023},   journal = {Methods in Ecology and Evolution},   url = {https://doi.org/10.1111/2041-210X.14170}, }"},{"path":"https://docs.ropensci.org/ohun/index.html","id":"ohun-optimizing-sound-event-detection","dir":"","previous_headings":"","what":"Optimizing Acoustic Signal Detection","title":"Optimizing Acoustic Signal Detection","text":"ohun intended facilitate automated detection sound events, providing functions diagnose optimize detection routines. provides utilities comparing detection annotations audio events described frequency time boxes. main features package : use reference annotations detection diagnostic optimization use signal detection theory indices evaluate detection performance package offers functions : Curate references acoustic data sets Diagnose detection performance Optimize detection routines based reference annotations Energy-based detection Template-based detection implementation detection diagnostics can applied built detection methods obtained software packages makes package ohun useful tool conducting direct comparisons performance different routines. addition, compatibility ohun data formats already used sound analysis R packages (e.g. seewave, warbleR) enables integration ohun complex acoustic analysis workflows popular programming environment within research community. functions allow parallelization tasks (using packages parallel pbapply), distributes tasks among several processors improve computational efficiency. package works sound files ‘.wav’, ‘.mp3’, ‘.flac’ ‘.wac’ format. Install/load package CRAN follows: install latest developmental version github need R package remotes: system requirements due dependency seewave may needed. Take look link instruction install/troubleshoot external dependencies. Take look vignettes overview main features packages: Optimizing sound event detection Energy-based detection Template-based detection package peer-reviewed rOpenSci. Please cite ohun follows: Araya-Salas, M. (2022), ohun: diagnosing optimizing automated sound event detection. R package version 0.1.1.","code":"# From CRAN would be install.packages(\"ohun\")  #load package library(ohun) remotes::install_github(\"ropensci/ohun\")  #load package library(ohun)"},{"path":"https://docs.ropensci.org/ohun/reference/consensus_detection.html","id":null,"dir":"Reference","previous_headings":"","what":"Remove ambiguous detections — consensus_detection","title":"Remove ambiguous detections — consensus_detection","text":"consensus_detection removes ambiguous detections","code":""},{"path":"https://docs.ropensci.org/ohun/reference/consensus_detection.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Remove ambiguous detections — consensus_detection","text":"","code":"consensus_detection(   detection,   by = \"overlap\",   filter = \"max\",   cores = 1,   pb = TRUE )"},{"path":"https://docs.ropensci.org/ohun/reference/consensus_detection.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Remove ambiguous detections — consensus_detection","text":"detection Data frame selection table (using warbleR package's format, see selection_table) output label_detection containing start end signals. Must contained least following columns: \"sound.files\", \"selec\", \"start\", \"end\" \"detection.class\" (last one generated label_detection). must also contained column indicated '' argument ('overlap' default). Character vector length 1 indicating column 'detection' used filter detections. Must refer numeric column. Default 'overlap', return label_detection. filter Character vector length 1 indicating criterium used filter column refer '' argument. Current options 'max' (maximum) 'min' (minimum). Default 'max'. cores Numeric. Controls whether parallel computing applied. specifies number cores used. Default 1 (.e. parallel computing). pb Logical argument control progress bar. Default TRUE.","code":""},{"path":"https://docs.ropensci.org/ohun/reference/consensus_detection.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Remove ambiguous detections — consensus_detection","text":"data frame selection table ('detection' also selection table, warbleR package's format, see selection_table) 'X' removing ambiguous detections (split merged positives).","code":""},{"path":"https://docs.ropensci.org/ohun/reference/consensus_detection.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Remove ambiguous detections — consensus_detection","text":"function removes ambiguous detections keeping one maximizes criterium given 'filter'. default keeps detection highest overlap reference signal. works output label_detection. Mostly useful several detections match reference case template detection multiple templates (see template_detector). Keep mind argument 'solve.ambiguous' FALSE keep ambiguous detections.","code":""},{"path":"https://docs.ropensci.org/ohun/reference/consensus_detection.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Remove ambiguous detections — consensus_detection","text":"#'  Araya-Salas, M., Smith-Vidaurre, G., Chaverri, G., Brenes, J. C., Chirino, F., Elizondo-Calvo, J., & Rico-Guevara, . (2023). ohun: R package diagnosing optimizing automatic sound event detection. Methods Ecology Evolution, 14, 2259–2271. https://doi.org/10.1111/2041-210X.14170","code":""},{"path":[]},{"path":"https://docs.ropensci.org/ohun/reference/consensus_detection.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Remove ambiguous detections — consensus_detection","text":"Marcelo Araya-Salas (marcelo.araya@ucr.ac.cr).","code":""},{"path":"https://docs.ropensci.org/ohun/reference/consensus_detection.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Remove ambiguous detections — consensus_detection","text":"","code":"{   # load example data   data(\"lbh1\", \"lbh_reference\")    # save sound files   tuneR::writeWave(lbh1, file.path(tempdir(), \"lbh1.wav\"))    # template for the first sound file in 'lbh_reference'   templ1 <- lbh_reference[lbh_reference$sound.files == \"lbh1.wav\" & lbh_reference$selec == 11, ]    # generate template correlations   tc <- template_correlator(     templates = templ1, path = tempdir(),     files = \"lbh1.wav\"   )    # template detection   td <- template_detector(template.correlations = tc, threshold = 0.35)    # this detection generates 2 split positives   diagnose_detection(     reference = lbh_reference[lbh_reference == \"lbh1.wav\", ],     detection = td,     solve.ambiguous = FALSE   )    # label detection     ltd <- label_detection(     reference = lbh_reference[lbh_reference == \"lbh1.wav\", ],     detection = td,      solve.ambiguous = FALSE     )    # now they can be filter to keep the detection with the highest score for each split   ftd <- consensus_detection(ltd, by = \"scores\")    # splits must be 0   diagnose_detection(     reference = lbh_reference[lbh_reference == \"lbh1.wav\", ],     detection = ftd,     solve.ambiguous = FALSE   ) } #> computing correlations (step 0 of 0): #>   detections true.positives false.positives false.negatives splits merges #> 1         13             10               3               0      0      0 #>     overlap recall precision   f.score #> 1 0.8917651      1 0.7692308 0.8695652"},{"path":"https://docs.ropensci.org/ohun/reference/diagnose_detection.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate the performance of a sound event detection procedure — diagnose_detection","title":"Evaluate the performance of a sound event detection procedure — diagnose_detection","text":"diagnose_detection evaluates performance sound event detection procedure comparing output selection table reference selection table","code":""},{"path":"https://docs.ropensci.org/ohun/reference/diagnose_detection.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate the performance of a sound event detection procedure — diagnose_detection","text":"","code":"diagnose_detection(   reference,   detection,   by.sound.file = FALSE,   time.diagnostics = FALSE,   cores = 1,   pb = TRUE,   path = NULL,   by = NULL,   macro.average = FALSE,   min.overlap = 0.5,   solve.ambiguous = TRUE )"},{"path":"https://docs.ropensci.org/ohun/reference/diagnose_detection.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate the performance of a sound event detection procedure — diagnose_detection","text":"reference Data frame 'selection.table' (following warbleR package format) reference selections (start end sound events) used evaluate performance detection, represented selections 'detection'. Must contained least following columns: \"sound.files\", \"selec\", \"start\" \"end\". must contain reference selections used detection optimization. detection Data frame 'selection.table' detections (start end sound events) compared 'reference' selections. Must contained least following columns: \"sound.files\", \"selec\", \"start\" \"end\". can contain data additional sound files found 'references'. case routine assumes sound events found files, detection files false positives. .sound.file Logical argument control whether performance diagnostics summarized across sound files (.sound.file = FALSE, 1 sound file included 'reference') shown separated sound file. Default FALSE. time.diagnostics Logical argument control diagnostics related duration sound events (\"mean.duration.true.positives\", \"mean.duration.false.positives\", \"mean.duration.false.negatives\" \"proportional.duration.true.positives\") returned (TRUE). Default FALSE. cores Numeric. Controls whether parallel computing applied. specifies number cores used. Default 1 (.e. parallel computing). pb Logical argument control progress bar. Default TRUE. path Character string containing directory path sound files located. supplied duty cycle (fraction sound file sounds detected)also returned. feature helpful tuning energy-based detection. Default NULL. Character vector name column 'reference' splitting diagnostics. Diagnostics returned separated level ''. Default NULL. macro.average Logical argument control diagnostics first calculated sound file averaged across sound files, can minimize effect unbalanced sample sizes sound files. FALSE (default) diagnostics based aggregated statistics irrespective sound files. following indices can estimated macro-averaging: overlap, mean.duration.true.positives, mean.duration.false.positives, mean.duration.false.positives, mean.duration.false.negatives, proportional.duration.true.positives, recall precision (f.score always derived recall precision). Note applying macro-averaging, recall precision derived true positive, false positive false negative values returned function. min.overlap Numeric. Controls minimum amount overlap required detection reference sound counted true positive. Default 0.5. Overlap measured intersection union. used solve.ambiguous = TRUE. solve.ambiguous Logical argument control whether ambiguous detections (.e. split merged positives) solved using maximum bipartite graph matching. Default TRUE. FALSE ambiguous detections solved.","code":""},{"path":"https://docs.ropensci.org/ohun/reference/diagnose_detection.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate the performance of a sound event detection procedure — diagnose_detection","text":"data frame including following detection performance diagnostics: detections: total number detections true.positives: number sound events 'reference' correspond detection. Matching defined degree overlap time. perfect detection routine equal number rows 'reference'. false.positives: number detections match (.e. overlap ) sound events 'reference'. perfect detection routine 0. false.negatives: number sound events 'reference' detected (found 'detection'. perfect detection routine 0. splits: number detections overlapping reference sounds also overlap detections. perfect detection routine 0. merges: number detections overlap two reference sounds. perfect detection routine 0. mean.duration.true.positives: mean duration true positives (ms). included time.diagnostics = TRUE. mean.duration.false.positives: mean duration false positives (ms). included time.diagnostics = TRUE. mean.duration.false.negatives: mean duration false negatives (ms). included time.diagnostics = TRUE. overlap: mean intersection union overlap true positives. proportional.duration.true.positives: ratio duration true positives duration sound events 'reference'. perfect detection routine 1. Based true positives split merged. duty.cycle: proportion sound file sounds detected. included time.diagnostics = TRUE path supplied. Useful conducting energy-based detection perfect detection can obtained low amplitude threshold, detect everything, produce duty cycle close 1. recall: Proportion sound events 'reference' detected. perfect detection routine 1. precision: Proportion detections correspond sound events 'reference'. perfect detection routine 1. f.score: Combines recall precision harmonic mean two. Provides single value evaluating performance. perfect detection routine 1.","code":""},{"path":"https://docs.ropensci.org/ohun/reference/diagnose_detection.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Evaluate the performance of a sound event detection procedure — diagnose_detection","text":"function evaluates performance sound event detection procedure comparing output selection table reference selection table sound events interest selected. function takes overlap detected sound events target sound events true positives. Note sound files located supplied 'path' analyzed even listed 'reference'. several possible matching pairs sound event detections found, optimal set matching pairs found maximum bipartite matching (using R package igraph). Priority assigning detection reference given amount time overlap. 'splits' 'merge.positives' also counted (.e. counted twice) 'true.positives'. Therefore \"true.positives + false.positives = detections\".","code":""},{"path":"https://docs.ropensci.org/ohun/reference/diagnose_detection.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Evaluate the performance of a sound event detection procedure — diagnose_detection","text":"Araya-Salas, M., Smith-Vidaurre, G., Chaverri, G., Brenes, J. C., Chirino, F., Elizondo-Calvo, J., & Rico-Guevara, . (2023). ohun: R package diagnosing optimizing automatic sound event detection. Methods Ecology Evolution, 14, 2259–2271. https://doi.org/10.1111/2041-210X.14170","code":""},{"path":[]},{"path":"https://docs.ropensci.org/ohun/reference/diagnose_detection.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Evaluate the performance of a sound event detection procedure — diagnose_detection","text":"Marcelo Araya-Salas marcelo.araya@ucr.ac.cr)","code":""},{"path":"https://docs.ropensci.org/ohun/reference/diagnose_detection.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Evaluate the performance of a sound event detection procedure — diagnose_detection","text":"","code":"{   # load data   data(\"lbh_reference\")    # perfect detection   diagnose_detection(reference = lbh_reference, detection = lbh_reference)    # missing one in detection   diagnose_detection(reference = lbh_reference, detection = lbh_reference[-1, ])    # an extra one in detection   diagnose_detection(reference = lbh_reference[-1, ], detection = lbh_reference)    # with time diagnostics   diagnose_detection(     reference = lbh_reference[-1, ],     detection = lbh_reference, time.diagnostics = TRUE   )    # and extra sound file in reference   diagnose_detection(     reference = lbh_reference,     detection =       lbh_reference[lbh_reference$sound.files != \"lbh1\", ]   )    # and extra sound file in detection   diagnose_detection(     reference =       lbh_reference[lbh_reference$sound.files != \"lbh1\", ],     detection = lbh_reference   )    # and extra sound file in detection by sound file   dd <- diagnose_detection(     reference =       lbh_reference[lbh_reference$sound.files != \"lbh1\", ],     detection = lbh_reference, time.diagnostics = TRUE, by.sound.file = TRUE   )    # get summary   summarize_diagnostic(dd) } #>   detections true.positives false.positives false.negatives splits merges #> 1         19             19               0               0      0      0 #>   overlap recall precision f.score #> 1       1      1         1       1"},{"path":"https://docs.ropensci.org/ohun/reference/energy_detector.html","id":null,"dir":"Reference","previous_headings":"","what":"Detects the start and end of sound events — energy_detector","title":"Detects the start and end of sound events — energy_detector","text":"energy_detector detects start end sound events based energy time attributes","code":""},{"path":"https://docs.ropensci.org/ohun/reference/energy_detector.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Detects the start and end of sound events — energy_detector","text":"","code":"energy_detector(   files = NULL,   envelopes = NULL,   path = \".\",   hop.size = 11.6,   wl = NULL,   thinning = 1,   bp = NULL,   smooth = 5,   threshold = 5,   peak.amplitude = 0,   hold.time = 0,   min.duration = 0,   max.duration = Inf,   cores = 1,   pb = TRUE )"},{"path":"https://docs.ropensci.org/ohun/reference/energy_detector.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Detects the start and end of sound events — energy_detector","text":"files Character vector indicating sound files analyzed. Optional. 'files' 'envelopes' supplied function work supported format sound files working directory. Supported file formats:'.wav', '.mp3', '.flac' '.wac'. supplied function work sound files (supported format) 'path'. envelopes object class 'envelopes' (generated get_envelopes) containing amplitude envelopes sound files analyzed. 'files' 'envelopes' supplied function work supported format sound files working directory. path Character string containing directory path sound files located. current working directory used default. hop.size numeric vector length 1 specifying time window duration (ms). Default 11.6 ms, equivalent 512 wl 44.1 kHz sampling rate. Ignored 'wl' supplied. wl numeric vector length 1 specifying window length spectrogram. Default NULL. supplied, 'hop.size' ignored. Used internally bandpass filtering (applied 'bp' supplied). thinning Numeric vector length 1 range 0~1 indicating proportional reduction number samples used represent amplitude envelopes (.e. thinning envelopes). Usually amplitude envelopes many samples needed accurately represent amplitude variation time, affects size output (usually large R objects / files). Default 1 (thinning). Higher sampling rates can afford higher size reduction (e.g. lower thinning values). Reduction conducted interpolation using approx. Note thinning may decrease time precision, higher thinning less precise time detection. argument used internally get_envelopes. used 'envelopes' supplied. bp Numeric vector length 2 giving lower upper limits frequency bandpass filter (kHz). Default NULL. argument used internally get_envelopes. used 'envelopes' supplied. Bandpass done using function ffilter, applies short-term Fourier transformation first create spectrogram target frequencies filtered back transformed wave object using reverse Fourier transformation. smooth numeric vector length 1 smooth amplitude envelope  sum smooth function. controls time 'neighborhood' (ms) amplitude samples smoothed (.e. averaged neighboring samples). Default 5. 0 means smoothing applied. Note smoothing applied thinning (see 'thinning' argument). function  envelope used internally analogous sum smoothing env. argument used internally get_envelopes. used 'envelopes' supplied. threshold Numeric vector length 1 value 0 100 specifying amplitude threshold detecting sound event occurrences. Amplitude represented percentage 0 100 represent lowest amplitude highest amplitude respectively. Default 5. peak.amplitude Numeric vector length 1 minimum peak amplitude value. Detections value excluded. Peak amplitude maximum sound pressure level (decibels) across sound event (see sound_pressure_level). can useful expecting higher peak amplitude target sound events compared non-target sound events keeping best examples target sound events. Default 0. hold.time Numeric vector length 1. Specifies time range (ms) selections merged (.e. 2 selections separated less specified 'hold.time' merged single selection). Default 0 (hold time applied). min.duration Numeric vector length 1 giving shortest duration (ms) sound events detected. removes sound events threshold. 'hold.time' supplied sound events first merged filtered duration. Default 0 (.e. filtering based minimum duration). max.duration Numeric vector length 1 giving longest duration (ms) sound events detected. removes sound events threshold. 'hold.time' supplied sound events first merged filtered duration.  Default Inf (.e. filtering based maximum duration). cores Numeric. Controls whether parallel computing applied. specifies number cores used. Default 1 (.e. parallel computing). pb Logical argument control progress bar. Default TRUE.","code":""},{"path":"https://docs.ropensci.org/ohun/reference/energy_detector.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Detects the start and end of sound events — energy_detector","text":"function returns 'selection_table' (warbleR package's formats, see selection_table) data frame (sound files found) containing start end sound event   sound file. sound event detected sound file included output data frame.","code":""},{"path":"https://docs.ropensci.org/ohun/reference/energy_detector.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Detects the start and end of sound events — energy_detector","text":"function detects time position target sound events based energy time thresholds. first detect sound given energy threshold (argument 'energy'). 'hold.time' supplied detected sounds merged necessary. sounds detected filtered based duration attributes ('min.duration' 'max.duration'). 'peak.amplitude' higher 0 sound events higher peak amplitude kept. Band pass filtering ('bp'), thinning ('thinning') envelope smoothing ('smooth') applied (supplied) threshold detection.","code":""},{"path":"https://docs.ropensci.org/ohun/reference/energy_detector.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Detects the start and end of sound events — energy_detector","text":"Araya-Salas, M., Smith-Vidaurre, G., Chaverri, G., Brenes, J. C., Chirino, F., Elizondo-Calvo, J., & Rico-Guevara, . (2023). ohun: R package diagnosing optimizing automatic sound event detection. Methods Ecology Evolution, 14, 2259–2271. https://doi.org/10.1111/2041-210X.14170","code":""},{"path":[]},{"path":"https://docs.ropensci.org/ohun/reference/energy_detector.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Detects the start and end of sound events — energy_detector","text":"Marcelo Araya-Salas (marcelo.araya@ucr.ac.cr)","code":""},{"path":"https://docs.ropensci.org/ohun/reference/energy_detector.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Detects the start and end of sound events — energy_detector","text":"","code":"# \\donttest{ # Save example files into temporary working directory data(\"lbh1\", \"lbh2\", \"lbh_reference\") tuneR::writeWave(lbh1, file.path(tempdir(), \"lbh1.wav\")) tuneR::writeWave(lbh2, file.path(tempdir(), \"lbh2.wav\"))  # using smoothing and minimum duration detec <- energy_detector(files = c(\"lbh1.wav\", \"lbh2.wav\"), path = tempdir(), threshold = 6, smooth = 6.8, bp = c(2, 9), hop.size = 3, min.duration = 0.05)  # diagnose detection diagnose_detection(reference = lbh_reference, detection = detec) #>   detections true.positives false.positives false.negatives splits merges #> 1         86             19              67               0      0      0 #>     overlap recall precision   f.score #> 1 0.8511668      1 0.2209302 0.3619048  # without declaring 'files' detec <- energy_detector(path = tempdir(), threshold = 60, smooth = 6.8, bp = c(2, 9), hop.size = 6.8, min.duration = 90)  # diagnose detection diagnose_detection(reference = lbh_reference, detection = detec) #>   detections true.positives false.positives false.negatives splits merges #> 1          0              0               0              19      0      0 #>   overlap recall precision f.score #> 1      NA      0         0      NA  # using hold time detec <- energy_detector(threshold = 10, hold.time = 150, bp = c(2, 9), hop.size = 6.8, path = tempdir())  # diagnose detection diagnose_detection(reference = lbh_reference, detection = detec) #>   detections true.positives false.positives false.negatives splits merges #> 1         19             19               0               0      0      0 #>     overlap recall precision f.score #> 1 0.8774537      1         1       1  # calculate envelopes first envs <- get_envelopes(bp = c(2, 9), hop.size = 6.8, path = tempdir())  # then run detection providing 'envelopes' (but no 'files') detec <- energy_detector(envelopes = envs, threshold = 10, hold.time = 150, min.duration = 50)  # diagnose detection diagnose_detection(reference = lbh_reference, detection = detec, time.diagnostics = TRUE) #>   detections true.positives false.positives false.negatives splits merges #> 1         19             19               0               0      0      0 #>     overlap mean.duration.true.positives mean.duration.false.positives #> 1 0.8774537                          152                            NA #>   mean.duration.false.negatives proportional.duration.true.positives recall #> 1                            NA                              1.06869      1 #>   precision f.score #> 1         1       1  # }"},{"path":"https://docs.ropensci.org/ohun/reference/feature_acoustic_data.html","id":null,"dir":"Reference","previous_headings":"","what":"alternative name for summarize_acoustic_data — feature_acoustic_data","title":"alternative name for summarize_acoustic_data — feature_acoustic_data","text":"alternative name summarize_acoustic_data","code":""},{"path":"https://docs.ropensci.org/ohun/reference/feature_acoustic_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"alternative name for summarize_acoustic_data — feature_acoustic_data","text":"","code":"feature_acoustic_data(path = \".\", digits = 2)"},{"path":"https://docs.ropensci.org/ohun/reference/feature_acoustic_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"alternative name for summarize_acoustic_data — feature_acoustic_data","text":"see summarize_acoustic_data documentation. feature_acoustic_data deprecated future versions.","code":""},{"path":"https://docs.ropensci.org/ohun/reference/feature_reference.html","id":null,"dir":"Reference","previous_headings":"","what":"alternative name for summarize_reference — feature_reference","title":"alternative name for summarize_reference — feature_reference","text":"alternative name summarize_reference","code":""},{"path":"https://docs.ropensci.org/ohun/reference/feature_reference.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"alternative name for summarize_reference — feature_reference","text":"","code":"feature_reference(   reference,   path = NULL,   by.sound.file = FALSE,   units = c(\"ms\", \"kHz\"),   digits = 2 )"},{"path":"https://docs.ropensci.org/ohun/reference/feature_reference.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"alternative name for summarize_reference — feature_reference","text":"see summarize_reference documentation. feature_reference deprecated future versions.","code":""},{"path":"https://docs.ropensci.org/ohun/reference/filter_detection.html","id":null,"dir":"Reference","previous_headings":"","what":"alternative name for consensus_detection — filter_detection","title":"alternative name for consensus_detection — filter_detection","text":"alternative name consensus_detection","code":""},{"path":"https://docs.ropensci.org/ohun/reference/filter_detection.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"alternative name for consensus_detection — filter_detection","text":"","code":"filter_detection(   detection,   by = \"overlap\",   filter = \"max\",   cores = 1,   pb = TRUE )"},{"path":"https://docs.ropensci.org/ohun/reference/filter_detection.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"alternative name for consensus_detection — filter_detection","text":"see consensus_detection documentation. filter_detection deprecated future versions.","code":""},{"path":"https://docs.ropensci.org/ohun/reference/get_envelopes.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract absolute amplitude envelopes — get_envelopes","title":"Extract absolute amplitude envelopes — get_envelopes","text":"get_envelopes extracts absolute amplitude envelopes speed energy detection","code":""},{"path":"https://docs.ropensci.org/ohun/reference/get_envelopes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract absolute amplitude envelopes — get_envelopes","text":"","code":"get_envelopes(   path = \".\",   files = NULL,   bp = NULL,   hop.size = 11.6,   wl = NULL,   cores = 1,   thinning = 1,   pb = TRUE,   smooth = 5,   normalize = TRUE )"},{"path":"https://docs.ropensci.org/ohun/reference/get_envelopes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract absolute amplitude envelopes — get_envelopes","text":"path Character string containing directory path sound files located. current working directory used default. files character vector indicating sound files analyzed. Supported file formats:'.wav', '.mp3', '.flac' '.wac'. supplied function work sound files (supported format) 'path'. bp Numeric vector length 2 giving lower upper limits frequency bandpass filter (kHz). Default NULL. Bandpass done using function ffilter, applies short-term Fourier transformation first create spectrogram target frequencies filtered back transformed wave object using reverse Fourier transformation. hop.size numeric vector length 1 specifying time window duration (ms). Default 11.6 ms, equivalent 512 wl 44.1 kHz sampling rate. Ignored 'wl' supplied. wl numeric vector length 1 specifying window length spectrogram. Default NULL. supplied, 'hop.size' ignored. Used internally bandpass filtering (applied 'bp' supplied). cores Numeric. Controls whether parallel computing applied. specifies number cores used. Default 1 (.e. parallel computing). thinning Numeric vector length 1 range 0~1 indicating proportional reduction number samples used represent amplitude envelopes (.e. thinning envelopes). Usually amplitude envelopes many samples needed accurately represent amplitude variation time, affects size output (usually large R objects / files). Default 1 (thinning). Higher sampling rates can afford higher size reduction (e.g. lower thinning values). Reduction conducted linear interpolation using approx. Note thinning may decrease time precision higher thinning less precise time detection. generally advised smoothing ('smooth' argument) applied. pb Logical argument control progress bar. Default TRUE. smooth numeric vector length 1 smooth amplitude envelope sum smooth function. controls time 'neighborhood' (ms) amplitude samples smoothed (.e. averaged neighboring samples). Default 5. 0 means smoothing applied. Note smoothing applied thinning (see 'thinning' argument). function  envelope used internally analogous sum smoothing env. argument used internally get_envelopes. normalize Logical argument control envelopes normalized 0-1 range.","code":""},{"path":"https://docs.ropensci.org/ohun/reference/get_envelopes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract absolute amplitude envelopes — get_envelopes","text":"object class 'envelopes'.","code":""},{"path":"https://docs.ropensci.org/ohun/reference/get_envelopes.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract absolute amplitude envelopes — get_envelopes","text":"function extracts absolute amplitude envelopes sound files. Can used manipulate envelopes running energy_detector.","code":""},{"path":"https://docs.ropensci.org/ohun/reference/get_envelopes.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Extract absolute amplitude envelopes — get_envelopes","text":"Araya-Salas, M., Smith-Vidaurre, G., Chaverri, G., Brenes, J. C., Chirino, F., Elizondo-Calvo, J., & Rico-Guevara, . (2023). ohun: R package diagnosing optimizing automatic sound event detection. Methods Ecology Evolution, 14, 2259–2271. https://doi.org/10.1111/2041-210X.14170","code":""},{"path":[]},{"path":"https://docs.ropensci.org/ohun/reference/get_envelopes.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extract absolute amplitude envelopes — get_envelopes","text":"Marcelo Araya-Salas (marcelo.araya@ucr.ac.cr).","code":""},{"path":"https://docs.ropensci.org/ohun/reference/get_envelopes.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract absolute amplitude envelopes — get_envelopes","text":"","code":"{   # Save to temporary working directory   data(list = c(\"lbh1\", \"lbh2\"))   tuneR::writeWave(lbh1, file.path(tempdir(), \"lbh1.wav\"))   tuneR::writeWave(lbh2, file.path(tempdir(), \"lbh2.wav\"))    # get raw absolute amplitude envelopes   envs <- get_envelopes(path = tempdir())    # extract segment for the first sound event in the first sound file   x <- envs[[1]]$envelope    # and plot it   plot(x[(length(x) / 9):(length(x) / 4)], type = \"l\", xlab = \"samples\", ylab = \"amplitude\")    # smoothing envelopes   envs <- get_envelopes(path = tempdir(), smooth = 6.8)   x <- envs[[1]]$envelope   plot(x[(length(x) / 9):(length(x) / 4)], type = \"l\", xlab = \"samples\", ylab = \"amplitude\")    # smoothing and thinning   envs <- get_envelopes(path = tempdir(), thinning = 1 / 10, smooth = 6.8)   x <- envs[[1]]$envelope   plot(x[(length(x) / 9):(length(x) / 4)], type = \"l\", xlab = \"samples\", ylab = \"amplitude\")    # no normalization   envs <- get_envelopes(path = tempdir(), thinning = 1 / 10, smooth = 6.8)   x <- envs[[1]]$envelope   plot(x[(length(x) / 9):(length(x) / 4)],     type = \"l\", xlab = \"samples\", ylab = \"amplitude\",     normalize = FALSE   ) }    #> Warning: \"normalize\" is not a graphical parameter #> Warning: \"normalize\" is not a graphical parameter #> Warning: \"normalize\" is not a graphical parameter #> Warning: \"normalize\" is not a graphical parameter #> Warning: \"normalize\" is not a graphical parameter #> Warning: \"normalize\" is not a graphical parameter"},{"path":"https://docs.ropensci.org/ohun/reference/get_templates.html","id":null,"dir":"Reference","previous_headings":"","what":"Find templates representative of the structural variation of sound events — get_templates","title":"Find templates representative of the structural variation of sound events — get_templates","text":"get_templates find sound events closer acoustic space centroid (.e. close average acoustic structure) reference table.","code":""},{"path":"https://docs.ropensci.org/ohun/reference/get_templates.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find templates representative of the structural variation of sound events — get_templates","text":"","code":"get_templates(   reference,   acoustic.space = NULL,   path = \".\",   n.sub.spaces = 1,   plot = TRUE,   color = \"#21908C4D\",   ... )"},{"path":"https://docs.ropensci.org/ohun/reference/get_templates.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find templates representative of the structural variation of sound events — get_templates","text":"reference Selection table (using warbleR package's format, see selection_table) data frame columns sound file name (sound.files), selection number (selec), start end time sound event (start end). acoustic.space Numeric matrix data frame two dimensions custom acoustic space used finding templates. supplied acoustic space calculated internally (default). Optional. Note function assumes 'reference' 'acoustic.space' refer sound events similarly ordered. path Character string containing directory path sound files located. current working directory used default. n.sub.spaces Integer vector length 1 number sub-spaces split total acoustic space. n.sub.spaces = 1, sound event closer centroid returned. n.sub.spaces > 1 function returns additional sound events, corresponding closer centroids sub-spaces. , function defines sub-spaces equal-size slices circle centered centroid acoustic space. plot Logical control plot created. Default TRUE. color Character string point color. Default '#21908C4D'. ... Additional arguments passed spectro_analysis customization measuring parameters calculate acoustic space.","code":""},{"path":"https://docs.ropensci.org/ohun/reference/get_templates.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find templates representative of the structural variation of sound events — get_templates","text":"function returns 'selection_table' (warbleR package's formats, see selection_table) data frame (sound files found) containing start end sound event   sound file.","code":""},{"path":"https://docs.ropensci.org/ohun/reference/get_templates.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Find templates representative of the structural variation of sound events — get_templates","text":"function finds sound events (reference table) representative acoustic structure variation sound events. done finding events closer centroid acoustic space. acoustic space supplied ('acoustic.space' argument) function estimate measuring several acoustic features using function spectro_analysis (features related energy distribution frequency time domain well features dominant frequency contours, see spectro_analysis details) summarizing Principal Component Analysis (z-transforming parameters) using function prcomp. Acoustic features missing values removed estimating Principal Component Analysis. rationale sound event close average structure likely share structural features events across acoustic space sound event periphery space. 1 template required function returns sound event closest acoustic space centroid. 1 template required additional sound events returned representative acoustic space. , function defines sub-spaces equal-size slices circle centered centroid acoustic space. column 'template' included output selection table identifies template. Custom acoustic spaces can supplied argument 'acoustic.space'. Notice function aims partition spaces sounds somehow homogeneously distributed. clear clusters found distribution acoustic space thus clusters might match sub-spaces defined function.","code":""},{"path":"https://docs.ropensci.org/ohun/reference/get_templates.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Find templates representative of the structural variation of sound events — get_templates","text":"Araya-Salas, M., Smith-Vidaurre, G., Chaverri, G., Brenes, J. C., Chirino, F., Elizondo-Calvo, J., & Rico-Guevara, . (2023). ohun: R package diagnosing optimizing automatic sound event detection. Methods Ecology Evolution, 14, 2259–2271. https://doi.org/10.1111/2041-210X.14170","code":""},{"path":[]},{"path":"https://docs.ropensci.org/ohun/reference/get_templates.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Find templates representative of the structural variation of sound events — get_templates","text":"Marcelo Araya-Salas (marcelo.araya@ucr.ac.cr). Implements modified version timer function seewave.","code":""},{"path":"https://docs.ropensci.org/ohun/reference/get_templates.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Find templates representative of the structural variation of sound events — get_templates","text":"","code":"{   # Save example files into temporary working directory   data(\"lbh1\", \"lbh2\", \"lbh_reference\")   tuneR::writeWave(lbh1, file.path(tempdir(), \"lbh1.wav\"))   tuneR::writeWave(lbh2, file.path(tempdir(), \"lbh2.wav\"))    # get a single mean template   template <- get_templates(reference = lbh_reference, path = tempdir())    # get 3 templates   template <- get_templates(reference = lbh_reference, n.sub.spaces = 3, path = tempdir()) } #> The first 2 principal components explained 0.65 of the variance  #> The first 2 principal components explained 0.65 of the variance"},{"path":"https://docs.ropensci.org/ohun/reference/label_detection.html","id":null,"dir":"Reference","previous_headings":"","what":"Label detections from a sound event detection procedure — label_detection","title":"Label detections from a sound event detection procedure — label_detection","text":"label_detection labels performance sound event detection procedure comparing output selection table reference selection table","code":""},{"path":"https://docs.ropensci.org/ohun/reference/label_detection.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Label detections from a sound event detection procedure — label_detection","text":"","code":"label_detection(   reference,   detection,   cores = 1,   pb = TRUE,   min.overlap = 0.5,   by = NULL,   solve.ambiguous = TRUE )"},{"path":"https://docs.ropensci.org/ohun/reference/label_detection.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Label detections from a sound event detection procedure — label_detection","text":"reference Data frame 'selection.table' (following warbleR package format) reference selections (start end sound events) used evaluate performance detection, represented selections 'detection'. Must contained least following columns: \"sound.files\", \"selec\", \"start\" \"end\". must contain reference selections used detection optimization. detection Data frame 'selection.table' detections (start end sound events) compared 'reference' selections. Must contained least following columns: \"sound.files\", \"selec\", \"start\" \"end\". can contain data additional sound files found 'references'. case routine assumes sound events found files, detection files false positives. cores Numeric. Controls whether parallel computing applied. specifies number cores used. Default 1 (.e. parallel computing). pb Logical argument control progress bar. Default TRUE. min.overlap Numeric. Controls minimum amount overlap required detection reference sound counted true positive. Default 0.5. Overlap measured intersection union. used solve.ambiguous = TRUE. Character vector name categorical column 'reference' running stratified. Labels returned separated level ''. Default NULL. solve.ambiguous Logical argument control whether ambiguous detections (.e. split merged positives) solved using maximum bipartite graph matching. Default TRUE. FALSE ambiguous detections solved.","code":""},{"path":"https://docs.ropensci.org/ohun/reference/label_detection.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Label detections from a sound event detection procedure — label_detection","text":"data frame selection table ('detection' also selection table, warbleR package's format, see selection_table) including three additional columns, 'detection.class', indicates class detection, 'reference' identifies event 'reference' table detected  'overlap' refers amount overlap reference sound. See diagnose_detection description labels used 'detection.class'. output data frame also contains additional data frame overlap pair overlapping detection/reference.  Overlap measured intersection union.","code":""},{"path":"https://docs.ropensci.org/ohun/reference/label_detection.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Label detections from a sound event detection procedure — label_detection","text":"function identifies rows output detection routine true false positives. achieved comparing data frame reference selection table sound events interest selected.","code":""},{"path":"https://docs.ropensci.org/ohun/reference/label_detection.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Label detections from a sound event detection procedure — label_detection","text":"Araya-Salas, M., Smith-Vidaurre, G., Chaverri, G., Brenes, J. C., Chirino, F., Elizondo-Calvo, J., & Rico-Guevara, . (2023). ohun: R package diagnosing optimizing automatic sound event detection. Methods Ecology Evolution, 14, 2259–2271. https://doi.org/10.1111/2041-210X.14170","code":""},{"path":[]},{"path":"https://docs.ropensci.org/ohun/reference/label_detection.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Label detections from a sound event detection procedure — label_detection","text":"Marcelo Araya-Salas marcelo.araya@ucr.ac.cr)","code":""},{"path":"https://docs.ropensci.org/ohun/reference/label_detection.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Label detections from a sound event detection procedure — label_detection","text":"","code":"{   # load data   data(\"lbh_reference\")    # an extra one in detection (1 false positive)   label_detection(reference = lbh_reference[-1, ], detection = lbh_reference)    # missing one in detection (all true positives)   label_detection(reference = lbh_reference, detection = lbh_reference[-1, ])    # perfect detection (all true positives)   label_detection(reference = lbh_reference, detection = lbh_reference)    # and extra sound file in reference (all true positives)   label_detection(     reference = lbh_reference, detection =       lbh_reference[lbh_reference$sound.files != \"lbh1.wav\", ]   )    # and extra sound file in detection (some false positives)   label_detection(     reference =       lbh_reference[lbh_reference$sound.files != \"lbh1.wav\", ],     detection = lbh_reference   )    # duplicate 1 detection row (to get 2 splits)   detec <- lbh_reference[c(1, seq_len(nrow(lbh_reference))), ]   detec$selec[1] <- 1.2   label_detection(     reference = lbh_reference,     detection = detec   )    # merge 2 detections (to get split and merge)   Y <- lbh_reference   Y$end[1] <- 1.2   label_detection(reference = lbh_reference, detection = Y)    # remove split to get only merge   Y <- Y[-2, ]   label_detection(reference = lbh_reference, detection = Y) } #> Object of class 'selection_table' #> * The output of the following call: #> label_detection(reference = lbh_reference, detection = Y) #>  #> Contains:  #> *  A selection table data frame with 18 rows and 9 columns: #> |sound.files | selec|  start|    end| bottom.freq| top.freq| #> |:-----------|-----:|------:|------:|-----------:|--------:| #> |lbh2.wav    |     1| 0.1092| 1.2000|      2.2954|   8.9382| #> |lbh2.wav    |     3| 1.2658| 1.3856|      2.2606|   9.0774| #> |lbh2.wav    |     4| 1.8697| 2.0053|      2.1911|   8.9035| #> |lbh2.wav    |     5| 2.4418| 2.5809|      2.1563|   8.6600| #> |lbh2.wav    |     6| 3.0368| 3.1689|      2.2259|   8.9382| #> |lbh2.wav    |     7| 3.6286| 3.7466|      2.3302|   8.6252| #> ... 3 more column(s) (detection.class, reference, overlap) #>  and 12 more row(s) #>  #> * A data frame (check.results) with 18 rows generated by check_sels() (as an attribute) #> created by warbleR < 1.1.21"},{"path":"https://docs.ropensci.org/ohun/reference/label_spectro.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot a labeled spectrogram — label_spectro","title":"Plot a labeled spectrogram — label_spectro","text":"label_spectro plot spectrogram along amplitude envelopes cross-correlation scores","code":""},{"path":"https://docs.ropensci.org/ohun/reference/label_spectro.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot a labeled spectrogram — label_spectro","text":"","code":"label_spectro(   wave,   reference = NULL,   detection = NULL,   envelope = FALSE,   threshold = NULL,   smooth = 5,   collevels = seq(-100, 0, 5),   palette = viridis::viridis,   template.correlation = NULL,   line.x.position = 2,   hop.size = NULL,   ... )"},{"path":"https://docs.ropensci.org/ohun/reference/label_spectro.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot a labeled spectrogram — label_spectro","text":"wave 'wave' class object. reference Data frame 'selection.table' (following warbleR package format) reference selections (start end sound events). Must contained least following columns: \"sound.files\", \"selec\", \"start\" \"end\". detection Data frame 'selection.table' detection (start end sound events) Must contained least following columns: \"sound.files\", \"selec\", \"start\" \"end\". envelope Logical control whether amplitude envelope plotted. Default FALSE. threshold numeric vector length 1 indicated amplitude correlation threshold plot envelope correlation scores respectively. Default NULL. Note amplitude range valid values 0-1, correlations range 0-100. smooth numeric vector length 1 smooth amplitude envelope sum smooth function. controls time range (ms) amplitude samples smoothed (.e. averaged neighboring samples). Default 5. 0 means smoothing applied. collevels Numeric sequence negative numbers control color partitioning amplitude values shown (spectro). palette Function color palette used spectrogram (spectro) template.correlation List extracted output template_correlator containing correlation scores metadata specific sound file/template dyad. instance 'correlations[[1]]' 'correlations' output template_correlator call. supplied correlation also plotted. Default NULL. line.x.position Numeric vector length 1 position frequency axis (kHz) lines highlighting sound events. Default 2. hop.size numeric vector length 1 specifying time window duration (ms). Default 11.6 ms, equivalent 512 'wl' 44.1 kHz sampling rate. ... Additional arguments passed  spectro spectrogram customization.","code":""},{"path":"https://docs.ropensci.org/ohun/reference/label_spectro.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot a labeled spectrogram — label_spectro","text":"spectrogram along lines highlighting position sound events 'reference' /'detection'. supplied also plot amplitude envelope corelation scores spectrogram.","code":""},{"path":"https://docs.ropensci.org/ohun/reference/label_spectro.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot a labeled spectrogram — label_spectro","text":"function plots spectrograms annotated position sound events. Created graphs included vignette, probably useful short recordings. works single 'wave' object time.","code":""},{"path":"https://docs.ropensci.org/ohun/reference/label_spectro.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Plot a labeled spectrogram — label_spectro","text":"#'  Araya-Salas, M., Smith-Vidaurre, G., Chaverri, G., Brenes, J. C., Chirino, F., Elizondo-Calvo, J., & Rico-Guevara, . (2023). ohun: R package diagnosing optimizing automatic sound event detection. Methods Ecology Evolution, 14, 2259–2271. https://doi.org/10.1111/2041-210X.14170","code":""},{"path":[]},{"path":"https://docs.ropensci.org/ohun/reference/label_spectro.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Plot a labeled spectrogram — label_spectro","text":"Marcelo Araya-Salas (marcelo.araya@ucr.ac.cr).","code":""},{"path":"https://docs.ropensci.org/ohun/reference/label_spectro.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot a labeled spectrogram — label_spectro","text":"","code":"{   # load example data   data(list = \"lbh1\", \"lbh_reference\")    # adding labels   label_spectro(     wave = lbh1,     reference = lbh_reference[lbh_reference$sound.files == \"lbh1.wav\", ],     wl = 200, ovlp = 50, flim = c(1, 10)   )    # adding envelope   label_spectro(     wave = lbh1,     detection = lbh_reference[lbh_reference$sound.files == \"lbh1.wav\", ],     wl = 200, ovlp = 50, flim = c(1, 10)   )    # see the package vignette for more examples }"},{"path":"https://docs.ropensci.org/ohun/reference/lbh1.html","id":null,"dir":"Reference","previous_headings":"","what":"Long-billed hermit recording — lbh1","title":"Long-billed hermit recording — lbh1","text":"lbh1 wave object long-billed hermit (Phaethornis longirostris) songs extracted xeno-canto's '154138' recording.","code":""},{"path":"https://docs.ropensci.org/ohun/reference/lbh1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Long-billed hermit recording — lbh1","text":"","code":"data(lbh1)"},{"path":"https://docs.ropensci.org/ohun/reference/lbh1.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Long-billed hermit recording — lbh1","text":"object class Wave length 110250.","code":""},{"path":"https://docs.ropensci.org/ohun/reference/lbh1.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Long-billed hermit recording — lbh1","text":"Marcelo Araya-Salas","code":""},{"path":"https://docs.ropensci.org/ohun/reference/lbh2.html","id":null,"dir":"Reference","previous_headings":"","what":"Long-billed hermit recording — lbh2","title":"Long-billed hermit recording — lbh2","text":"lbh2  wave object long-billed hermit (Phaethornis longirostris) songs extracted xeno-canto's '154129' recording.","code":""},{"path":"https://docs.ropensci.org/ohun/reference/lbh2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Long-billed hermit recording — lbh2","text":"","code":"data(lbh2)"},{"path":"https://docs.ropensci.org/ohun/reference/lbh2.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Long-billed hermit recording — lbh2","text":"object class Wave length 110250.","code":""},{"path":"https://docs.ropensci.org/ohun/reference/lbh2.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Long-billed hermit recording — lbh2","text":"Marcelo Araya-Salas","code":""},{"path":"https://docs.ropensci.org/ohun/reference/lbh_reference.html","id":null,"dir":"Reference","previous_headings":"","what":"Example data frame of a selection table including all sound events of interests — lbh_reference","title":"Example data frame of a selection table including all sound events of interests — lbh_reference","text":"lbh_reference data frame containing start, end, bottom top frequency songs 'lbh_1.wav' 'lbh_2.wav' recordings.","code":""},{"path":"https://docs.ropensci.org/ohun/reference/lbh_reference.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Example data frame of a selection table including all sound events of interests — lbh_reference","text":"","code":"data(lbh_reference)"},{"path":"https://docs.ropensci.org/ohun/reference/lbh_reference.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Example data frame of a selection table including all sound events of interests — lbh_reference","text":"data frame 19 rows 6 variables: sound.files recording names selec selection numbers within recording start start times selected sound event end end times selected sound event bottom.freq lower limit frequency range top.freq upper limit frequency range","code":""},{"path":"https://docs.ropensci.org/ohun/reference/lbh_reference.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Example data frame of a selection table including all sound events of interests — lbh_reference","text":"Marcelo Araya-Salas, ohun","code":""},{"path":"https://docs.ropensci.org/ohun/reference/lbh_reference.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Example data frame of a selection table including all sound events of interests — lbh_reference","text":"data frame containing start, end, low high frequency Phaethornis longirostris (Long-billed Hermit) songs 2 example sound files included package ('lbh_1' 'lbh_2'). two files clips extracted xeno-canto's '154138' '154129' recordings respectively.","code":""},{"path":"https://docs.ropensci.org/ohun/reference/merge_overlaps.html","id":null,"dir":"Reference","previous_headings":"","what":"Merge overlapping selections — merge_overlaps","title":"Merge overlapping selections — merge_overlaps","text":"merge_overlaps merges several overlapping selections single selection","code":""},{"path":"https://docs.ropensci.org/ohun/reference/merge_overlaps.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Merge overlapping selections — merge_overlaps","text":"","code":"merge_overlaps(X, pb = TRUE, cores = 1)"},{"path":"https://docs.ropensci.org/ohun/reference/merge_overlaps.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Merge overlapping selections — merge_overlaps","text":"X Data frame 'selection.table' (following warbleR package format) selections (start end sound events). Must contained least following columns: \"sound.files\", \"selec\", \"start\" \"end\". pb Logical argument control progress bar. Default TRUE. cores Numeric. Controls whether parallel computing applied. specifies number cores used. Default 1 (.e. parallel computing).","code":""},{"path":"https://docs.ropensci.org/ohun/reference/merge_overlaps.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Merge overlapping selections — merge_overlaps","text":"time-overlapping selection found returns data frame overlapping selections collapse single selection.","code":""},{"path":"https://docs.ropensci.org/ohun/reference/merge_overlaps.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Merge overlapping selections — merge_overlaps","text":"function finds time-overlapping selection reference tables collapses single selection. can useful prepare reference tables used energy detection routine. cases overlapping selections expected detected single sound. Therefore, merging can useful prepare references format representing realistic expectation perfect energy detection routine look like.","code":""},{"path":"https://docs.ropensci.org/ohun/reference/merge_overlaps.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Merge overlapping selections — merge_overlaps","text":"Araya-Salas, M., Smith-Vidaurre, G., Chaverri, G., Brenes, J. C., Chirino, F., Elizondo-Calvo, J., & Rico-Guevara, . (2023). ohun: R package diagnosing optimizing automatic sound event detection. Methods Ecology Evolution, 14, 2259–2271. https://doi.org/10.1111/2041-210X.14170","code":""},{"path":[]},{"path":"https://docs.ropensci.org/ohun/reference/merge_overlaps.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Merge overlapping selections — merge_overlaps","text":"Marcelo Araya-Salas marcelo.araya@ucr.ac.cr)","code":""},{"path":"https://docs.ropensci.org/ohun/reference/merge_overlaps.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Merge overlapping selections — merge_overlaps","text":"","code":"{   # load data   data(\"lbh_reference\")    # nothing to merge   merge_overlaps(lbh_reference)    # create artificial overlapping selections   lbh_ref2 <- rbind(as.data.frame(lbh_reference[c(3, 10), ]), lbh_reference[c(3, 10), ])    lbh_ref2$selec <- seq_len(nrow(lbh_ref2))    merge_overlaps(lbh_ref2) } #> No overlapping selections were found #> 4 selections overlapped #>   sound.files selec    start       end bottom.freq top.freq #> 1    lbh1.wav     2 0.088118 0.2360047      1.9824   8.4861 #> 2    lbh2.wav     1 1.265850 1.3855678      2.2606   9.0774"},{"path":"https://docs.ropensci.org/ohun/reference/ohun.html","id":null,"dir":"Reference","previous_headings":"","what":"ohun: Optimizing sound event detection — ohun","title":"ohun: Optimizing sound event detection — ohun","text":"ohun intended facilitate automated detection sound events, providing functions diagnose optimize detection routines. Detections software can also explored optimized.","code":""},{"path":"https://docs.ropensci.org/ohun/reference/ohun.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"ohun: Optimizing sound event detection — ohun","text":"main features package : use reference annotations detection optimization diagnostic use signal detection theory diagnostic parameters evaluate detection performance batch processing sound files improve computational performance package offers functions : Energy-based detection Template-based detection Diagnose detection precision Improve detection adjusting parameters optimize accuracy functions allow parallelization tasks, distributes tasks among several processors improve computational efficiency. package works sound files '.wav', '.mp3', '.flac' '.wac' format. License: GPL (>= 2)","code":""},{"path":[]},{"path":"https://docs.ropensci.org/ohun/reference/ohun.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"ohun: Optimizing sound event detection — ohun","text":"Marcelo Araya-Salas Maintainer: Marcelo Araya-Salas (marcelo.araya@ucr.ac.cr)","code":""},{"path":"https://docs.ropensci.org/ohun/reference/optimize_energy_detector.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimize energy-based sound event detection — optimize_energy_detector","title":"Optimize energy-based sound event detection — optimize_energy_detector","text":"Optimize energy-based sound event detection different correlation threshold values","code":""},{"path":"https://docs.ropensci.org/ohun/reference/optimize_energy_detector.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimize energy-based sound event detection — optimize_energy_detector","text":"","code":"optimize_energy_detector(   reference,   files = NULL,   threshold = 5,   peak.amplitude = 0,   hop.size = 11.6,   wl = NULL,   smooth = 5,   hold.time = 0,   min.duration = NULL,   max.duration = NULL,   thinning = 1,   cores = 1,   pb = TRUE,   by.sound.file = FALSE,   bp = NULL,   path = \".\",   previous.output = NULL,   envelopes = NULL,   macro.average = FALSE,   min.overlap = 0.5 )"},{"path":"https://docs.ropensci.org/ohun/reference/optimize_energy_detector.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimize energy-based sound event detection — optimize_energy_detector","text":"reference Selection table (using warbleR package's format, see selection_table) data frame columns sound file name (sound.files), selection number (selec), start end time sound event (start end). must contain reference selections used detection optimization. files Character vector indicating sound files analyzed. Optional.  supplied function work sound files 'reference'. can used include sound files target sound events. Supported file formats:'.wav', '.mp3', '.flac' '.wac'. supplied function work sound files (supported format) 'path'. threshold numeric vector specifying amplitude threshold detecting sound events (%). Default 5. Several values can supplied optimization. peak.amplitude Numeric vector length 1 minimum peak amplitude value. detection value excluded. Peak amplitude maximum sound pressure level (decibels) across sound event (see sound_pressure_level). can useful expecting higher peak amplitude target sound events compared non-target sound events keeping best examples target sound events (.e. high precision low recall). Default 0. Several values can supplied optimization. hop.size numeric vector length 1 specifying time window duration (ms). Default 11.6 ms, equivalent 512 wl 44.1 kHz sampling rate. Ignored 'wl' supplied. wl numeric vector length 1 specifying window length spectrogram. Default NULL. supplied, 'hop.size' ignored. Used internally bandpass filtering (applied 'bp' supplied). smooth numeric vector length 1 smooth amplitude envelope sum smooth function. controls time 'neighborhood' (ms) amplitude samples smoothed (.e. averaged neighboring samples). Default 5. 0 means smoothing applied. Note smoothing applied thinning (see 'thinning' argument). function  envelope used internally analogous sum smoothing env. argument used internally get_envelopes. Several values can supplied optimization. hold.time Numeric vector length 1. Specifies time range (ms) selections merged (.e. 2 selections separated less specified 'hold.time' merged single selection). Default 0 (hold time applied). Several values can supplied optimization. min.duration Numeric vector giving shortest duration (ms) sound events detected. removes sound events threshold. Several values can supplied optimization. max.duration Numeric vector giving longest duration (ms) sound events detected. removes sound events threshold. Several values can supplied optimization. thinning Numeric vector range 0~1 indicating proportional reduction number samples used represent amplitude envelopes (.e. thinning envelopes). Usually amplitude envelopes many samples needed accurately represent amplitude variation time, affects size output (usually large R objects / files). Default  1 (thinning). Higher sampling rates may afford higher size reduction (e.g. lower thinning values). Reduction conducted interpolation using approx. Note thinning may decrease time precision, higher thinning less precise time detection. Several values can supplied optimization. cores Numeric. Controls whether parallel computing applied. specifies number cores used. Default 1 (.e. parallel computing). pb Logical argument control progress bar messages. Default TRUE. .sound.file Logical argument control whether performance diagnostics summarized across sound files (.sound.file = FALSE 1 sound file included 'reference') shown separated sound file. Default FALSE. bp Numeric vector length 2 giving lower upper limits frequency bandpass filter (kHz). Default NULL.  argument used internally get_envelopes. used 'envelopes' supplied. Bandpass done using function ffilter, applies short-term Fourier transformation first create spectrogram target frequencies filtered back transformed wave object using reverse Fourier transformation. path Character string containing directory path sound files located. current working directory used default. previous.output Data frame output previous run function. used include previous results new output avoid recalculating detection performance parameter combinations previously evaluated. envelopes object class 'envelopes' (generated get_envelopes) containing amplitude envelopes sound files analyzed. 'files' 'envelopes' supplied function work supported format sound files working directory. macro.average Logical argument control diagnostics first calculated sound file averaged across sound files, can minimize effect unbalanced sample sizes sound files. FALSE (default) diagnostics based aggregated statistics irrespective sound files. following indices can estimated macro-averaging: overlap, mean.duration.true.positives, mean.duration.false.positives, mean.duration.false.positives, mean.duration.false.negatives, proportional.duration.true.positives, recall precision (f.score always derived recall precision). Note applying macro-averaging, recall precision derived true positive, false positive false negative values returned function. min.overlap Numeric. Controls minimum amount overlap required detection reference sound counted true positive. Default 0.5. Overlap measured intersection union.","code":""},{"path":"https://docs.ropensci.org/ohun/reference/optimize_energy_detector.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimize energy-based sound event detection — optimize_energy_detector","text":"data frame row shows result detection job particular combination tuning parameters (including data frame). also includes following diagnostic metrics: true.positives: number sound events 'reference' correspond detection. Matching defined degree overlap time. perfect detection routine equal number rows 'reference'. false.positives: number detections match sound events 'reference'. perfect detection routine 0. false.negatives: number sound events 'reference' detected (found 'detection'. perfect detection routine 0. splits: number detections overlapping reference sounds also overlap detections. perfect detection routine 0. merges: number detections overlap two reference sounds. perfect detection routine 0. mean.duration.true.positives: mean duration true positives (ms). included time.diagnostics = TRUE. mean.duration.false.positives: mean duration false positives (ms). included time.diagnostics = TRUE. mean.duration.false.negatives: mean duration false negatives (ms). included time.diagnostics = TRUE. overlap: mean intersection union overlap true positives. proportional.duration.true.positives: ratio duration true positives th duration sound events 'reference'. perfect detection routine 1. Based true positives split merged. included time.diagnostics = TRUE. duty.cycle: proportion sound file sounds detected. included time.diagnostics = TRUE path supplied. recall: Proportion sound events 'reference' detected. perfect detection routine 1. precision: Proportion detections correspond sound events 'reference'. perfect detection routine 1.","code":""},{"path":"https://docs.ropensci.org/ohun/reference/optimize_energy_detector.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Optimize energy-based sound event detection — optimize_energy_detector","text":"function takes selections data frame 'selection_table' ('reference') estimates detection performance energy detector different detection parameter combinations. done comparing position time detection reference selections 'reference'. function returns several diagnostic metrics allow user determine parameter values provide detection closely matches selections 'reference'. parameters can later used performing efficient detection using energy_detector.","code":""},{"path":"https://docs.ropensci.org/ohun/reference/optimize_energy_detector.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Optimize energy-based sound event detection — optimize_energy_detector","text":"Araya-Salas, M., Smith-Vidaurre, G., Chaverri, G., Brenes, J. C., Chirino, F., Elizondo-Calvo, J., & Rico-Guevara, . (2023). ohun: R package diagnosing optimizing automatic sound event detection. Methods Ecology Evolution, 14, 2259–2271. https://doi.org/10.1111/2041-210X.14170","code":""},{"path":"https://docs.ropensci.org/ohun/reference/optimize_energy_detector.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Optimize energy-based sound event detection — optimize_energy_detector","text":"Marcelo Araya-Salas (marcelo.araya@ucr.ac.cr).","code":""},{"path":"https://docs.ropensci.org/ohun/reference/optimize_energy_detector.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimize energy-based sound event detection — optimize_energy_detector","text":"","code":"# \\donttest{ # Save example files into temporary working directory data(\"lbh1\", \"lbh2\", \"lbh_reference\") tuneR::writeWave(lbh1, file.path(tempdir(), \"lbh1.wav\")) tuneR::writeWave(lbh2, file.path(tempdir(), \"lbh2.wav\"))  # using smoothing and minimum duration optimize_energy_detector(   reference = lbh_reference, path = tempdir(),   threshold = c(6, 10), smooth = 6.8, bp = c(2, 9), hop.size = 6.8,   min.duration = 90 ) #> 2 combinations will be evaluated: #>   threshold peak.amplitude smooth hold.time min.duration max.duration thinning #> 1         6              0    6.8         0           90          Inf        1 #> 2        10              0    6.8         0           90          Inf        1 #>   detections true.positives false.positives false.negatives splits merges #> 1         19             19               0               0      0      0 #> 2         19             19               0               0      0      0 #>     overlap mean.duration.true.positives mean.duration.false.positives #> 1 0.8526227                          164                            NA #> 2 0.9081851                          147                            NA #>   mean.duration.false.negatives proportional.duration.true.positives duty.cycle #> 1                            NA                             1.153234  0.3113362 #> 2                            NA                             1.032732  0.2789096 #>   recall precision f.score #> 1      1         1       1 #> 2      1         1       1  # with thinning and smoothing optimize_energy_detector(   reference = lbh_reference, path = tempdir(),   threshold = c(6, 10, 15), smooth = c(7, 10), thinning = c(0.1, 0.01),   bp = c(2, 9), hop.size = 6.8, min.duration = 90 ) #> 12 combinations will be evaluated: #>    threshold peak.amplitude smooth hold.time min.duration max.duration thinning #> 1          6              0      7         0           90          Inf     0.10 #> 2         10              0      7         0           90          Inf     0.10 #> 3         15              0      7         0           90          Inf     0.10 #> 4          6              0     10         0           90          Inf     0.10 #> 5         10              0     10         0           90          Inf     0.10 #> 6         15              0     10         0           90          Inf     0.10 #> 7          6              0      7         0           90          Inf     0.01 #> 8         10              0      7         0           90          Inf     0.01 #> 9         15              0      7         0           90          Inf     0.01 #> 10         6              0     10         0           90          Inf     0.01 #> 11        10              0     10         0           90          Inf     0.01 #> 12        15              0     10         0           90          Inf     0.01 #>    detections true.positives false.positives false.negatives splits merges #> 1          19             19               0               0      0      0 #> 2          19             19               0               0      0      0 #> 3          19             19               0               0      0      0 #> 4          19             19               0               0      0      0 #> 5          19             19               0               0      0      0 #> 6          19             19               0               0      0      0 #> 7          19             19               0               0      0      0 #> 8          19             19               0               0      0      0 #> 9          19             19               0               0      0      0 #> 10         19             19               0               0      0      0 #> 11         19             19               0               0      0      0 #> 12         19             19               0               0      0      0 #>      overlap mean.duration.true.positives mean.duration.false.positives #> 1  0.8494709                          165                            NA #> 2  0.9065211                          147                            NA #> 3  0.9227890                          136                            NA #> 4  0.8300895                          169                            NA #> 5  0.9018598                          149                            NA #> 6  0.9192277                          139                            NA #> 7  0.8265783                          164                            NA #> 8  0.8872974                          149                            NA #> 9  0.9075075                          137                            NA #> 10 0.8103066                          171                            NA #> 11 0.8863643                          150                            NA #> 12 0.9044356                          140                            NA #>    mean.duration.false.negatives proportional.duration.true.positives #> 1                             NA                            1.1573464 #> 2                             NA                            1.0337601 #> 3                             NA                            0.9542338 #> 4                             NA                            1.1921639 #> 5                             NA                            1.0501397 #> 6                             NA                            0.9780232 #> 7                             NA                            1.1575802 #> 8                             NA                            1.0474697 #> 9                             NA                            0.9631188 #> 10                            NA                            1.2023828 #> 11                            NA                            1.0558039 #> 12                            NA                            0.9802918 #>    duty.cycle recall precision f.score #> 1   0.3125000      1         1       1 #> 2   0.2792090      1         1       1 #> 3   0.2581187      1         1       1 #> 4   0.3218886      1         1       1 #> 5   0.2836085      1         1       1 #> 6   0.2642870      1         1       1 #> 7   0.3124432      1         1       1 #> 8   0.2829246      1         1       1 #> 9   0.2602180      1         1       1 #> 10  0.3247048      1         1       1 #> 11  0.2851953      1         1       1 #> 12  0.2647593      1         1       1  # by sound file (opt_ed <- optimize_energy_detector(   reference = lbh_reference,   path = tempdir(), threshold = c(6, 10, 15), smooth = 6.8, bp = c(2, 9),   hop.size = 6.8, min.duration = 90, by.sound.file = TRUE )) #> 3 combinations will be evaluated: #>   sound.files threshold peak.amplitude smooth hold.time min.duration #> 1    lbh2.wav         6              0    6.8         0           90 #> 2    lbh1.wav         6              0    6.8         0           90 #> 3    lbh2.wav        10              0    6.8         0           90 #> 4    lbh1.wav        10              0    6.8         0           90 #> 5    lbh2.wav        15              0    6.8         0           90 #> 6    lbh1.wav        15              0    6.8         0           90 #>   max.duration thinning detections true.positives false.positives #> 1          Inf        1          9              9               0 #> 2          Inf        1         10             10               0 #> 3          Inf        1          9              9               0 #> 4          Inf        1         10             10               0 #> 5          Inf        1          9              9               0 #> 6          Inf        1         10             10               0 #>   false.negatives splits merges mean.duration.true.positives #> 1               0      0      0                          159 #> 2               0      0      0                          168 #> 3               0      0      0                          142 #> 4               0      0      0                          151 #> 5               0      0      0                          128 #> 6               0      0      0                          142 #>   mean.duration.false.positives mean.duration.false.negatives   overlap #> 1                            NA                            NA 0.8044589 #> 2                            NA                            NA 0.8959702 #> 3                            NA                            NA 0.8747964 #> 4                            NA                            NA 0.9382350 #> 5                            NA                            NA 0.9221066 #> 6                            NA                            NA 0.9235634 #>   proportional.duration.true.positives duty.cycle recall precision f.score #> 1                            1.2125978  0.2869232      1         1       1 #> 2                            1.0998059  0.3357491      1         1       1 #> 3                            1.0803862  0.2556395      1         1       1 #> 4                            0.9898431  0.3021796      1         1       1 #> 5                            0.9759279  0.2309227      1         1       1 #> 6                            0.9322323  0.2845922      1         1       1  # summarize summarize_diagnostic(opt_ed) #>   threshold peak.amplitude smooth hold.time min.duration max.duration thinning #> 1         6              0    6.8         0           90          Inf        1 #> 2        10              0    6.8         0           90          Inf        1 #> 3        15              0    6.8         0           90          Inf        1 #>   detections true.positives false.positives false.negatives splits merges #> 1         19             19               0               0      0      0 #> 2         19             19               0               0      0      0 #> 3         19             19               0               0      0      0 #>     overlap recall precision f.score #> 1 0.8526227      1         1       1 #> 2 0.9081851      1         1       1 #> 3 0.9228733      1         1       1  # using hold time (op_ed <- optimize_energy_detector(   reference = lbh_reference,   threshold = 10, hold.time = c(100, 150), bp = c(2, 9), hop.size = 6.8,   path = tempdir() )) #> 2 combinations will be evaluated: #>   threshold peak.amplitude smooth hold.time min.duration max.duration thinning #> 1        10              0      5       100         -Inf          Inf        1 #> 2        10              0      5       150         -Inf          Inf        1 #>   detections true.positives false.positives false.negatives splits merges #> 1         19             19               0               0      0      0 #> 2         19             19               0               0      0      0 #>     overlap mean.duration.true.positives mean.duration.false.positives #> 1 0.8774537                          152                            NA #> 2 0.8774537                          152                            NA #>   mean.duration.false.negatives proportional.duration.true.positives duty.cycle #> 1                            NA                              1.06869  0.2890185 #> 2                            NA                              1.06869  0.2890185 #>   recall precision f.score #> 1      1         1       1 #> 2      1         1       1  # including previous output in new call optimize_energy_detector(   reference = lbh_reference, threshold = 10,   hold.time = c(50, 200), previous.output = op_ed, smooth = 6.8,   bp = c(2, 9), hop.size = 7, path = tempdir() ) #> 2 combinations will be evaluated: #>   threshold peak.amplitude smooth hold.time min.duration max.duration thinning #> 1        10              0    5.0       100         -Inf          Inf        1 #> 2        10              0    5.0       150         -Inf          Inf        1 #> 3        10              0    6.8        50         -Inf          Inf        1 #> 4        10              0    6.8       200         -Inf          Inf        1 #>   detections true.positives false.positives false.negatives splits merges #> 1         19             19               0               0      0      0 #> 2         19             19               0               0      0      0 #> 3         20             19               1               0      0      0 #> 4         19             19               0               0      0      0 #>     overlap mean.duration.true.positives mean.duration.false.positives #> 1 0.8774537                          152                            NA #> 2 0.8774537                          152                            NA #> 3 0.8897689                          150                             2 #> 4 0.8763392                          153                            NA #>   mean.duration.false.negatives proportional.duration.true.positives duty.cycle #> 1                            NA                             1.068690  0.2890185 #> 2                            NA                             1.068690  0.2890185 #> 3                            NA                             1.056741  0.2855536 #> 4                            NA                             1.074756  0.2905922 #>   recall precision  f.score #> 1      1      1.00 1.000000 #> 2      1      1.00 1.000000 #> 3      1      0.95 0.974359 #> 4      1      1.00 1.000000  # having and extra file in files (simulating a file that should have no detetions) sub_reference <- lbh_reference[lbh_reference$sound.files != \"lbh1.wav\", ]  optimize_energy_detector(   reference = sub_reference, files = unique(lbh_reference$sound.files),   threshold = 10, hold.time = c(1, 150), bp = c(2, 9), smooth = 6.8,   hop.size = 7, path = tempdir() ) #> 2 combinations will be evaluated: #>   threshold peak.amplitude smooth hold.time min.duration max.duration thinning #> 1        10              0    6.8         1         -Inf          Inf        1 #> 2        10              0    6.8       150         -Inf          Inf        1 #>   detections true.positives false.positives false.negatives splits merges #> 1         28              9              19               0      0      0 #> 2         19              9              10               0      0      0 #>     overlap mean.duration.true.positives mean.duration.false.positives #> 1 0.8677330                          143                             2 #> 2 0.8543355                          146                            NA #>   mean.duration.false.negatives proportional.duration.true.positives duty.cycle #> 1                            NA                             1.089011  0.2829051 #> 2                            NA                             1.106874  0.2905922 #>   recall precision   f.score #> 1      1 0.3214286 0.4864865 #> 2      1 0.4736842 0.6428571 # }"},{"path":"https://docs.ropensci.org/ohun/reference/optimize_template_detector.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimize acoustic template detection — optimize_template_detector","title":"Optimize acoustic template detection — optimize_template_detector","text":"optimize_template_detector optimizes acoustic template detection","code":""},{"path":"https://docs.ropensci.org/ohun/reference/optimize_template_detector.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimize acoustic template detection — optimize_template_detector","text":"","code":"optimize_template_detector(   template.correlations,   reference,   threshold,   cores = 1,   pb = TRUE,   by.sound.file = FALSE,   previous.output = NULL,   macro.average = FALSE,   min.overlap = 0.5 )"},{"path":"https://docs.ropensci.org/ohun/reference/optimize_template_detector.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimize acoustic template detection — optimize_template_detector","text":"template.correlations object class 'template_correlations' (generated template_correlator) optimize detections. Must contain data sound files 'reference'. can also contain data additional sound files. case routine assumes sound events found files, detection files false positives. reference Data frame 'selection.table' (following warbleR package format) reference selections (start end sound events) used evaluate performance detection, represented selections 'detection'. Must contained least following columns: \"sound.files\", \"selec\", \"start\" \"end\". must contain reference selections used detection optimization. threshold Numeric vector length > 1 values 0 1 specifying correlation threshold detecting sound event occurrences (.e. correlation peaks). Must supplied. Several values supplied optimization. cores Numeric. Controls whether parallel computing applied. specifies number cores used. Default 1 (.e. parallel computing). pb Logical argument control progress bar messages. Default TRUE. .sound.file Logical control diagnostics calculated sound file independently (TRUE) sound files combined (FALSE, default). previous.output Data frame output previous run function. used include previous results new output avoid recalculating detection performance parameter combinations previously evaluated. macro.average Logical argument control diagnostics first calculated sound file averaged across sound files, can minimize effect unbalanced sample sizes sound files. FALSE (default) diagnostics based aggregated statistics irrespective sound files. following indices can estimated macro-averaging: overlap, mean.duration.true.positives, mean.duration.false.positives, mean.duration.false.positives, mean.duration.false.negatives, proportional.duration.true.positives, recall precision (f.score always derived recall precision). Note applying macro-averaging, recall precision derived true positive, false positive false negative values returned function. min.overlap Numeric. Controls minimum amount overlap required detection reference sound counted true positive. Default 0.5. Overlap measured intersection union.","code":""},{"path":"https://docs.ropensci.org/ohun/reference/optimize_template_detector.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimize acoustic template detection — optimize_template_detector","text":"data frame row shows result detection job cutoff value, including following diagnostic metrics: true.positives: number sound events 'reference' correspond detection. Matching defined degree overlap time. perfect detection routine equal number rows 'reference'. false.positives: number detections match sound events 'reference'. perfect detection routine 0. false.negatives: number sound events 'reference' detected (found 'detection'. perfect detection routine 0. splits: number detections overlapping reference sounds also overlap detections. perfect detection routine 0. merges: number sound events 'detection' overlap one sound event 'reference'. perfect detection routine 0. recall: Proportion sound events 'reference' detected. perfect detection routine 1. precision: Proportion detections correspond sound events 'reference' detected. perfect detection routine 1.","code":""},{"path":"https://docs.ropensci.org/ohun/reference/optimize_template_detector.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Optimize acoustic template detection — optimize_template_detector","text":"function takes reference data frame 'selection_table' ('X') output template_correlator estimates detection performance different detection parameter combinations. done comparing position time detection reference selections. function returns several diagnostic metrics allow user determine parameter values provide detection closely matches selections 'reference'. parameters can later used performing efficient detection using template_detector. Supported file formats:'.wav', '.mp3', '.flac' '.wac'.","code":""},{"path":"https://docs.ropensci.org/ohun/reference/optimize_template_detector.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Optimize acoustic template detection — optimize_template_detector","text":"Araya-Salas, M., Smith-Vidaurre, G., Chaverri, G., Brenes, J. C., Chirino, F., Elizondo-Calvo, J., & Rico-Guevara, . (2023). ohun: R package diagnosing optimizing automatic sound event detection. Methods Ecology Evolution, 14, 2259–2271. https://doi.org/10.1111/2041-210X.14170","code":""},{"path":[]},{"path":"https://docs.ropensci.org/ohun/reference/optimize_template_detector.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Optimize acoustic template detection — optimize_template_detector","text":"Marcelo Araya-Salas (marcelo.araya@ucr.ac.cr).","code":""},{"path":"https://docs.ropensci.org/ohun/reference/optimize_template_detector.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimize acoustic template detection — optimize_template_detector","text":"","code":"{ # Save sound files to temporary working directory data(\"lbh1\", \"lbh2\", \"lbh_reference\") tuneR::writeWave(lbh1, file.path(tempdir(), \"lbh1.wav\")) tuneR::writeWave(lbh2, file.path(tempdir(), \"lbh2.wav\"))  # template for the second sound file in 'lbh_reference' templ <- lbh_reference[11, ]  # generate template correlations tc <- template_correlator(templates = templ, path = tempdir(), files = \"lbh2.wav\")  # using 2 threshold optimize_template_detector(template.correlations = tc, reference = lbh_reference[lbh_reference$sound.files == \"lbh2.wav\", ], threshold = c(0.2, 0.5))  # using several thresholds optimize_template_detector(template.correlations = tc, reference = lbh_reference[lbh_reference$sound.files == \"lbh2.wav\", ],  threshold = seq(0.5, 0.9, by = 0.05))   # template for the first and second sound file in 'lbh_reference'  templ <- lbh_reference[c(1, 11), ]   # generate template correlations  tc <- template_correlator(templates = templ, path = tempdir(),  files = c(\"lbh1.wav\", \"lbh2.wav\"))  optimize_template_detector(template.correlations = tc, reference =   lbh_reference, threshold = seq(0.5, 0.7, by = 0.1))   # showing diagnostics by sound file  optimize_template_detector(template.correlations = tc, reference =  lbh_reference,  threshold = seq(0.5, 0.7, by = 0.1), by.sound.file = TRUE) } #> 2 thresholds will be evaluated: #> 9 thresholds will be evaluated: #> 3 thresholds will be evaluated: #> 3 thresholds will be evaluated: #>    threshold sound.files   templates detections true.positives false.positives #> 1        0.5    lbh2.wav  lbh2.wav-1          9              9               0 #> 2        0.5    lbh1.wav  lbh2.wav-1          0              0               0 #> 3        0.5    lbh1.wav lbh1.wav-11         10             10               0 #> 4        0.5    lbh2.wav lbh1.wav-11          0              0               0 #> 5        0.6    lbh2.wav  lbh2.wav-1          9              9               0 #> 6        0.6    lbh1.wav  lbh2.wav-1          0              0               0 #> 7        0.6    lbh1.wav lbh1.wav-11         10             10               0 #> 8        0.6    lbh2.wav lbh1.wav-11          0              0               0 #> 9        0.7    lbh2.wav  lbh2.wav-1          7              7               0 #> 10       0.7    lbh1.wav  lbh2.wav-1          0              0               0 #> 11       0.7    lbh1.wav lbh1.wav-11          4              4               0 #> 12       0.7    lbh2.wav lbh1.wav-11          0              0               0 #>    false.negatives splits merges   overlap    recall precision   f.score #> 1                0      0      0 0.8562007 1.0000000         1 1.0000000 #> 2               10     NA     NA        NA 0.0000000         0 0.0000000 #> 3                0      0      0 0.8917651 1.0000000         1 1.0000000 #> 4                9     NA     NA        NA 0.0000000         0 0.0000000 #> 5                0      0      0 0.8562007 1.0000000         1 1.0000000 #> 6               10     NA     NA        NA 0.0000000         0 0.0000000 #> 7                0      0      0 0.8917651 1.0000000         1 1.0000000 #> 8                9     NA     NA        NA 0.0000000         0 0.0000000 #> 9                2      0      0 0.8436591 0.7777778         1 0.8750000 #> 10              10     NA     NA        NA 0.0000000         0 0.0000000 #> 11               6      0      0 0.9326121 0.4000000         1 0.5714286 #> 12               9     NA     NA        NA 0.0000000         0 0.0000000"},{"path":"https://docs.ropensci.org/ohun/reference/plot_detection.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot detection and reference annotations — plot_detection","title":"Plot detection and reference annotations — plot_detection","text":"plot_detection evaluates performance sound event detection procedure comparing output selection table reference selection table","code":""},{"path":"https://docs.ropensci.org/ohun/reference/plot_detection.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot detection and reference annotations — plot_detection","text":"","code":"plot_detection(   reference,   detection,   mid.point = FALSE,   size = 20,   positions = c(1, 2) )"},{"path":"https://docs.ropensci.org/ohun/reference/plot_detection.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot detection and reference annotations — plot_detection","text":"reference Data frame 'selection.table' (following warbleR package format) reference selections (start end sound events) used evaluate performance detection, represented selections 'detection'. Must contained least following columns: \"sound.files\", \"selec\", \"start\" \"end\". must contain reference selections used detection optimization. detection Data frame 'selection.table' detections (start end sound events) compared 'reference' selections. Must contained least following columns: \"sound.files\", \"selec\", \"start\" \"end\". can contain data additional sound files found 'references'. case routine assumes sound events found files, detection files false positives. mid.point Logical argument control annotations shown rectangle fix width center mid point time position (TRUE) true time range annotations used (FALSE,  default). 'mid.point' can useful make visible annotations long sound files otherwise look thin. size Numeric. Controls size rectangles mid.point = TRUE. Default 20. positions Numeric. Controls vertical position rectangles representing anotations. Default c(1, 2). can used get reference detection annotations closer vertical axis. Note height rectangles 0.5.","code":""},{"path":"https://docs.ropensci.org/ohun/reference/plot_detection.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot detection and reference annotations — plot_detection","text":"ggplot graph (.e. object class \"ggplot\").","code":""},{"path":"https://docs.ropensci.org/ohun/reference/plot_detection.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot detection and reference annotations — plot_detection","text":"function helps visualize match reference detection annotations plotting next rectangles along time axis. annotations contain data several sound files sound file plotted panel. plot can modify users using regular ggplot syntax.","code":""},{"path":"https://docs.ropensci.org/ohun/reference/plot_detection.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Plot detection and reference annotations — plot_detection","text":"Araya-Salas, M., Smith-Vidaurre, G., Chaverri, G., Brenes, J. C., Chirino, F., Elizondo-Calvo, J., & Rico-Guevara, . (2023). ohun: R package diagnosing optimizing automatic sound event detection. Methods Ecology Evolution, 14, 2259–2271. https://doi.org/10.1111/2041-210X.14170","code":""},{"path":[]},{"path":"https://docs.ropensci.org/ohun/reference/plot_detection.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Plot detection and reference annotations — plot_detection","text":"Marcelo Araya-Salas marcelo.araya@ucr.ac.cr)","code":""},{"path":"https://docs.ropensci.org/ohun/reference/plot_detection.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot detection and reference annotations — plot_detection","text":"","code":"{   # load data   data(\"lbh_reference\")    # mid point and regular size   plot_detection(     reference = lbh_reference[-14, ],     detection = lbh_reference[-1, ], mid.point = TRUE   )    # mid point and larger size   plot_detection(     reference = lbh_reference[-14, ],     detection = lbh_reference[-1, ], mid.point = TRUE, size = 25   )    # true time rectangles   plot_detection(     reference = lbh_reference[-14, ],     detection = lbh_reference[-1, ]   )    # use position to make reference and anotations overlap vertically   plot_detection(     reference = lbh_reference[-14, ],     detection = lbh_reference[-1, ], positions = c(1, 1.4)   )    # modified using ggplot   gg_pd <- plot_detection(     reference = lbh_reference[-14, ],     detection = lbh_reference[-1, ], positions = c(1, 1.4)   )    gg_pd + ggplot2::theme_classic(base_size = 25) }"},{"path":"https://docs.ropensci.org/ohun/reference/print.envelopes.html","id":null,"dir":"Reference","previous_headings":"","what":"Class 'envelopes': list of absolute amplitude envelopes — print.envelopes","title":"Class 'envelopes': list of absolute amplitude envelopes — print.envelopes","text":"Class absolute amplitude envelopes","code":""},{"path":"https://docs.ropensci.org/ohun/reference/print.envelopes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Class 'envelopes': list of absolute amplitude envelopes — print.envelopes","text":"","code":"# S3 method for class 'envelopes' print(x, ...)"},{"path":"https://docs.ropensci.org/ohun/reference/print.envelopes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Class 'envelopes': list of absolute amplitude envelopes — print.envelopes","text":"x Object class envelopes, generated get_envelopes. ... arguments passed methods. Ignored printing envelopes.","code":""},{"path":"https://docs.ropensci.org/ohun/reference/print.envelopes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Class 'envelopes': list of absolute amplitude envelopes — print.envelopes","text":"Prints summary object class 'envelopes'.","code":""},{"path":"https://docs.ropensci.org/ohun/reference/print.envelopes.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Class 'envelopes': list of absolute amplitude envelopes — print.envelopes","text":"object class envelopes created get_envelopes list sound files absolute amplitude envelopes metadata","code":""},{"path":[]},{"path":"https://docs.ropensci.org/ohun/reference/print.template_correlations.html","id":null,"dir":"Reference","previous_headings":"","what":"print method for class template_correlations — print.template_correlations","title":"print method for class template_correlations — print.template_correlations","text":"print method class template_correlations","code":""},{"path":"https://docs.ropensci.org/ohun/reference/print.template_correlations.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"print method for class template_correlations — print.template_correlations","text":"","code":"# S3 method for class 'template_correlations' print(x, ...)"},{"path":"https://docs.ropensci.org/ohun/reference/print.template_correlations.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"print method for class template_correlations — print.template_correlations","text":"x Object class template_correlations, generated template_correlator. ... arguments passed methods. Ignored printing 'template_correlations' class objects.","code":""},{"path":"https://docs.ropensci.org/ohun/reference/print.template_correlations.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"print method for class template_correlations — print.template_correlations","text":"Prints summary object class 'template_correlations'.","code":""},{"path":"https://docs.ropensci.org/ohun/reference/reassemble_detection.html","id":null,"dir":"Reference","previous_headings":"","what":"Reassemble annotations from clips — reassemble_detection","title":"Reassemble annotations from clips — reassemble_detection","text":"reassemble_detection reassembles detections made clips refer original sound files","code":""},{"path":"https://docs.ropensci.org/ohun/reference/reassemble_detection.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reassemble annotations from clips — reassemble_detection","text":"","code":"reassemble_detection(detection, Y, cores = 1, pb = TRUE)"},{"path":"https://docs.ropensci.org/ohun/reference/reassemble_detection.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reassemble annotations from clips — reassemble_detection","text":"detection Data frame selection table (using warbleR package's format, see selection_table) containing start end signals. Must contained least following columns: \"sound.files\", \"selec\", \"start\" \"end\". Y Data frame start end clips orignal sound files. Must contain column \"original.sound.files\", \"sound.files\" (clip files), \"start\" \"end\". cores Numeric. Controls whether parallel computing applied. specifies number cores used. Default 1 (.e. parallel computing). pb Logical argument control progress bar. Default TRUE.","code":""},{"path":"https://docs.ropensci.org/ohun/reference/reassemble_detection.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reassemble annotations from clips — reassemble_detection","text":"data frame annotations refering position detections original sound files.","code":""},{"path":"https://docs.ropensci.org/ohun/reference/reassemble_detection.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Reassemble annotations from clips — reassemble_detection","text":"working large sound files, can convenient split files smaller clips speed detection process (can done function split_acoustic_data). However, can make difficult interpret results, detections refer clips rather original sound files. function take detections made clips created split_acoustic_data, format information refer back original (unsplit) sound files.","code":""},{"path":"https://docs.ropensci.org/ohun/reference/reassemble_detection.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Reassemble annotations from clips — reassemble_detection","text":"Araya-Salas, M., Smith-Vidaurre, G., Chaverri, G., Brenes, J. C., Chirino, F., Elizondo-Calvo, J., & Rico-Guevara, . (2023). ohun: R package diagnosing optimizing automatic sound event detection. Methods Ecology Evolution, 14, 2259–2271. https://doi.org/10.1111/2041-210X.14170","code":""},{"path":[]},{"path":"https://docs.ropensci.org/ohun/reference/reassemble_detection.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Reassemble annotations from clips — reassemble_detection","text":"Marcelo Araya-Salas (marcelo.araya@ucr.ac.cr).","code":""},{"path":"https://docs.ropensci.org/ohun/reference/reassemble_detection.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reassemble annotations from clips — reassemble_detection","text":"","code":"{ # load example data data(\"lbh1\", \"lbh2\", \"lbh_reference\") tuneR::writeWave(lbh1, file.path(tempdir(), \"lbh1.wav\")) tuneR::writeWave(lbh2, file.path(tempdir(), \"lbh2.wav\"))   ## if X is a data frame ##### df_ref <- as.data.frame(lbh_reference)    # get split annotations split_df_ref <- split_acoustic_data(X = df_ref,  only.sels = TRUE, sgmt.dur = 1.5,   path = tempdir(), pb = FALSE,   files = c(\"lbh1.wav\", \"lbh2.wav\"))     # get clip information Y <- split_acoustic_data(sgmt.dur = 1.5,   path = tempdir(), pb = FALSE,  output.path = tempdir(), files = c(\"lbh1.wav\", \"lbh2.wav\"))     # reassemble annotations tc <- reassemble_detection(detection = split_df_ref,   Y = Y, pb = FALSE)  # start and end are the same as in the original unsplit data df_ref <- df_ref[order(df_ref$sound.files, df_ref$start), ] all(tc$end == df_ref$end) all(tc$start == df_ref$start)   ### if X is a selection table ## # split annotations and files split_lbh_reference <- split_acoustic_data(X = lbh_reference,   sgmt.dur = 1.5, path = tempdir(),  output.path = tempdir(),  files = c(\"lbh1.wav\", \"lbh2.wav\"))  # reassemble annotations tc <- reassemble_detection(detection = split_lbh_reference,    Y = attributes(split_lbh_reference)$clip.info)    # start and end are the same as in the original unsplit data lbh_reference <- lbh_reference[order(lbh_reference$sound.files, lbh_reference$start), ] all(tc$end == lbh_reference$end) all(tc$start == lbh_reference$start) } #> [1] TRUE"},{"path":"https://docs.ropensci.org/ohun/reference/split_acoustic_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Splits sound files and associated annotations — split_acoustic_data","title":"Splits sound files and associated annotations — split_acoustic_data","text":"split_acoustic_data splits sound files (corresponding selection tables) shorter clips","code":""},{"path":"https://docs.ropensci.org/ohun/reference/split_acoustic_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Splits sound files and associated annotations — split_acoustic_data","text":"","code":"split_acoustic_data(   path = \".\",   sgmt.dur = 10,   sgmts = NULL,   files = NULL,   cores = 1,   pb = TRUE,   only.sels = FALSE,   output.path = file.path(path, \"clips\"),   X = NULL )"},{"path":"https://docs.ropensci.org/ohun/reference/split_acoustic_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Splits sound files and associated annotations — split_acoustic_data","text":"path Directory path sound files found. current working directory used default. sgmt.dur Numeric. Duration (s) segments sound files split. Sound files shorter 'sgmt.dur' split. Ignored 'sgmts' supplied. sgmts Numeric. Number segments split sound file. supplied 'sgmt.dur' ignored. files Character vector indicating subset files split. Supported file formats:'.wav', '.mp3', '.flac' '.wac'. supplied function work sound files (supported format) 'path'. cores Numeric. Controls whether parallel computing applied. specifies number cores used. Default 1 (.e. parallel computing). pb Logical argument control progress bar. Default TRUE. used .sels Logical argument control data frame returned (wave files saved). Default FALSE. output.path Directory path output files saved. supplied subfolder called 'clips' created within supplied 'path'. X 'selection_table' object data frame columns sound file name (sound.files), selection number (selec), start end time signal (start end). supplied data frame/selection table modified reflect position selections new sound files. Note selections split 2 segments. deal , 'split.sels' column added data frame selection labeled 'split'. Default NULL.","code":""},{"path":"https://docs.ropensci.org/ohun/reference/split_acoustic_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Splits sound files and associated annotations — split_acoustic_data","text":"Wave files segment (e.g. clips) working directory (.sels = FALSE, named 'sound.file.name-#.wav'). Clips saved .wav format. 'X' supplied function returns data frame containing name original sound files (original.sound.files), name segments (sound.files) start end segments original files. 'X' supplied data frame position selections newly created clips returned instead. However, 'X' 'selection table' clips saved, data frame information position clips original sound files also returned attribute output selection table (\"clip.info\"). Output annotation data contains position annotations new clips, additional column, 'split.sels', inform users whether annotations split multiple clips ('split') (NA). split annotations 'selec' column contain original 'selec' id plus additional index (selec-index) users can still identify annotation splits came . Sound files 'path' referenced 'X' stil split. function may work properly short segments (< 1 s).","code":""},{"path":"https://docs.ropensci.org/ohun/reference/split_acoustic_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Splits sound files and associated annotations — split_acoustic_data","text":"function aims reduce size sound files order simplify processes limited sound file size (big files can manipulated, e.g. energy_detector).","code":""},{"path":"https://docs.ropensci.org/ohun/reference/split_acoustic_data.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Splits sound files and associated annotations — split_acoustic_data","text":"Araya-Salas, M., Smith-Vidaurre, G., Chaverri, G., Brenes, J. C., Chirino, F., Elizondo-Calvo, J., & Rico-Guevara, . (2023). ohun: R package diagnosing optimizing automatic sound event detection. Methods Ecology Evolution, 14, 2259–2271. https://doi.org/10.1111/2041-210X.14170","code":""},{"path":[]},{"path":"https://docs.ropensci.org/ohun/reference/split_acoustic_data.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Splits sound files and associated annotations — split_acoustic_data","text":"Marcelo Araya-Salas (marcelo.araya@ucr.ac.cr)","code":""},{"path":"https://docs.ropensci.org/ohun/reference/split_acoustic_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Splits sound files and associated annotations — split_acoustic_data","text":"","code":"{   # load data and save to temporary working directory   data(\"lbh1\", \"lbh2\")   tuneR::writeWave(lbh1, file.path(tempdir(), \"lbh1.wav\"))   tuneR::writeWave(lbh2, file.path(tempdir(), \"lbh2.wav\"))    # split files in 1 s files   split_acoustic_data(sgmt.dur = 1, path = tempdir(), files = c(\"lbh1.wav\", \"lbh2.wav\"))    # Check this folder   tempdir() } #> [1] \"/var/folders/y6/nj790rtn62lfktb1sh__79hc0000gn/T//Rtmpw4iTKj\""},{"path":"https://docs.ropensci.org/ohun/reference/summarize_acoustic_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarize information about file format in an acoustic data set — summarize_acoustic_data","title":"Summarize information about file format in an acoustic data set — summarize_acoustic_data","text":"summarize_acoustic_data summarizes information file format acoustic data set","code":""},{"path":"https://docs.ropensci.org/ohun/reference/summarize_acoustic_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarize information about file format in an acoustic data set — summarize_acoustic_data","text":"","code":"summarize_acoustic_data(path = \".\", digits = 2)"},{"path":"https://docs.ropensci.org/ohun/reference/summarize_acoustic_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarize information about file format in an acoustic data set — summarize_acoustic_data","text":"path Character string containing directory path sound files located. Default \".\" (current working directory). digits Numeric vector length 1 number decimals include. Default 2.","code":""},{"path":"https://docs.ropensci.org/ohun/reference/summarize_acoustic_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarize information about file format in an acoustic data set — summarize_acoustic_data","text":"function prints summary format files acoustic data set.","code":""},{"path":"https://docs.ropensci.org/ohun/reference/summarize_acoustic_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Summarize information about file format in an acoustic data set — summarize_acoustic_data","text":"function summarizes information file format acoustic data set. provides information number files, file formats, sampling rates, bit depts, channels, duration file size (MB). file format, sampling rate, bit depth number channels function includes information number files format (e.g. '44.1 kHz (2)' means 2 files sampling rate 44.1 kHz).","code":""},{"path":"https://docs.ropensci.org/ohun/reference/summarize_acoustic_data.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Summarize information about file format in an acoustic data set — summarize_acoustic_data","text":"Araya-Salas, M., Smith-Vidaurre, G., Chaverri, G., Brenes, J. C., Chirino, F., Elizondo-Calvo, J., & Rico-Guevara, . (2023). ohun: R package diagnosing optimizing automatic sound event detection. Methods Ecology Evolution, 14, 2259–2271. https://doi.org/10.1111/2041-210X.14170","code":""},{"path":[]},{"path":"https://docs.ropensci.org/ohun/reference/summarize_acoustic_data.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Summarize information about file format in an acoustic data set — summarize_acoustic_data","text":"Marcelo Araya-Salas marcelo.araya@ucr.ac.cr)","code":""},{"path":"https://docs.ropensci.org/ohun/reference/summarize_acoustic_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarize information about file format in an acoustic data set — summarize_acoustic_data","text":"","code":"{   # load data and save example files into temporary working directory   data(\"lbh1\", \"lbh2\", \"lbh_reference\")   tuneR::writeWave(lbh1, file.path(tempdir(), \"lbh1.wav\"))   tuneR::writeWave(lbh2, file.path(tempdir(), \"lbh2.wav\"))    # summary across sound files   summarize_acoustic_data(path = tempdir()) } #> Features of the acoustic data set in '/private/var/folders/y6/nj790rtn62lfktb1sh__79hc0000gn/T/Rtmpw4iTKj': #>  #> * 10 sound files #>  #> * 1 file format(s) (.wav (10)) #>  #> * 1 sampling rate(s) (22.05 kHz (10)) #>  #> * 1 bit depth(s) (16 bits (10)) #>  #> * 1 number of channels (1 channel(s) (10)) #>  #> * File duration range: 0.5-5 s (mean: 2 s) #>  #> * File size range: 0.02-0.22 MB (mean: 0.09 MB) #>  #>  (detailed information by sound file can be obtained with 'warbleR::info_sound_files()')"},{"path":"https://docs.ropensci.org/ohun/reference/summarize_diagnostic.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarize detection diagnostics — summarize_diagnostic","title":"Summarize detection diagnostics — summarize_diagnostic","text":"summarize_diagnostic summarizes detection diagnostics","code":""},{"path":"https://docs.ropensci.org/ohun/reference/summarize_diagnostic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarize detection diagnostics — summarize_diagnostic","text":"","code":"summarize_diagnostic(   diagnostic,   time.diagnostics = FALSE,   macro.average = FALSE )"},{"path":"https://docs.ropensci.org/ohun/reference/summarize_diagnostic.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarize detection diagnostics — summarize_diagnostic","text":"diagnostic data frame output detection optimization function (diagnose_detection, optimize_energy_detector optimize_template_detector) time.diagnostics Logical argument control diagnostics related duration sound events (\"mean.duration.true.positives\", \"mean.duration.false.positives\", \"mean.duration.false.negatives\" \"proportional.duration.true.positives\") returned (TRUE). Default FALSE. macro.average Logical argument control diagnostics first calculated sound file averaged across sound files, can minimize effect unbalanced sample sizes sound files. FALSE (default) diagnostics based aggregated statistics irrespective sound files. following indices can estimated macro-averaging: overlap, mean.duration.true.positives, mean.duration.false.positives, mean.duration.false.positives, mean.duration.false.negatives, proportional.duration.true.positives, recall precision (f.score always derived recall precision). Note applying macro-averaging, recall precision derived true positive, false positive false negative values returned function.","code":""},{"path":"https://docs.ropensci.org/ohun/reference/summarize_diagnostic.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarize detection diagnostics — summarize_diagnostic","text":"data frame, similar output detection optimization function (diagnose_detection, optimize_energy_detector, optimize_template_detector) including following detection performance diagnostics: detections: total number detections true.positives: number sound events 'reference' correspond detection. Matching defined degree overlap time. perfect detection routine equal number rows 'reference'. false.positives: number detections match (.e. overlap ) sound events 'reference'. perfect detection routine 0. false.negatives: number sound events 'reference' detected (found 'detection'. perfect detection routine 0. splits: number detections overlapping reference sounds also overlap detections. perfect detection routine 0. merges: number detections overlap two reference sounds. perfect detection routine 0. mean.duration.true.positives: mean duration true positives (s). included time.diagnostics = TRUE. mean.duration.false.positives: mean duration false positives (ms). included time.diagnostics = TRUE. mean.duration.false.negatives: mean duration false negatives (ms). included time.diagnostics = TRUE. overlap: mean intersection union overlap true positives. proportional.duration.true.positives: ratio duration true positives duration sound events 'reference'. perfect detection routine 1. Based true positives split merged. duty.cycle: proportion sound file sounds detected. included time.diagnostics = TRUE path supplied. Useful conducting energy-based detection perfect detection can obtained low amplitude threshold, detect everything, produce duty cycle close 1. recall: Proportion sound events 'reference' detected. perfect detection routine 1. precision: Proportion detections correspond sound events 'reference'. perfect detection routine 1. f.score: Combines recall precision harmonic mean two. Provides single value evaluating performance. perfect detection routine 1.","code":""},{"path":"https://docs.ropensci.org/ohun/reference/summarize_diagnostic.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Summarize detection diagnostics — summarize_diagnostic","text":"function summarizes detection diagnostic data frame diagnostic parameters shown split (typically) categorical column, usually sound files. function used internally diagnose_detection. 'splits' 'merge.positives' also counted (.e. counted twice) 'true.positives'. Therefore \"true.positives + false.positives = detections\".","code":""},{"path":"https://docs.ropensci.org/ohun/reference/summarize_diagnostic.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Summarize detection diagnostics — summarize_diagnostic","text":"Araya-Salas, M., Smith-Vidaurre, G., Chaverri, G., Brenes, J. C., Chirino, F., Elizondo-Calvo, J., & Rico-Guevara, . 2022. ohun: R package diagnosing optimizing automatic sound event detection. BioRxiv, 2022.12.13.520253. Mesaros, ., Heittola, T., & Virtanen, T. (2016). Metrics polyphonic sound event detection. Applied Sciences, 6(6), 162.","code":""},{"path":[]},{"path":"https://docs.ropensci.org/ohun/reference/summarize_diagnostic.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Summarize detection diagnostics — summarize_diagnostic","text":"Marcelo Araya-Salas marcelo.araya@ucr.ac.cr)","code":""},{"path":"https://docs.ropensci.org/ohun/reference/summarize_diagnostic.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarize detection diagnostics — summarize_diagnostic","text":"","code":"{   # load example selection tables    data(\"lbh_reference\")    # run diagnose_detection() by sound file   diag <- diagnose_detection(     reference = lbh_reference,     detection = lbh_reference[-1, ], by.sound.file = TRUE   )    # summarize   summarize_diagnostic(diagnostic = diag)    # should be the same as this:   diagnose_detection(     reference = lbh_reference,     detection = lbh_reference[-1, ], by.sound.file = FALSE   ) } #>   detections true.positives false.positives false.negatives splits merges #> 1         18             18               0               1      0      0 #>   overlap    recall precision  f.score #> 1       1 0.9473684         1 0.972973"},{"path":"https://docs.ropensci.org/ohun/reference/summarize_reference.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarize temporal and frequency dimensions of annotations and gaps — summarize_reference","title":"Summarize temporal and frequency dimensions of annotations and gaps — summarize_reference","text":"summarize_reference summarizes temporal frequency dimensions annotations gaps","code":""},{"path":"https://docs.ropensci.org/ohun/reference/summarize_reference.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarize temporal and frequency dimensions of annotations and gaps — summarize_reference","text":"","code":"summarize_reference(   reference,   path = NULL,   by.sound.file = FALSE,   units = c(\"ms\", \"kHz\"),   digits = 2 )"},{"path":"https://docs.ropensci.org/ohun/reference/summarize_reference.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarize temporal and frequency dimensions of annotations and gaps — summarize_reference","text":"reference Data frame 'selection.table' (following warbleR package format) reference selections (start end sound events) used evaluate performance detection, represented selections 'detection'. Must contained least following columns: \"sound.files\", \"selec\", \"start\" \"end\". frequency range columns included (\"bottom.freq\" \"top.freq\") also used characterize reference selections. path Character string containing directory path sound files located. supplied duty cycle peak frequency features returned. features helpful tuning energy-based detection. Default NULL. .sound.file Logical argument control whether features summarized across sound files (.sound.file = FALSE, 1 sound file included 'reference') shown separated sound file. Default FALSE. units character vector length 2 units used time frequency parameters, order. Default c(\"ms\", \"kHz\"). can also take 's' 'Hz'. digits Numeric vector length 1 number decimals include. Default 2.","code":""},{"path":"https://docs.ropensci.org/ohun/reference/summarize_reference.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarize temporal and frequency dimensions of annotations and gaps — summarize_reference","text":"function returns mean, minimum maximum duration selections gaps (time intervals selections) number annotations sound file. frequency range columns included reference table (.e. \"bottom.freq\" \"top.freq\") minimum bottom frequency ('min.bottom.freq') maximum top frequency ('max.top.freq') also estimated. Finally, path sound files 'reference' supplied duty cycle (fraction sound file corresponding target sound events) peak amplitude (highest amplitude detection) also returned. `.sound.file = FALSE` matrix features rows returned. Otherwise data frame returned row correspond sound file. default, time features returned 'ms' frequency features 'kHz' (see 'units' argument).","code":""},{"path":"https://docs.ropensci.org/ohun/reference/summarize_reference.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Summarize temporal and frequency dimensions of annotations and gaps — summarize_reference","text":"function extracts quantitative features reference tables can inform range values used energy-based detection optimization routine. Features related selection duration can used set 'max.duration' 'min.duration' values, frequency related features can inform bandpass values, gap related features inform hold time values duty cycle can used evaluate performance.","code":""},{"path":"https://docs.ropensci.org/ohun/reference/summarize_reference.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Summarize temporal and frequency dimensions of annotations and gaps — summarize_reference","text":"Araya-Salas, M., Smith-Vidaurre, G., Chaverri, G., Brenes, J. C., Chirino, F., Elizondo-Calvo, J., & Rico-Guevara, . (2023). ohun: R package diagnosing optimizing automatic sound event detection. Methods Ecology Evolution, 14, 2259–2271. https://doi.org/10.1111/2041-210X.14170","code":""},{"path":[]},{"path":"https://docs.ropensci.org/ohun/reference/summarize_reference.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Summarize temporal and frequency dimensions of annotations and gaps — summarize_reference","text":"Marcelo Araya-Salas marcelo.araya@ucr.ac.cr)","code":""},{"path":"https://docs.ropensci.org/ohun/reference/summarize_reference.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarize temporal and frequency dimensions of annotations and gaps — summarize_reference","text":"","code":"{   # load data and save example files into temporary working directory   data(\"lbh1\", \"lbh2\", \"lbh_reference\")   tuneR::writeWave(lbh1, file.path(tempdir(), \"lbh1.wav\"))   tuneR::writeWave(lbh2, file.path(tempdir(), \"lbh2.wav\"))    # summary across sound files   summarize_reference(reference = lbh_reference, path = tempdir())    # summary across sound files   summarize_reference(reference = lbh_reference, by.sound.file = TRUE, path = tempdir()) } #>   sound.files min.sel.duration mean.sel.duration max.sel.duration #> 1    lbh2.wav           117.96            131.45           139.08 #> 2    lbh1.wav           140.84            152.64           163.73 #>   min.gap.duration mean.gap.duration max.gap.duration annotations #> 1           406.68            446.09           484.14           9 #> 2           322.16            352.29           514.08          10 #>   min.bottom.freq mean.bottom.freq max.bottom.freq min.top.freq mean.top.freq #> 1            2.16             2.27            2.37         8.49          8.82 #> 2            1.81             1.96            2.09         8.49          8.82 #>   max.top.freq duty.cycle min.peak.amplitude mean.peak.amplitude #> 1         9.08       0.24              73.76               76.01 #> 2         9.53       0.31              85.21               86.60 #>   max.peak.amplitude #> 1              77.65 #> 2              88.03"},{"path":"https://docs.ropensci.org/ohun/reference/template_correlator.html","id":null,"dir":"Reference","previous_headings":"","what":"Acoustic templates correlator using time-frequency cross-correlation — template_correlator","title":"Acoustic templates correlator using time-frequency cross-correlation — template_correlator","text":"template_correlator estimates templates cross-correlation across multiple sound files.","code":""},{"path":"https://docs.ropensci.org/ohun/reference/template_correlator.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Acoustic templates correlator using time-frequency cross-correlation — template_correlator","text":"","code":"template_correlator(   templates,   files = NULL,   hop.size = 11.6,   wl = NULL,   ovlp = 0,   wn = \"hanning\",   cor.method = \"pearson\",   cores = 1,   path = \".\",   pb = TRUE,   type = \"fourier\",   fbtype = \"mel\",   ... )"},{"path":"https://docs.ropensci.org/ohun/reference/template_correlator.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Acoustic templates correlator using time-frequency cross-correlation — template_correlator","text":"templates 'selection_table', 'extended_selection_table' (warbleR package's formats, see selection_table) data frame time frequency information sound event(s) used templates (1 template per row). object must contain columns sound files (sound.files), selection number (selec), start end time sound event (start end). frequency range columns included ('bottom.freq' 'top.freq', kHz) correlation run frequency ranges. templates must sampling rate templates 'files' (find templates) must also sampling rate. files Character vector name files run cross-correlation supplied template(s). Supported file formats:'.wav', '.mp3', '.flac' '.wac'. supplied function work sound files (supported formats) 'path'. hop.size numeric vector length 1 specifying time window duration (ms). Default 11.6 ms, equivalent 512 wl 44.1 kHz sampling rate. Ignored 'wl' supplied. wl numeric vector length 1 specifying window length spectrogram. Default NULL. supplied, 'hop.size' ignored. ovlp Numeric vector length 1 specifying % overlap two consecutive windows, spectro. Default 0. High values ovlp slow function may produce accurate results. wn character vector length 1 specifying window name ftwindow. cor.method character vector length 1 specifying correlation method cor. cores Numeric. Controls whether parallel computing applied. specifies number cores used. Default 1 (.e. parallel computing). path Character string containing directory path sound files located. current working directory used default. pb Logical argument control progress bar. Default TRUE. type character vector length 1 specifying type cross-correlation: \"fourier\" (.e. spectrographic cross-correlation using Fourier transform; internally using spectro; default), \"mfcc\" (auditory scale coefficient matrix cross-correlation; internally using melfcc) \"mel-auditory\" (cross-correlation auditory spectrum, .e. spectrum transformation auditory scale; internally using melfcc). argument 'fbtype' controls auditory scale used. Note last 2 methods widely used context can regarded experimental. fbtype Character vector indicating auditory frequency scale use: \"mel\", \"bark\", \"htkmel\", \"fcmel\". ... Additional arguments passed melfcc customization using auditory scales.","code":""},{"path":"https://docs.ropensci.org/ohun/reference/template_correlator.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Acoustic templates correlator using time-frequency cross-correlation — template_correlator","text":"function returns object class 'template_correlations' list correlation scores combination templates files. 'template_correlations' objects must used infer sound event occurrences using template_detector graphically explore template correlations across sound files using full_spectrograms.","code":""},{"path":"https://docs.ropensci.org/ohun/reference/template_correlator.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Acoustic templates correlator using time-frequency cross-correlation — template_correlator","text":"function calculates similarity acoustic templates across sound files means time-frequency cross-correlation. Fourier spectrograms time-frequency representations auditory scales (including cepstral coefficients) can used. Several templates can run several sound files. Note template-based detection divided two steps: template correlation (using function) template detection (peak detection infers detection based peak correlation scores, using function template_detector). output function (object 'template_correlations') must input template_detector inferring sound event occurrences. optimize_template_detector can used optimize template detection.","code":""},{"path":"https://docs.ropensci.org/ohun/reference/template_correlator.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Acoustic templates correlator using time-frequency cross-correlation — template_correlator","text":"Araya-Salas, M., Smith-Vidaurre, G., Chaverri, G., Brenes, J. C., Chirino, F., Elizondo-Calvo, J., & Rico-Guevara, . (2023). ohun: R package diagnosing optimizing automatic sound event detection. Methods Ecology Evolution, 14, 2259–2271. https://doi.org/10.1111/2041-210X.14170 Khanna H., Gaunt S.L.L.  & McCallum D.. (1997). Digital spectrographic cross-correlation: tests recall. Bioacoustics 7(3): 209-234. Lyon, R. H., & Ordubadi, . (1982). Use cepstra acoustical signal analysis. Journal Mechanical Design, 104(2), 303-306.","code":""},{"path":[]},{"path":"https://docs.ropensci.org/ohun/reference/template_correlator.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Acoustic templates correlator using time-frequency cross-correlation — template_correlator","text":"Marcelo Araya-Salas marcelo.araya@ucr.ac.cr)","code":""},{"path":"https://docs.ropensci.org/ohun/reference/template_correlator.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Acoustic templates correlator using time-frequency cross-correlation — template_correlator","text":"","code":"{   # load example data   data(\"lbh1\", \"lbh2\", \"lbh_reference\")    # save sound files   tuneR::writeWave(lbh1, file.path(tempdir(), \"lbh1.wav\"))   tuneR::writeWave(lbh2, file.path(tempdir(), \"lbh2.wav\"))    # create template   templ <- lbh_reference[4, ]   templ2 <- warbleR::selection_table(templ,     extended = TRUE,     path = tempdir()   )    # fourier spectrogram   (tc_fr <- template_correlator(templates = templ, path = tempdir(), type = \"fourier\"))    # mel auditory spectrograms   (tc_ma <- template_correlator(templates = templ, path = tempdir(), type = \"mel-auditory\"))    # mfcc spectrograms   (tc_mfcc <- template_correlator(templates = templ, path = tempdir(), type = \"mfcc\"))    # similar results (but no exactly the same) are found with the 3 methods   # these are the correlation of the correlation vectors   # fourier vs mel-auditory   cor(     tc_fr$`lbh2.wav-4/lbh2.wav`$correlation.scores,     tc_ma$`lbh2.wav-4/lbh2.wav`$correlation.scores   )    # fourier vs mfcc   cor(     tc_fr$`lbh2.wav-4/lbh2.wav`$correlation.scores,     tc_mfcc$`lbh2.wav-4/lbh2.wav`$correlation.scores   )    # mel-auditory vs mfcc   cor(     tc_ma$`lbh2.wav-4/lbh2.wav`$correlation.scores,     tc_mfcc$`lbh2.wav-4/lbh2.wav`$correlation.scores   )    # using an extended selection table   templ_est <- warbleR::selection_table(templ,     extended = TRUE,     path = tempdir()   )    tc_fr_est <- template_correlator(templates = templ_est, path = tempdir(), type = \"fourier\")    # produces the same result as templates in a regular data frame   cor(     tc_fr$`lbh2.wav-4/lbh2.wav`$correlation.scores,     tc_fr_est$`lbh2.wav_4-1/lbh2.wav`$correlation.scores   ) } #> all selections are OK  #>  #> all selections are OK  #>  #> [1] 1"},{"path":"https://docs.ropensci.org/ohun/reference/template_detector.html","id":null,"dir":"Reference","previous_headings":"","what":"Acoustic template detection from time-frequency cross-correlations — template_detector","title":"Acoustic template detection from time-frequency cross-correlations — template_detector","text":"template_detector find sound event occurrences cross-correlation vectors template_correlator","code":""},{"path":"https://docs.ropensci.org/ohun/reference/template_detector.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Acoustic template detection from time-frequency cross-correlations — template_detector","text":"","code":"template_detector(   template.correlations,   cores = 1,   threshold,   pb = TRUE,   verbose = TRUE )"},{"path":"https://docs.ropensci.org/ohun/reference/template_detector.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Acoustic template detection from time-frequency cross-correlations — template_detector","text":"template.correlations object class 'template_correlations' generated template_correlator containing correlation score vectors. cores Numeric. Controls whether parallel computing applied. specifies number cores used. Default 1 (.e. parallel computing). threshold Numeric vector length 1 value 0 1 specifying correlation threshold detecting sound event occurrences (.e. correlation peaks). Must supplied. Correlation scores forced 0 1 (converting negative scores 0). 0 1 represent lowest highest similarity template respectively. pb Logical argument control progress bar. Default TRUE. verbose Logical argument control summary messages printed console.","code":""},{"path":"https://docs.ropensci.org/ohun/reference/template_detector.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Acoustic template detection from time-frequency cross-correlations — template_detector","text":"function returns 'selection_table' (warbleR package's formats, see selection_table) data frame (sound files found) start end correlation score detected sound events.","code":""},{"path":"https://docs.ropensci.org/ohun/reference/template_detector.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Acoustic template detection from time-frequency cross-correlations — template_detector","text":"function infers sound events occurrences cross-correlation scores along sound files. Correlation scores must generated first using template_correlator. output data frame (selection table sound files still found original path supplied template_correlator, using warbleR package's format, see selection_table) containing start end detected sound events well cross-correlation score ('scores' column) detection. Note detected sounds assumed duration template, start end correspond correlation peak position +/- half template duration.","code":""},{"path":"https://docs.ropensci.org/ohun/reference/template_detector.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Acoustic template detection from time-frequency cross-correlations — template_detector","text":"Araya-Salas, M., Smith-Vidaurre, G., Chaverri, G., Brenes, J. C., Chirino, F., Elizondo-Calvo, J., & Rico-Guevara, . (2023). ohun: R package diagnosing optimizing automatic sound event detection. Methods Ecology Evolution, 14, 2259–2271. https://doi.org/10.1111/2041-210X.14170","code":""},{"path":[]},{"path":"https://docs.ropensci.org/ohun/reference/template_detector.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Acoustic template detection from time-frequency cross-correlations — template_detector","text":"Marcelo Araya-Salas marcelo.araya@ucr.ac.cr)","code":""},{"path":"https://docs.ropensci.org/ohun/reference/template_detector.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Acoustic template detection from time-frequency cross-correlations — template_detector","text":"","code":"{   # load example data   data(\"lbh1\", \"lbh2\", \"lbh_reference\")    # save sound files   tuneR::writeWave(lbh1, file.path(tempdir(), \"lbh1.wav\"))   tuneR::writeWave(lbh2, file.path(tempdir(), \"lbh2.wav\"))    # template for the first sound file in 'lbh_reference'   templ1 <- lbh_reference[1, ]    # generate template correlations   tc <- template_correlator(templates = templ1, path = tempdir(), files = \"lbh1.wav\")    # template detection   td <- template_detector(template.correlations = tc, threshold = 0.4)    # diagnose detection   diagnose_detection(     reference =       lbh_reference[lbh_reference$sound.files == \"lbh1.wav\", ],     detection = td   )    # template for the second and third sound file in 'lbh_reference'   # which have similar song types   templ2 <- lbh_reference[4, ]    # generate template correlations   tc <- template_correlator(     templates = templ2, path = tempdir(),     files = c(\"lbh1.wav\", \"lbh2.wav\")   )    # template detection   td <- template_detector(template.correlations = tc, threshold = 0.3)    # diagnose detection   diagnose_detection(reference = lbh_reference, detection = td) } #>   detections true.positives false.positives false.negatives splits merges #> 1         77             19              58               0      0      0 #>     overlap recall precision   f.score #> 1 0.8606319      1 0.2467532 0.3958333"},{"path":"https://docs.ropensci.org/ohun/news/index.html","id":"ohun-103","dir":"Changelog","previous_headings":"","what":"ohun 1.0.3","title":"ohun 1.0.3","text":"CRAN release: 2025-07-22","code":""},{"path":"https://docs.ropensci.org/ohun/news/index.html","id":"new-features-1-0-3","dir":"Changelog","previous_headings":"","what":"NEW FEATURES","title":"ohun 1.0.3","text":"New function reassemble_detection() reassembles detections made clips refer original sound files","code":""},{"path":"https://docs.ropensci.org/ohun/news/index.html","id":"minor-improvements-1-0-3","dir":"Changelog","previous_headings":"","what":"MINOR IMPROVEMENTS","title":"ohun 1.0.3","text":"Update names functions package warbleR latest versions Replace sapply() vapply() Fix bug true positive set false positives based solving ambiguous detection using maximum bipartite graph matching","code":""},{"path":"https://docs.ropensci.org/ohun/news/index.html","id":"ohun-102","dir":"Changelog","previous_headings":"","what":"ohun 1.0.2","title":"ohun 1.0.2","text":"CRAN release: 2024-08-19 Update requested CRAN.","code":""},{"path":"https://docs.ropensci.org/ohun/news/index.html","id":"ohun-101","dir":"Changelog","previous_headings":"","what":"ohun 1.0.1","title":"ohun 1.0.1","text":"CRAN release: 2023-11-17 Update requested CRAN.","code":""},{"path":"https://docs.ropensci.org/ohun/news/index.html","id":"ohun-100","dir":"Changelog","previous_headings":"","what":"ohun 1.0.0","title":"ohun 1.0.0","text":"CRAN release: 2023-09-23","code":""},{"path":"https://docs.ropensci.org/ohun/news/index.html","id":"new-features-1-0-0","dir":"Changelog","previous_headings":"","what":"NEW FEATURES","title":"ohun 1.0.0","text":"New function plot_detection() visually inspect detections","code":""},{"path":"https://docs.ropensci.org/ohun/news/index.html","id":"minor-improvements-1-0-0","dir":"Changelog","previous_headings":"","what":"MINOR IMPROVEMENTS","title":"ohun 1.0.0","text":"sp package replaced sf Replace sapply() vapply() performance indices name changes: split.positives splits, merged.positives merges, proportional.overlap..true.positives overlap f1.score f.score label_detection() renamed consensus_detection()","code":""},{"path":"https://docs.ropensci.org/ohun/news/index.html","id":"ohun-010-2022-12-19","dir":"Changelog","previous_headings":"","what":"ohun 0.1.0 (2022-12-19)","title":"ohun 0.1.0 (2022-12-19)","text":"CRAN release: 2022-12-19","code":""},{"path":"https://docs.ropensci.org/ohun/news/index.html","id":"new-features-0-1-0","dir":"Changelog","previous_headings":"","what":"NEW FEATURES","title":"ohun 0.1.0 (2022-12-19)","text":"released CRAN","code":""}]
