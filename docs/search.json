[{"path":"https://marce10.github.io/ohun/articles/ohun.html","id":"automatic-signal-detection","dir":"Articles","previous_headings":"","what":"Automatic signal detection","title":"<center><font size=","text":"Finding position signals sound file challenging task. ohun offers two methods automatic signal detection: template-based energy-based detection. methods better suited highly stereotyped good signal--noise ratio (SNR) signals, respectively. target signals don’t fit requirements, elaborated methods (.e. machine learning approaches) warranted: Diagram depicting target signal features can used tell adequate acoustic signal detection approach. Steps ‘ohun’ can helpful shown color. (SNR = signal--noise ratio)   Still, detection run using software can optimized tools provided ohun.  ","code":""},{"path":"https://marce10.github.io/ohun/articles/ohun.html","id":"signal-detection-theory-applied-to-bioacoustics","dir":"Articles","previous_headings":"","what":"Signal detection theory applied to bioacoustics","title":"<center><font size=","text":"Broadly speaking, signal detection theory deals process recovering signals (.e. target signals) background noise (necessarily acoustic noise) ’s widely used optimizing decision making process presence uncertainty. detection routine, detected ‘items’ can classified 4 classes: True positives (TPs): signals correctly identified ‘signal’ False positives (FPs): background noise incorrectly identified ‘signal’ False negatives (FNs): signals incorrectly identified ‘background noise’ True negatives (TNs): background noise correctly identified ‘background noise’ Several additional indices derived indices used evaluate performance detection routine. three useful indices context acoustic signal detection included ohun: Recall: correct detections relative total detections (.k.. true positive rate sensitivity; TPs / (TPs + FNs)) Precision: correct detections relative total detections (TPs / (TPs + FPs)). F1 score: combines recall precision harmonic mean two, provides single value evaluating performance (.k.. F-measure Dice similarity coefficient). (Metrics make use ‘true negatives’ easily applied context acoustic signal detection noise always partitioned discrete units) perfect detection false positives false negatives, result recall precision equal 1. However, perfect detection always reached compromise detecting target signals plus noise (recall = 1 & precision < 1) detecting target signals (recall < 1 & precision = 1) warranted. right balance two extremes given relative costs missing signals mistaking noise signals. Hence, indices provide useful framework diagnosing optimizing performance detection routine. package ohun provides set tools evaluate performance acoustic signal detection based indices described . accomplish , result detection routine compared reference table containing time position target signals sound files. package comes example reference table containing annotations long-billed hermit hummingbird songs two sound files (also supplied example data: ‘lbh1’ ‘lbh2’), can used illustrate detection performance evaluation. example data can explored follows:   ‘selection table’, object class provided package warbleR (see selection_table() details). Selection tables basically data frames contained information double-checked (using warbleR’s check_sels()). behave pretty much data frames can easily converted data frames:   ohun functions work kind data can take selection tables data frames. Spectrograms highlighted signals selection table can plotted function label_spectro() (function plots one wave object time):   function diagnose_detection() evaluates performance detection routine comparing reference table. instance, perfect detection given comparing lbh_reference :   work mostly single sound file convenience functions can work several sound files time. files found single working directory. Although example bit silly, shows basic diagnostic indices, include basic detection theory indices (‘true.positives’, ‘false.positives’, ‘false.negatives’, ‘recall’ ‘precision’) mentioned . can play around reference table see indices can used spot imperfect detection routines (hopefully improve !). instance, can remove signals see reflected diagnostics. Getting rid rows ‘detection’, simulating detection false negatives, affect recall precision:    additional signals reference opposite, reducing precision recall. can simply switching tables:    function offers three additional diagnose metrics: Split positives: target signals overlapped 1 detecion Merged positives: number cases 2 target signals ‘reference’ overlapped detection Proportional overlap true positives: ratio time overlap true positives corresponding signal reference table perfect detection routine split merged positives 0 proportional overlap 1. can shift start signals bit reflect detection mismatch reference table regarding time location signals:    addition, following diagnostics related duration signals can also returned setting time.diagnostics = TRUE. tweak reference detection data just false positives false negatives:   additional metrics can used filter undesired signals based duration (instance energy-based detection energy_detector(), explained ). Diagnostics can also detailed sound file:   diagnostics can summarized (default diagnose_detection() output) function summarize_diagnostic():  ","code":"# load example data data(\"lbh1\", \"lbh2\", \"lbh_reference\")  lbh_reference ## Object of class 'selection_table'  ## * The output of the following call:  ## warbleR::selection_table(X = lbh_reference)  ##  ## Contains:  ## *  A selection table data frame with 19 rows and 6 columns:  ## |sound.files | selec|  start|    end| bottom.freq| top.freq| ## |:-----------|-----:|------:|------:|-----------:|--------:| ## |lbh2.wav    |     1| 0.1092| 0.2482|      2.2954|   8.9382| ## |lbh2.wav    |     2| 0.6549| 0.7887|      2.2954|   9.0426| ## |lbh2.wav    |     3| 1.2658| 1.3856|      2.2606|   9.0774| ## |lbh2.wav    |     4| 1.8697| 2.0053|      2.1911|   8.9035| ## |lbh2.wav    |     5| 2.4418| 2.5809|      2.1563|   8.6600| ## |lbh2.wav    |     6| 3.0368| 3.1689|      2.2259|   8.9382| ## ... and 13 more row(s)  ##  ##  * A data frame (check.results) generated by check_sels() (as attribute)  ## created by warbleR 1.1.27 # convert to data frame as.data.frame(lbh_reference) ##    sound.files selec    start       end bottom.freq top.freq ## 1     lbh2.wav     1 0.109161 0.2482449      2.2954   8.9382 ## 2     lbh2.wav     2 0.654921 0.7887232      2.2954   9.0426 ## 3     lbh2.wav     3 1.265850 1.3855678      2.2606   9.0774 ## 4     lbh2.wav     4 1.869705 2.0052678      2.1911   8.9035 ## 5     lbh2.wav     5 2.441769 2.5808529      2.1563   8.6600 ## 6     lbh2.wav     6 3.036825 3.1688667      2.2259   8.9382 ## 7     lbh2.wav     7 3.628617 3.7465742      2.3302   8.6252 ## 8     lbh2.wav     8 4.153288 4.2818085      2.2954   8.4861 ## 9     lbh2.wav     9 4.723673 4.8609963      2.3650   8.6948 ## 10    lbh1.wav    10 0.088118 0.2360047      1.9824   8.4861 ## 11    lbh1.wav    11 0.572290 0.7201767      2.0520   9.5295 ## 12    lbh1.wav    12 1.056417 1.1972614      2.0868   8.4861 ## 13    lbh1.wav    13 1.711338 1.8680274      1.9824   8.5905 ## 14    lbh1.wav    14 2.190249 2.3416568      2.0520   8.5209 ## 15    lbh1.wav    15 2.697143 2.8538324      1.9824   9.2513 ## 16    lbh1.wav    16 3.181315 3.3344833      1.9129   8.4861 ## 17    lbh1.wav    17 3.663719 3.8133662      1.8781   8.6948 ## 18    lbh1.wav    18 4.140816 4.3045477      1.8433   9.2165 ## 19    lbh1.wav    19 4.626712 4.7851620      1.8085   8.9035 # save sound file writeWave(lbh1, file.path(tempdir(), \"lbh1.wav\"))  # save sound file writeWave(lbh2, file.path(tempdir(), \"lbh2.wav\"))  # print spectrogram label_spectro(wave = lbh1, reference = lbh_reference[lbh_reference$sound.files ==     \"lbh1.wav\", ], hop.size = 10, ovlp = 50, flim = c(1, 10)) # print spectrogram label_spectro(wave = lbh2, reference = lbh_reference[lbh_reference$sound.files ==     \"lbh2.wav\", ], hop.size = 10, ovlp = 50, flim = c(1, 10)) lbh1_reference <- lbh_reference[lbh_reference$sound.files == \"lbh1.wav\", ]  # diagnose diagnose_detection(reference = lbh1_reference, detection = lbh1_reference)[, c(1:3,     7:9)] ##   true.positives false.positives false.negatives recall precision f1.score ## 1             10               0               0      1         1        1 # create new table lbh1_detection <- lbh1_reference[3:9, ]  # print spectrogram label_spectro(wave = lbh1, reference = lbh1_reference, detection = lbh1_detection,     hop.size = 10, ovlp = 50, flim = c(1, 10)) # diagnose diagnose_detection(reference = lbh1_reference, detection = lbh1_detection)[, c(1:3,     7:9)] ##   true.positives false.positives false.negatives recall precision  f1.score ## 1              7               0               3    0.7         1 0.8235294 # print spectrogram label_spectro(wave = lbh1, detection = lbh1_reference, reference = lbh1_detection,     hop.size = 10, ovlp = 50, flim = c(1, 10)) # diagnose diagnose_detection(reference = lbh1_detection, detection = lbh1_reference)[, c(1:3,     7:9)] ##   true.positives false.positives false.negatives recall precision  f1.score ## 1              7               3               0      1       0.7 0.8235294 # create new table lbh1_detection <- lbh1_reference  # add 'noise' to start set.seed(18) lbh1_detection$start <- lbh1_detection$start + rnorm(nrow(lbh1_detection), mean = 0,     sd = 0.1)  ## print spectrogram label_spectro(wave = lbh1, reference = lbh1_reference, detection = lbh1_detection,     hop.size = 10, ovlp = 50, flim = c(1, 10)) # diagnose diagnose_detection(reference = lbh1_reference, detection = lbh1_detection) ##   true.positives false.positives false.negatives split.positives ## 1             10               0               0               0 ##   merged.positives overlap.to.true.positives recall precision f1.score ## 1                0                 0.5280701      1         1        1 # diagnose with time diagnostics diagnose_detection(reference = lbh1_reference[-1, ], detection = lbh1_detection[-10,     ], time.diagnostics = TRUE) ##   true.positives false.positives false.negatives split.positives ## 1              8               1               1               0 ##   merged.positives overlap.to.true.positives mean.duration.true.positives ## 1                0                 0.6103203                    0.1387504 ##   mean.duration.false.positives mean.duration.false.negatives ## 1                    0.05524073                       0.15845 ##   proportional.duration.true.positives    recall precision  f1.score ## 1                                    1 0.8888889 0.8888889 0.8888889 # diagnose by sound file diagnostic <- diagnose_detection(reference = lbh1_reference, detection = lbh1_detection,     by.sound.file = TRUE)  diagnostic ##   sound.files true.positives false.positives false.negatives split.positives ## 1    lbh1.wav             10               0               0               0 ##   merged.positives overlap.to.true.positives recall precision f1.score ## 1                0                 0.5280701      1         1        1 # summarize summarize_diagnostic(diagnostic) ##   true.positives false.positives false.negatives split.positives ## 1             10               0               0               0 ##   merged.positives overlap.to.true.positives recall precision f1.score ## 1                0                 0.5280701      1         1        1"},{"path":[]},{"path":"https://marce10.github.io/ohun/articles/ohun.html","id":"energy-based-detection","dir":"Articles","previous_headings":"Detecting signals with ohun","what":"Energy-based detection","title":"<center><font size=","text":"detector uses amplitude envelopes infer position signals. Amplitude envelopes representations variation energy time. following code plots amplitude envelope along spectrogram example data lbh1:   type detector doesn’t require highly stereotyped signals, although work better high quality recordings amplitude target signals higher background noise (.e. high signal--noise ratio). function ernergy_detector() performs type detection.  ","code":"# plot spectrogram and envelope label_spectro(wave = cutw(lbh1, from = 0, to = 1.5, output = \"Wave\"), ovlp = 90,     hop.size = 10, flim = c(0, 10), envelope = TRUE)"},{"path":"https://marce10.github.io/ohun/articles/ohun.html","id":"how-it-works","dir":"Articles","previous_headings":"Detecting signals with ohun > Energy-based detection","what":"How it works","title":"<center><font size=","text":"can understand use ernergy_detector() using simulated signals. using function simulate_songs() warbleR. example simulate recording 10 sounds two different frequency ranges durations:   function call saves ‘.wav’ sound file temporary directory (tempdir()) also returns wave object R environment. outputs used run energy-based detection creating plots, respectively. spectrogram amplitude envelope simulated recording look like:   Note amplitude envelope shows high signal--noise ratio signals, ideal energy-based detection. can conducted using ernergy_detector() follows:   output selection table: Now make use additional arguments filter specific signals based structural features. instance can use argument minimum.duration provide time treshold (ms) exclude short signals keep longest signals:   can use argument max.duration (also ms) exclude long signals keep short ones:   can also focus detection specific frequency ranges using argument bp (bandpass). setting bp = c(5, 8) signals found within frequency range (5-8 kHz) detected, excludes signals 5 kHz:   logic can applied detect signals found 5 kHz. just need set upper bound band pass filter range higher frequency signals (instance bp = (0, 6)):   Amplitude modulation (variation amplitude across signal) can problematic detection based amplitude envelopes. can also simulate amplitude modulation using warbleR::simulate_songs():   signals strong amplitude modulation can split detection:   two arguments can deal : holdtime smooth. hold.time allows merge split signals found within given time range (ms). time range high enough merge things belonging signal high merges different signals. example hold.time 200 ms can trick (know gaps signals ~0.5 s long):   smooth works merging amplitude envelope ‘hills’ split signals . smooths envelopes applying sliding window averaging amplitude values. ’s given ms window size. smooth 350 ms can merged back split signals example:   function additional arguments filtering detections (peak.amplitude) speeding analysis (thinning parallel).  ","code":"# install this package first if not installed install.packages('Sim.DiffProc')  # Creating vector for duration durs <- rep(c(0.3, 1), 5)  # Creating simulated song set.seed(12) simulated_1 <- warbleR::simulate_songs(n = 10, durs = durs, freqs = 5, sig2 = 0.01,     gaps = 0.5, harms = 1, bgn = 0.1, path = tempdir(), file.name = \"simulated_1\",     selec.table = TRUE, shape = \"cos\", fin = 0.3, fout = 0.35, samp.rate = 18)$wave # plot spectrogram and envelope label_spectro(wave = simulated_1, env = TRUE, fastdisp = TRUE) # run detection detection <- energy_detector(files = \"simulated_1.wav\", bp = c(2, 8), threshold = 50,     smooth = 150, path = tempdir())  # plot spectrogram and envelope label_spectro(wave = simulated_1, envelope = TRUE, detection = detection, threshold = 50) detection ## Object of class 'selection_table'  ## * The output of the following call:  ## energy_detector(files = \"simulated_1.wav\", path = tempdir(),   ##  bp = c(2, 8), smooth = 150, threshold = 50)  ##  ## Contains:  ## *  A selection table data frame with 10 rows and 5 columns:  ## |sound.files     | duration| selec|  start|    end| ## |:---------------|--------:|-----:|------:|------:| ## |simulated_1.wav |   0.2328|     1| 0.5309| 0.7638| ## |simulated_1.wav |   0.7947|     2| 1.3955| 2.1901| ## |simulated_1.wav |   0.2334|     3| 2.8308| 3.0642| ## |simulated_1.wav |   0.7944|     4| 3.6955| 4.4899| ## |simulated_1.wav |   0.2333|     5| 5.1307| 5.3641| ## |simulated_1.wav |   0.7945|     6| 5.9956| 6.7901| ## ... and 4 more row(s)  ##  ##  * A data frame (check.results) generated by check_sels() (as attribute)  ## created by warbleR 1.1.27 # run detection detection <- energy_detector(files = \"simulated_1.wav\", bp = c(1, 8), threshold = 50,     min.duration = 500, smooth = 150, path = tempdir())  # plot spectrogram label_spectro(wave = simulated_1, detection = detection) # run detection detection <- energy_detector(files = \"simulated_1.wav\", bp = c(1, 8), threshold = 50,     smooth = 150, max.duration = 500, path = tempdir())  # plot spectrogram label_spectro(wave = simulated_1, detection = detection) # Detecting detection <- energy_detector(files = \"simulated_1.wav\", bp = c(5, 8), threshold = 50,     smooth = 150, path = tempdir())  # plot spectrogram label_spectro(wave = simulated_1, detection = detection) # Detect detection <- energy_detector(files = \"simulated_1.wav\", bp = c(0, 6), threshold = 50,     min.duration = 1, smooth = 150, path = tempdir())  # plot spectrogram label_spectro(wave = simulated_1, detection = detection) # Creating simulated song set.seed(12)  # Creating vector for duration durs <- rep(c(0.3, 1), 5)  sim_2 <- sim_songs(n = 10, durs = durs, freqs = 5, sig2 = 0.01, gaps = 0.5, harms = 1,     bgn = 0.1, path = tempdir(), file.name = \"simulated_2\", selec.table = TRUE, shape = \"cos\",     fin = 0.3, fout = 0.35, samp.rate = 18, am.amps = c(1, 2, 3, 2, 0.1, 2, 3, 3,         2, 1))  # extract wave object and selection table simulated_2 <- sim_2$wave sim2_sel_table <- sim_2$selec.table  # plot spectrogram label_spectro(wave = simulated_2, envelope = TRUE) # detect sounds detection <- energy_detector(files = \"simulated_2.wav\", threshold = 50, path = tempdir())  # plot spectrogram label_spectro(wave = simulated_2, envelope = TRUE, threshold = 50, detection = detection) # detect sounds detection <- energy_detector(files = \"simulated_2.wav\", threshold = 50, min.duration = 1,     path = tempdir(), hold.time = 200)  # plot spectrogram label_spectro(wave = simulated_2, envelope = TRUE, threshold = 50, detection = detection) # detect sounds detection <- energy_detector(files = \"simulated_2.wav\", threshold = 50, min.duration = 1,     path = tempdir(), smooth = 350)  # plot spectrogram label_spectro(wave = simulated_2, envelope = TRUE, threshold = 50, detection = detection,     smooth = 350)"},{"path":"https://marce10.github.io/ohun/articles/ohun.html","id":"optimizing-energy-based-detection","dir":"Articles","previous_headings":"Detecting signals with ohun > Energy-based detection","what":"Optimizing energy-based detection","title":"<center><font size=","text":"last example using smooth can used showcase tunning parameters can optimized. explained , need reference table contains time position target signals. function optimize_energy_detector() can used finding optimal parameter values. must provide range parameter values evaluated:   output contains combination parameters used iteration well corresponding diagnose indices. case combinations generate good detection (recall & precision = 1). However, routine highest smooth (last row) split signals (‘split.positive’ column). also shows better overlap reference signals (‘overlap..true.positives’ closer 1). addition, two complementary functions optimizing energy-based detection routines: feature_reference() merge_overlaps(). feature_reference() allow user get sense time frequency characteristics reference table. information can used determine range tuning parameter values optimization. output function applied lbh_reference:   Features related selection duration can used set ‘max.duration’ ‘min.duration’ values, frequency related features can inform banpass values, gap related features inform hold time values duty cycle can used evaluate performance. Peak amplitude can used keep signals highest intensity, mostly useful routines subset target signals present recordings needed. merge_overlaps() finds time-overlapping selections reference tables collapses single selection. Overlapping selections likely appear single amplitude ‘hill’ thus detected single signal. merge_overlaps() can useful prepare references format representing realistic expectation pefect energy detection routine look like.","code":"optim_detection <- optimize_energy_detector(reference = sim2_sel_table, files = \"simulated_2.wav\",     threshold = 50, min.duration = 1, path = tempdir(), smooth = c(100, 250, 350)) ## 3 combinations will be evaluated: optim_detection[, c(1, 2:5, 7:12, 17:18)] ##   threshold peak.amplitude smooth hold.time min.duration thinning ## 1        50              0    100         0            1        1 ## 2        50              0    250         0            1        1 ## 3        50              0    350         0            1        1 ##   true.positives false.positives false.negatives split.positives ## 1             10               0               0              10 ## 2             10               0               0               5 ## 3             10               0               0               0 ##   merged.positives proportional.duration.true.positives duty.cycle ## 1                0                             1.000000  0.3714601 ## 2                0                             1.179487  0.3555202 ## 3                0                             1.000000  0.4442706 feature_reference(reference = lbh_reference, path = tempdir()) ##                   min   mean    max ## sel.duration   117.96 142.60 163.73 ## gap.duration   624.97 680.92 811.61 ## duty.cycle       0.24   0.27   0.31 ## peak.amplitude  47.74  55.56  62.01 ## bottom.freq      1.81   2.11   2.37 ## top.freq         8.49   8.82   9.53"},{"path":"https://marce10.github.io/ohun/articles/ohun.html","id":"template-based-detection","dir":"Articles","previous_headings":"Detecting signals with ohun","what":"Template-based detection","title":"<center><font size=","text":"detection method better suited highly stereotyped signals. doesn’t depend signal--noise ratio ’s robust higher levels background noise. procedure divided three steps: Choosing right template (get_templates()) Estimating cross-correlation scores templates along sound files (template_correlator()) Detecting signals applying correlation threshold (template_detector()) function get_templates() can help find template closer average acoustic structure signals reference table. done finding signals closer centroid acoustic space. acoustic space supplied (‘acoustic.space’ argument) function estimates measuring several acoustic parameters using function spectro_analysis() warbleR) summarizing Principal Component Analysis (z-transforming parameters). 1 template required function returns signal closest acoustic space centroid. rationale signal closest average signal structure likely share structural features signals across acoustic space signal periphery space. ‘mean structure’ templates can obtained follows:   , template can used detect similar signals example ‘lbh1’ data:   output object class ‘template_correlations’, printing method:   object can used detect signals using template_detector():   output can explored plotting spectrogram along detection correlation scores:   performance can evaluated using diagnose_detection():  ","code":"# get mean structure template template <- get_templates(reference = lbh1_reference, path = tempdir()) ## The first 2 principal components explained 0.53 of the variance # get correlations correlations <- template_correlator(templates = template, files = \"lbh1.wav\", path = tempdir()) # print correlations ## Object of class 'template_correlations'  ## * The output of the following template_correlator() call:  ## template_correlator(templates = template, files = \"lbh1.wav\",   ##  path = tempdir())  ## * Contains 1 correlation score vector(s) from 1 template(s): ##  lbh1.wav-15  ## ... and 1 sound files(s): ##  lbh1.wav  ##  * Created by ohun 0.1.0 # run detection detection <- template_detector(template.correlations = correlations, threshold = 0.4)  detection ## Object of class 'selection_table'  ## * The output of the following call:  ## template_detector(template.correlations = correlations, threshold = 0.4)  ##  ## Contains:  ## *  A selection table data frame with 27 rows and 6 columns:  ## |sound.files | selec|  start|    end|template    | scores| ## |:-----------|-----:|------:|------:|:-----------|------:| ## |lbh1.wav    |     1| 0.0931| 0.2498|lbh1.wav-15 | 0.6030| ## |lbh1.wav    |     2| 0.1281| 0.2848|lbh1.wav-15 | 0.4416| ## |lbh1.wav    |     3| 0.1514| 0.3080|lbh1.wav-15 | 0.4028| ## |lbh1.wav    |     4| 0.1746| 0.3313|lbh1.wav-15 | 0.4072| ## |lbh1.wav    |     5| 0.5705| 0.7272|lbh1.wav-15 | 0.7269| ## |lbh1.wav    |     6| 0.6054| 0.7621|lbh1.wav-15 | 0.4089| ## ... and 21 more row(s)  ##  ##  * A data frame (check.results) generated by check_sels() (as attribute)  ## created by warbleR 1.1.27 # plot spectrogram label_spectro(wave = lbh1, detection = detection, template.correlation = correlations$`lbh1.wav-10/lbh1.wav`,     flim = c(0, 10), threshold = 0.4, hop.size = 10, ovlp = 50) # diagnose diagnose_detection(reference = lbh1_reference, detection = detection) ##   true.positives false.positives false.negatives split.positives ## 1             10               0               0              10 ##   merged.positives overlap.to.true.positives recall precision f1.score ## 1                0                 0.7230055      1         1        1"},{"path":"https://marce10.github.io/ohun/articles/ohun.html","id":"optimizing-template-based-detection","dir":"Articles","previous_headings":"Detecting signals with ohun > Template-based detection","what":"Optimizing template-based detection","title":"<center><font size=","text":"function optimize_template_detector() allows evaluate performance different correlation thresholds:   Additional threshold values can evaluated without run . just need supplied output previous run argument previous.output (trick can done optimizing energy-based detection):   case several threshold values can achieved optimal detection.  ","code":"# run optimization optimization <- optimize_template_detector(template.correlations = correlations,     reference = lbh1_reference, threshold = seq(0.1, 0.5, 0.1)) ## 5 thresholds will be evaluated: # print output optimization ##   threshold   templates true.positives false.positives false.negatives ## 1       0.1 lbh1.wav-15             10              42               0 ## 2       0.2 lbh1.wav-15             10              22               0 ## 3       0.3 lbh1.wav-15             10               4               0 ## 4       0.4 lbh1.wav-15             10               0               0 ## 5       0.5 lbh1.wav-15             10               0               0 ##   split.positives merged.positives overlap.to.true.positives recall precision ## 1              10                0                 0.5172444      1 0.1923077 ## 2              10                0                 0.5588146      1 0.3125000 ## 3              10                0                 0.6129631      1 0.7142857 ## 4              10                0                 0.7230055      1 1.0000000 ## 5               0                0                 0.9478477      1 1.0000000 ##    f1.score ## 1 0.3225806 ## 2 0.4761905 ## 3 0.8333333 ## 4 1.0000000 ## 5 1.0000000 # run optimization optimize_template_detector(template.correlations = correlations, reference = lbh1_reference,     threshold = c(0.6, 0.7), previous.output = optimization) ## 2 thresholds will be evaluated: ##   threshold   templates true.positives false.positives false.negatives ## 1       0.1 lbh1.wav-15             10              42               0 ## 2       0.2 lbh1.wav-15             10              22               0 ## 3       0.3 lbh1.wav-15             10               4               0 ## 4       0.4 lbh1.wav-15             10               0               0 ## 5       0.5 lbh1.wav-15             10               0               0 ## 6       0.6 lbh1.wav-15              9               0               1 ## 7       0.7 lbh1.wav-15              2               0               8 ##   split.positives merged.positives overlap.to.true.positives recall precision ## 1              10                0                 0.5172444    1.0 0.1923077 ## 2              10                0                 0.5588146    1.0 0.3125000 ## 3              10                0                 0.6129631    1.0 0.7142857 ## 4              10                0                 0.7230055    1.0 1.0000000 ## 5               0                0                 0.9478477    1.0 1.0000000 ## 6               0                0                 0.9551485    0.9 1.0000000 ## 7               0                0                 0.9874463    0.2 1.0000000 ##    f1.score ## 1 0.3225806 ## 2 0.4761905 ## 3 0.8333333 ## 4 1.0000000 ## 5 1.0000000 ## 6 0.9473684 ## 7 0.3333333"},{"path":"https://marce10.github.io/ohun/articles/ohun.html","id":"detecting-several-templates","dir":"Articles","previous_headings":"Detecting signals with ohun > Template-based detection","what":"Detecting several templates","title":"<center><font size=","text":"Several templates can used within call. correlate two templates two example sound files, taking one template sound file:   Note cases can get signal detected several times (duplicates), one template. can check case just diagnosing detection:   Duplicates shown split positives. Fortunately, can leave single detected signal leaving highest correlation. first need label row detection using label_detection() remove duplicates using filter_detection(): function adds column (‘detection.class’) class label row:   Now can filter duplicates diagnose detection , telling function select single row per duplicate using correlation score criterium (= \"scores\", column part template_detector() output):   successfully get rid duplicates detected every single target signal.","code":"# get correlations correlations <- template_correlator(templates = lbh_reference[c(1, 10), ], files = c(\"lbh1.wav\",     \"lbh2.wav\"), path = tempdir())  # run detection detection <- template_detector(template.correlations = correlations, threshold = 0.5) # diagnose diagnose_detection(reference = lbh_reference, detection = detection) ##   true.positives false.positives false.negatives split.positives ## 1             19               0               0               4 ##   merged.positives overlap.to.true.positives recall precision f1.score ## 1                0                 0.9565014      1         1        1 # labeling detection labeled <- label_detection(reference = lbh_reference, detection = detection) table(labeled$detection.class) ##  ##         true.positive true.positive (split)  ##                    15                     8 # filter filtered <- filter_detection(detection = labeled, by = \"scores\")  # diagnose diagnose_detection(reference = lbh_reference, detection = filtered) ##   true.positives false.positives false.negatives split.positives ## 1             19               0               0               0 ##   merged.positives overlap.to.true.positives recall precision f1.score ## 1                0                 0.9501523      1         1        1"},{"path":"https://marce10.github.io/ohun/articles/ohun.html","id":"improving-detection-speed","dir":"Articles","previous_headings":"Detecting signals with ohun","what":"Improving detection speed","title":"<center><font size=","text":"Detection routines can take long time working large amounts acoustic data (e.g. large sound files /many sound files). useful points keep mine trying make routine time-efficient: Always test procedures small data subsets template_detector() faster energy_detector() Parallelization (see parallel argument functions) can significantly speed-routines, works better Unix-based operating systems (linux mac OS) Sampling rate matters: detecting signals low sampling rate files goes faster, avoid nyquist frequencies (sampling rate / 2) way higher highest frequency target signals (sound files can downsampled using warbleR’s fix_sound_files()) Large sound files can make routine crash, use split_acoustic_data() split reference tables files shorter clips. Think using computer lots RAM memory computer cluster working large amounts data thinning argument (reduces size amplitude envelope) can also speed-energy_detector()  ","code":""},{"path":"https://marce10.github.io/ohun/articles/ohun.html","id":"additional-tips","dir":"Articles","previous_headings":"Detecting signals with ohun","what":"Additional tips","title":"<center><font size=","text":"Use knowledge signal structure determine initial range tuning parameters detection optimization routine people hard time figuring target signal occurs recording, detection algorithms also hard time Several templates representing range variation signal structure can used detect semi-stereotyped signals Make sure reference tables contain target signals target signals. performance detection better reference . Avoid overlapping signals several signals single one (like multi-syllable vocalization) reference table running energy-based detector Low-precision can improved training classification model (e.g. random forest) tell signals noise Please cite ohun like : Araya-Salas, M. (2021), ohun: automatic detection acoustic signals. R package version 0.1.0.","code":""},{"path":"https://marce10.github.io/ohun/articles/ohun.html","id":"references","dir":"Articles","previous_headings":"Detecting signals with ohun","what":"References","title":"<center><font size=","text":"Araya-Salas, M. (2021), ohun: automatic detection acoustic signals. R package version 0.1.0. Araya-Salas M, Smith-Vidaurre G (2017) warbleR: R package streamline analysis animal acoustic signals. Methods Ecol Evol 8:184-191. Khanna H., Gaunt S.L.L. & McCallum D.. (1997). Digital spectrographic cross-correlation: tests sensitivity. Bioacoustics 7(3): 209-234. Macmillan, N. ., & Creelman, C.D. (2004). Detection theory: user’s guide. Psychology press.   Session information","code":"## R version 4.2.0 (2022-04-22) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: Ubuntu 22.04 LTS ##  ## Matrix products: default ## BLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.10.0 ## LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.10.0 ##  ## locale: ##  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C               ##  [3] LC_TIME=es_CR.UTF-8        LC_COLLATE=en_US.UTF-8     ##  [5] LC_MONETARY=es_CR.UTF-8    LC_MESSAGES=en_US.UTF-8    ##  [7] LC_PAPER=es_CR.UTF-8       LC_NAME=C                  ##  [9] LC_ADDRESS=C               LC_TELEPHONE=C             ## [11] LC_MEASUREMENT=es_CR.UTF-8 LC_IDENTIFICATION=C        ##  ## attached base packages: ## [1] stats     graphics  grDevices utils     datasets  methods   base      ##  ## other attached packages: ## [1] ohun_0.1.0         warbleR_1.1.27     NatureSounds_1.0.4 knitr_1.39         ## [5] seewave_2.2.0      tuneR_1.4.0        ##  ## loaded via a namespace (and not attached): ##  [1] Rcpp_1.0.8.3      fftw_1.0-7        foreach_1.5.2     assertthat_0.2.1  ##  [5] rprojroot_2.0.3   digest_0.6.29     utf8_1.2.2        R6_2.5.1          ##  [9] Sim.DiffProc_4.8  signal_0.7-7      evaluate_0.15     highr_0.9         ## [13] ggplot2_3.3.6     pillar_1.7.0      rlang_1.0.3       rstudioapi_0.13   ## [17] jquerylib_0.1.4   rmarkdown_2.14    pkgdown_2.0.3     textshaping_0.3.6 ## [21] desc_1.4.1        stringr_1.4.0     RCurl_1.98-1.6    munsell_0.5.0     ## [25] proxy_0.4-26      Deriv_4.1.3       compiler_4.2.0    xfun_0.31         ## [29] pkgconfig_2.0.3   systemfonts_1.0.4 htmltools_0.5.2   tidyselect_1.1.2  ## [33] tibble_3.1.7      gridExtra_2.3     codetools_0.2-18  dtw_1.22-3        ## [37] fansi_1.0.3       viridisLite_0.4.0 crayon_1.5.1      dplyr_1.0.9       ## [41] shinyBS_0.61.1    MASS_7.3-57       bitops_1.0-7      grid_4.2.0        ## [45] jsonlite_1.8.0    gtable_0.3.0      lifecycle_1.0.1   DBI_1.1.2         ## [49] magrittr_2.0.3    formatR_1.12      scales_1.2.0      cli_3.3.0         ## [53] stringi_1.7.6     cachem_1.0.6      pbapply_1.5-0     viridis_0.6.2     ## [57] fs_1.5.2          bslib_0.3.1       ellipsis_0.3.2    ragg_1.2.2        ## [61] vctrs_0.4.1       generics_0.1.2    rjson_0.2.21      iterators_1.0.14  ## [65] tools_4.2.0       glue_1.6.2        purrr_0.3.4       parallel_4.2.0    ## [69] fastmap_1.1.0     yaml_2.3.5        colorspace_2.0-3  soundgen_2.5.1    ## [73] memoise_2.0.1     sass_0.4.1"},{"path":"https://marce10.github.io/ohun/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Marcelo Araya-Salas. Author, maintainer.","code":""},{"path":"https://marce10.github.io/ohun/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Araya-Salas, M. (2021), ohun: automatic detection acoustic signals. R package version 0.1.0","code":"@Misc{,   title = {ohun: automatic detection of acoustic signals},   author = {M. Araya-Salas},   year = {2021}, }"},{"path":"https://marce10.github.io/ohun/index.html","id":"ohun-optimizing-acoustic-signal-detection","dir":"","previous_headings":"","what":"Optimizing acoustic signal detection","title":"Optimizing acoustic signal detection","text":"ohun intended facilitate automatic detection acoustic signals, providing functions diagnose optimize detection routines. main features package : use reference annotations detection diagnostic optimization use signal detection theory indices evaluate detection performance package offers functions : Diagnose detection performance Optimize detection routines based reference annotations Energy-based detection Template-based detection functions allow parallelization tasks, distributes tasks among several processors improve computational efficiency. package works sound files ‘.wav’, ‘.mp3’, ‘.flac’ ‘.wac’ format. install latest developmental version github need R package remotes: Please cite ohun follows: Araya-Salas, M. (2021), ohun: automatic detection acoustic signals. R package version 0.1.0.","code":"remotes::install_github(\"maRce10/ohun\")  #load package library(ohun)"},{"path":"https://marce10.github.io/ohun/reference/diagnose_detection.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate the performance of a signal detection procedure — diagnose_detection","title":"Evaluate the performance of a signal detection procedure — diagnose_detection","text":"diagnose_detection evaluates performance signal detection procedure comparing output selection table reference selection table","code":""},{"path":"https://marce10.github.io/ohun/reference/diagnose_detection.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate the performance of a signal detection procedure — diagnose_detection","text":"","code":"diagnose_detection(reference, detection, by.sound.file = FALSE, time.diagnostics = FALSE, parallel = 1, pb = TRUE, path = NULL)"},{"path":"https://marce10.github.io/ohun/reference/diagnose_detection.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate the performance of a signal detection procedure — diagnose_detection","text":"reference Data frame 'selection.table' (following warbleR package format) reference selections (start end signals) used evaluate performance detection, represented selections 'detection'. Must contained least following columns: \"sound.files\", \"selec\", \"start\" \"end\". must contain reference selections used detection optimization. detection Data frame 'selection.table' detections (start end signals) compared 'reference' selections. Must contained least following columns: \"sound.files\", \"selec\", \"start\" \"end\". can contain data additional sound files found 'references'. case routine assumes signals found files, detection files false positives. .sound.file Logical argument control whether performance diagnostics summarized across sound files (.sound.file = FALSE, 1 sound file included 'reference') shown separated sound file. Default FALSE. time.diagnostics Logical argument control diagnostics related duration signals (\"mean.duration.true.positives\", \"mean.duration.false.positives\", \"mean.duration.false.negatives\" \"proportional.duration.true.positives\") returned (TRUE). Default FALSE. parallel Numeric. Controls whether parallel computing applied. specifies number cores used. Default 1 (.e. parallel computing). pb Logical argument control progress bar. Default TRUE. path Character string containing directory path sound files located. supplied duty cycle (fraction sound file sounds detected)also returned. feature helpful tuning energy-based detection. Default NULL.","code":""},{"path":"https://marce10.github.io/ohun/reference/diagnose_detection.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate the performance of a signal detection procedure — diagnose_detection","text":"data frame including following detection performance diagnostics: true.positives: number signals 'reference' correspond detection. Matching defined degree overlap time. perfect detection routine equal number rows 'reference'. false.positives: number detections match signals 'reference'. perfect detection routine 0. false.negatives: number signals 'reference' detected (found 'detection'. perfect detection routine 0. split.positives: number signals 'reference' overlapped 1 detection (.e. detections split). perfect detection routine 0. merged.positives: number signals 'detection' overlapped 1 detection (.e. signals merged). perfect detection routine 0. mean.duration.true.positives: mean duration true positives (s). included time.diagnostics = TRUE. mean.duration.false.positives: mean duration false positives (s). included time.diagnostics = TRUE. mean.duration.false.negatives: mean duration false negatives (s). included time.diagnostics = TRUE. overlap..true.positives: ratio time overlap true positives 'detection' corresponding reference signal duration reference signal. proportional.duration.true.positives: ratio duration true positives duration signals 'reference'. perfect detection routine 1. Based true positives split merged. duty.cycle: proportion sound file sounds detected. included time.diagnostics = TRUE path supplied. Useful conducting energy-based detection perfect detection can obtained low amplitude threshold, detect everything, produce duty cycle close 1. recall: Proportion signals 'reference' detected. perfect detection routine 1. precision: Proportion detections correspond signals 'reference'. perfect detection routine 1. f1.score: Combines recall precision harmonic mean two. Provides single value evaluating performance. perfect detection routine 1.","code":""},{"path":"https://marce10.github.io/ohun/reference/diagnose_detection.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Evaluate the performance of a signal detection procedure — diagnose_detection","text":"function evaluates performance signal detection procedure comparing output selection table reference selection table signals interest selected.","code":""},{"path":"https://marce10.github.io/ohun/reference/diagnose_detection.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Evaluate the performance of a signal detection procedure — diagnose_detection","text":"Araya-Salas, M. (2021), ohun: automatic detection acoustic signals. R package version 0.1.0.","code":""},{"path":[]},{"path":"https://marce10.github.io/ohun/reference/diagnose_detection.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Evaluate the performance of a signal detection procedure — diagnose_detection","text":"Marcelo Araya-Salas marcelo.araya@ucr.ac.cr)","code":""},{"path":"https://marce10.github.io/ohun/reference/diagnose_detection.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Evaluate the performance of a signal detection procedure — diagnose_detection","text":"","code":"{ # load data data(\"lbh_reference\")  # perfect detection diagnose_detection(reference = lbh_reference, detection = lbh_reference)  # missing one in detection diagnose_detection(reference = lbh_reference, detection = lbh_reference[-1, ])  # an extra one in detection diagnose_detection(reference = lbh_reference[-1, ], detection = lbh_reference)  # with time diagnostics diagnose_detection(reference = lbh_reference[-1, ], detection = lbh_reference, time.diagnostics = TRUE)  # and extra sound file in reference diagnose_detection(reference = lbh_reference, detection = lbh_reference[lbh_reference$sound.files != \"lbh1\", ])  # and extra sound file in detection diagnose_detection(reference = lbh_reference[lbh_reference$sound.files != \"lbh1\", ], detection = lbh_reference)  # and extra sound file in detection by sound file dd <- diagnose_detection(reference = lbh_reference[lbh_reference$sound.files != \"lbh1\", ], detection = lbh_reference, time.diagnostics = TRUE, by.sound.file = TRUE)  # get summary summarize_diagnostic(dd) }"},{"path":"https://marce10.github.io/ohun/reference/energy_detector.html","id":null,"dir":"Reference","previous_headings":"","what":"Detects the start and end of acoustic signals — energy_detector","title":"Detects the start and end of acoustic signals — energy_detector","text":"energy_detector detects start end acoustic signals based energy time attributes","code":""},{"path":"https://marce10.github.io/ohun/reference/energy_detector.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Detects the start and end of acoustic signals — energy_detector","text":"","code":"energy_detector(files = NULL, envelopes = NULL, path = \".\", hop.size = 11.6, wl = NULL, thinning = 1, bp = NULL, smooth = 5, threshold = 5, peak.amplitude = 0, hold.time = 0, min.duration = 0, max.duration = Inf, parallel = 1, pb = TRUE)"},{"path":"https://marce10.github.io/ohun/reference/energy_detector.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Detects the start and end of acoustic signals — energy_detector","text":"files Character vector indicating sound files analyzed. Optional. 'files' 'envelopes' supplied function work supported format sound files working directory. envelopes object class 'envelopes' (generated get_envelopes) containing amplitude envelopes sound files analyzed. 'files' 'envelopes' supplied function work supported format sound files working directory. path Character string containing directory path sound files located. current working directory used default. hop.size numeric vector length 1 specifying time window duration (ms). Default 11.6 ms, equivalent 512 wl 44.1 kHz sampling rate. Ignored 'wl' supplied. wl numeric vector length 1 specifying window length spectrogram. Default NULL. supplied, 'hop.size' ignored. Used internally bandpass filtering (applied 'bp' supplied). thinning Numeric vector length 1 range 0~1 indicating proportional reduction number samples used represent amplitude envelopes (.e. thinning envelopes). Usually amplitude envelopes many samples needed accurately represent amplitude variation time, affects size output (usually large R objects / files). Default 1 (thinning). Higher sampling rates can afford higher size reduction (e.g. lower thinning values). Reduction conducted interpolation using approx. Note thinning may decrease time precision, higher thinning less precise time detection. argument used internally get_envelopes. used 'envelopes' supplied. bp Numeric vector length 2 giving lower upper limits frequency bandpass filter (kHz). Default NULL. argument used internally get_envelopes. used 'envelopes' supplied. smooth numeric vector length 1 smooth amplitude envelope sum smooth function. controls time 'neighborhood' (ms) amplitude samples smoothed (.e. averaged neighboring samples). Default 5. 0 means smoothing applied. Note smoothing applied thinning (see 'thinning' argument). argument used internally get_envelopes. used 'envelopes' supplied. threshold Numeric vector length 1 value 0 100 specifying amplitude threshold detecting signal occurrences. Amplitude represented percentage 0 100 represent lowest amplitude highest amplitude respectively. Default 5. peak.amplitude Numeric vector length 1 minimum peak amplitude value. Detections value excluded. Peak amplitude maximum sound pressure level (decibels) across signal (see sound_pressure_level). can useful expecting higher peak amplitude target signals compared non-target signals keeping best examples target signals. Default 0. hold.time Numeric vector length 1. Specifies time range (ms) selections merged (.e. 2 selections separated less specified 'hold.time' merged single selection). Default 0 (hold time applied). min.duration Numeric vector length 1 giving shortest duration (ms) signals detected. removes signals threshold. 'hold.time' supplied signals first merged filtered duration. Default 0 (.e. filtering based minimum duration). max.duration Numeric vector length 1 giving longest duration (ms) signals detected. removes signals threshold. 'hold.time' supplied signals first merged filtered duration.  Default Inf (.e. filtering based maximum duration). parallel Numeric. Controls whether parallel computing applied. specifies number cores used. Default 1 (.e. parallel computing). pb Logical argument control progress bar. Default TRUE.","code":""},{"path":"https://marce10.github.io/ohun/reference/energy_detector.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Detects the start and end of acoustic signals — energy_detector","text":"function returns 'selection_table' (warbleR package's formats, see selection_table) data frame (sound files found) containing start end signal   sound file. signal detected sound file included output data frame.","code":""},{"path":"https://marce10.github.io/ohun/reference/energy_detector.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Detects the start and end of acoustic signals — energy_detector","text":"function detects time position target signals based energy time thresholds. first detect sound given energy threshold (argument 'energy'). 'hold.time' supplied detected sounds merged necessary. sounds detected filtered based duration attributes ('min.duration' 'max.duration'). 'peak.amplitude' higher 0 signals higher peak amplitude kept. Band pass filtering ('bp'), thinning ('thinning') envelope smoothing ('smooth') applied (supplied) threshold detection.","code":""},{"path":"https://marce10.github.io/ohun/reference/energy_detector.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Detects the start and end of acoustic signals — energy_detector","text":"Araya-Salas, M. (2021), ohun: automatic detection acoustic signals. R package version 0.1.0.","code":""},{"path":[]},{"path":"https://marce10.github.io/ohun/reference/energy_detector.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Detects the start and end of acoustic signals — energy_detector","text":"Marcelo Araya-Salas (marcelo.araya@ucr.ac.cr). Implements modified version timer function seewave.","code":""},{"path":"https://marce10.github.io/ohun/reference/energy_detector.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Detects the start and end of acoustic signals — energy_detector","text":"","code":"{ # Save example files into temporary working directory data(\"lbh1\", \"lbh2\", \"lbh_reference\") writeWave(lbh1, file.path(tempdir(), \"lbh1.wav\")) writeWave(lbh2, file.path(tempdir(), \"lbh2.wav\"))  # using smoothing and minimum duration detec <- energy_detector(files = c(\"lbh1.wav\", \"lbh2.wav\"), path = tempdir(), threshold = 60, smooth = 6.8, bp = c(2, 9), hop.size = 6.8, min.duration = 0.09)  # diagnose detection diagnose_detection(reference = lbh_reference, detection = detec)  # without declaring 'files' detec <- energy_detector(path = tempdir(), threshold = 60, smooth = 6.8, bp = c(2, 9), hop.size = 6.8, min.duration = 90)  # diagnose detection diagnose_detection(reference = lbh_reference, detection = detec)  # using hold time detec <- energy_detector(threshold = 10, hold.time = 150, bp = c(2, 9), hop.size = 6.8, path = tempdir())  # diagnose detection diagnose_detection(reference = lbh_reference, detection = detec)  # calculate envelopes first envs <- get_envelopes(bp = c(2, 9), hop.size = 6.8, path = tempdir())  # then run detection providing 'envelopes' (but no 'files') detec <- energy_detector(envelopes = envs, threshold = 10, hold.time = 150, min.duration = 50)  # diagnose detection diagnose_detection(reference = lbh_reference, detection = detec, time.diagnostics = TRUE)  if (FALSE) { # USIN OTHER SOUND FILE FORMAT (flac program must be installed)  # fisrt convert files to flac  warbleR::wav_2_flac(path = tempdir())   # change sound file extension to flac  flac_reference <- lbh_reference  flac_reference$sound.files <- gsub(\".wav\", \".flac\", flac_reference$sound.files)   # run detection  detec <- energy_detector(files = c(\"lbh1.flac\", \"lbh2.flac\"), path = tempdir(), threshold = 60,  smooth = 6.8, bp = c(2, 9), hop.size = 6.8, min.duration = 90)   # diagnose detection  diagnose_detection(reference = flac_reference, detection = detec)  } }"},{"path":"https://marce10.github.io/ohun/reference/feature_reference.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract quantitative features of references — feature_reference","title":"Extract quantitative features of references — feature_reference","text":"feature_reference extracts quantitative characteristics reference table","code":""},{"path":"https://marce10.github.io/ohun/reference/feature_reference.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract quantitative features of references — feature_reference","text":"","code":"feature_reference(reference, path = NULL, by.sound.file = FALSE, units = c(\"ms\", \"kHz\"), digits = 2)"},{"path":"https://marce10.github.io/ohun/reference/feature_reference.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract quantitative features of references — feature_reference","text":"reference Data frame 'selection.table' (following warbleR package format) reference selections (start end signals) used evaluate performance detection, represented selections 'detection'. Must contained least following columns: \"sound.files\", \"selec\", \"start\" \"end\". frequency range columns included (\"bottom.freq\" \"top.freq\") also used characterize reference selections. path Character string containing directory path sound files located. supplied duty cycle peak frequency features returned. features helpful tuning energy-based detection. Default NULL. .sound.file Logical argument control whether features summarized across sound files (.sound.file = FALSE, 1 sound file included 'reference') shown separated sound file. Default FALSE. units character vector length 2 units used time frequency parameters, order. Default c(\"ms\", \"kHz\"). can also take 's' 'Hz'. digits Numeric vector length 1 number decimals include. Default 2.","code":""},{"path":"https://marce10.github.io/ohun/reference/feature_reference.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract quantitative features of references — feature_reference","text":"function returns mean, minimum maximum duration selections gaps (time intervals selections). frequency range columns included reference table (.e. \"bottom.freq\" \"top.freq\") minimum bottom frequency ('min.bottom.freq') maximum top frequency ('max.top.freq') also estimated. Finally, path sound files 'reference' supplied duty cycle (fraction sound file sounds detected) peak amplitude (highest amplitude detection) also returned. `.sound.file = FALSE` matrix features rows returned. Otherwise data frame returned row correspond sound file. default, time features returned 'ms' frequency features 'kHz' (see 'units' argument).","code":""},{"path":"https://marce10.github.io/ohun/reference/feature_reference.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract quantitative features of references — feature_reference","text":"function extract quantitative features reference tables can inform range values used energy-based detection optimization routine. Features related selection duration can used set 'max.duration' 'min.duration' values, frequency related features can inform banpass values, gap related features inform hold time values duty cycle can used evaluate performance.","code":""},{"path":"https://marce10.github.io/ohun/reference/feature_reference.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Extract quantitative features of references — feature_reference","text":"Araya-Salas, M. (2021), ohun: automatic detection acoustic signals. R package version 0.1.0.","code":""},{"path":[]},{"path":"https://marce10.github.io/ohun/reference/feature_reference.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extract quantitative features of references — feature_reference","text":"Marcelo Araya-Salas marcelo.araya@ucr.ac.cr)","code":""},{"path":"https://marce10.github.io/ohun/reference/feature_reference.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract quantitative features of references — feature_reference","text":"","code":"{ # load data and save example files into temporary working directory data(\"lbh1\", \"lbh2\", \"lbh_reference\") writeWave(lbh1, file.path(tempdir(), \"lbh1.wav\")) writeWave(lbh2, file.path(tempdir(), \"lbh2.wav\"))  # summary across sound files feature_reference(reference = lbh_reference, path = tempdir())  # summary across sound files feature_reference(reference = lbh_reference, by.sound.file = TRUE, path = tempdir()) }"},{"path":"https://marce10.github.io/ohun/reference/filter_detection.html","id":null,"dir":"Reference","previous_headings":"","what":"Remove ambiguous detections — filter_detection","title":"Remove ambiguous detections — filter_detection","text":"filter_detection removes ambiguous detections (split merged detections)","code":""},{"path":"https://marce10.github.io/ohun/reference/filter_detection.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Remove ambiguous detections — filter_detection","text":"","code":"filter_detection(detection, by = \"overlap\", filter = \"max\", parallel = 1, pb = TRUE)"},{"path":"https://marce10.github.io/ohun/reference/filter_detection.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Remove ambiguous detections — filter_detection","text":"detection Data frame selection table (using warbleR package's format, see selection_table) output label_detection containing start end signals. Must contained least following columns: \"sound.files\", \"selec\", \"start\", \"end\", \"detection.class\" \"reference.row\" (last 2 generated label_detection). must also contained column indicated '' argument. Character vector length 1 indicating column 'detection' used filter delections. Must refer numeric column. Default 'overlap', return label_detection. filter Character vector length 1 indicating criterium used filter column refer '' argument. Current options 'max' (maximum) 'min' (minimum). Default 'max'. parallel Numeric. Controls whether parallel computing applied. specifies number cores used. Default 1 (.e. parallel computing). pb Logical argument control progress bar. Default TRUE.","code":""},{"path":"https://marce10.github.io/ohun/reference/filter_detection.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Remove ambiguous detections — filter_detection","text":"data frame selection table ('detection' also selection table, warbleR package's format, see selection_table) 'X' removing ambiguous detections (split merged positives).","code":""},{"path":"https://marce10.github.io/ohun/reference/filter_detection.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Remove ambiguous detections — filter_detection","text":"function removes ambiguous detections (split merged detections, see diagnose_detection) keeping one maximizes criterium given 'filter'. default keeps detection highest overlap reference signal. works output label_detection.","code":""},{"path":"https://marce10.github.io/ohun/reference/filter_detection.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Remove ambiguous detections — filter_detection","text":"#' Araya-Salas, M. (2021), ohun: automatic detection acoustic signals. R package version 0.1.0.","code":""},{"path":[]},{"path":"https://marce10.github.io/ohun/reference/filter_detection.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Remove ambiguous detections — filter_detection","text":"Marcelo Araya-Salas (marcelo.araya@ucr.ac.cr).","code":""},{"path":"https://marce10.github.io/ohun/reference/filter_detection.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Remove ambiguous detections — filter_detection","text":"","code":"{ # load example data data(\"lbh1\", \"lbh_reference\")  # save sound files writeWave(lbh1, file.path(tempdir(), \"lbh1.wav\"))  # template for the first sound file in 'lbh_reference' templ1 <- lbh_reference[1, ]  # generate template correlations tc <- template_correlator(templates = templ1, path = tempdir(), files = \"lbh1.wav\")  # template detection td <- template_detector(template.correlations = tc, threshold = 0.12)  # this detection generates 2 split positives diagnose_detection(reference = lbh_reference[lbh_reference == \"lbh1.wav\", ], detection = td)  # label detection ltd <- label_detection(reference = lbh_reference[lbh_reference == \"lbh1.wav\", ], detection = td)  # now they can be filter to keep the detection with the highest score for each split ftd <- filter_detection(ltd)  # splits must be 0 diagnose_detection(reference = lbh_reference[lbh_reference == \"lbh1.wav\", ], detection = ftd) }"},{"path":"https://marce10.github.io/ohun/reference/get_envelopes.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract absolute amplitude envelopes — get_envelopes","title":"Extract absolute amplitude envelopes — get_envelopes","text":"get_envelopes extracts absolute amplitude envelopes speed energy detection","code":""},{"path":"https://marce10.github.io/ohun/reference/get_envelopes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract absolute amplitude envelopes — get_envelopes","text":"","code":"get_envelopes(path = \".\", files = NULL, bp = NULL, hop.size = 11.6, wl = NULL, parallel = 1, thinning = 1, pb = TRUE, smooth = 5, normalize = TRUE)"},{"path":"https://marce10.github.io/ohun/reference/get_envelopes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract absolute amplitude envelopes — get_envelopes","text":"path Character string containing directory path sound files located. current working directory used default. files character vector indicating sound files analyzed. bp Numeric vector length 2 giving lower upper limits frequency bandpass filter (kHz). Default NULL. hop.size numeric vector length 1 specifying time window duration (ms). Default 11.6 ms, equivalent 512 wl 44.1 kHz sampling rate. Ignored 'wl' supplied. wl numeric vector length 1 specifying window length spectrogram. Default NULL. supplied, 'hop.size' ignored. Used internally bandpass filtering (applied 'bp' supplied). parallel Numeric. Controls whether parallel computing applied. specifies number cores used. Default 1 (.e. parallel computing). thinning Numeric vector length 1 range 0~1 indicating proportional reduction number samples used represent amplitude envelopes (.e. thinning envelopes). Usually amplitude envelopes many samples needed accurately represent amplitude variation time, affects size output (usually large R objects / files). Default 1 (thinning). Higher sampling rates can afford higher size reduction (e.g. lower thinning values). Reduction conducted linear interpolation using approx. Note thinning may decrease time precision higher thinning less precise time detection. generally advised smoothing ('smooth' argument) applied. pb Logical argument control progress bar. Default TRUE. smooth numeric vector length 1 smooth amplitude envelope sum smooth function. controls time range (ms) amplitude samples smoothed (.e. averaged neighboring samples). Default 5. 0 means smoothing applied. Note smoothing applied thinning (see 'thinning' argument). normalize Logical argument control envelopes normalized 0-1 range.","code":""},{"path":"https://marce10.github.io/ohun/reference/get_envelopes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract absolute amplitude envelopes — get_envelopes","text":"object class 'envelopes'.","code":""},{"path":"https://marce10.github.io/ohun/reference/get_envelopes.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract absolute amplitude envelopes — get_envelopes","text":"function extracts absolute amplitude envelopes sound files. Can used manipulate envelopes running energy_detector.","code":""},{"path":"https://marce10.github.io/ohun/reference/get_envelopes.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Extract absolute amplitude envelopes — get_envelopes","text":"Araya-Salas, M., & Smith-Vidaurre, G. (2017). warbleR: R package streamline analysis animal acoustic signals. Methods Ecology Evolution, 8(2), 184-191.","code":""},{"path":[]},{"path":"https://marce10.github.io/ohun/reference/get_envelopes.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extract absolute amplitude envelopes — get_envelopes","text":"Marcelo Araya-Salas (marcelo.araya@ucr.ac.cr).","code":""},{"path":"https://marce10.github.io/ohun/reference/get_envelopes.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract absolute amplitude envelopes — get_envelopes","text":"","code":"{ # Save to temporary working directory data(list = c(\"lbh1\", \"lbh2\")) writeWave(lbh1, file.path(tempdir(), \"lbh1.wav\")) writeWave(lbh2, file.path(tempdir(), \"lbh2.wav\"))  # get raw absolute amplitude envelopes envs <- get_envelopes(path = tempdir())  # extract segment for the first signal in the first sound file x <- envs[[1]]$envelope  # and plot it plot(x[(length(x)/9):(length(x)/4)], type = \"l\", xlab = \"samples\", ylab = \"amplitude\")  # smoothing envelopes envs <- get_envelopes(path = tempdir(), smooth = 6.8) x <- envs[[1]]$envelope plot(x[(length(x)/9):(length(x)/4)], type = \"l\", xlab = \"samples\", ylab = \"amplitude\")  # smoothing and thinning envs <- get_envelopes(path = tempdir(), thinning = 1/10, smooth = 6.8) x <- envs[[1]]$envelope plot(x[(length(x)/9):(length(x)/4)], type = \"l\", xlab = \"samples\", ylab = \"amplitude\")  # no normalization envs <- get_envelopes(path = tempdir(), thinning = 1/10, smooth = 6.8) x <- envs[[1]]$envelope plot(x[(length(x)/9):(length(x)/4)], type = \"l\", xlab = \"samples\", ylab = \"amplitude\", normalize = FALSE) }"},{"path":"https://marce10.github.io/ohun/reference/get_templates.html","id":null,"dir":"Reference","previous_headings":"","what":"Find templates more similar to other signals in a reference table — get_templates","title":"Find templates more similar to other signals in a reference table — get_templates","text":"get_templates find signals closer acoustic space  centroid (.e. close average acoustic structure) reference table.","code":""},{"path":"https://marce10.github.io/ohun/reference/get_templates.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find templates more similar to other signals in a reference table — get_templates","text":"","code":"get_templates(reference, acoustic.space = NULL, path = \".\", n.sub.spaces = 1, plot = TRUE, color = \"#21908C4D\", ...)"},{"path":"https://marce10.github.io/ohun/reference/get_templates.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find templates more similar to other signals in a reference table — get_templates","text":"reference Selection table (using warbleR package's format, see selection_table) data frame columns sound file name (sound.files), selection number (selec), start end time signal (start end). acoustic.space Numeric matrix data frame two dimensions custom acoustic space used finding templates. supplied acoustic space calculated internally (default). Optional. Note function assumes 'reference' 'acoustic.space' refer signals similarly ordered. path Character string containing directory path sound files located. current working directory used default. n.sub.spaces Integer vector length 1 number sub-spaces split total acoustic space. 1 signal closer centroid returned. higher 1 function returns additional signals closer centroids sub-spaces. , function defines sub-spaces equal-size slices circle centered centroid acoustic space. plot Logical control plot created. Default TRUE. color Character string point color. Default '#21908C4D'. ... Additional arguments passed spectro_analysis customization measuring parameters calculate acoustic space.","code":""},{"path":"https://marce10.github.io/ohun/reference/get_templates.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find templates more similar to other signals in a reference table — get_templates","text":"function returns 'selection_table' (warbleR package's formats, see selection_table) data frame (sound files found) containing start end signal   sound file. signal detected sound file included output data frame.","code":""},{"path":"https://marce10.github.io/ohun/reference/get_templates.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Find templates more similar to other signals in a reference table — get_templates","text":"function finds signals reference table representative acoustic variation. done finding signals closer centroid acoustic space. acoustic space supplied ('acoustic.space' argument) function estimate measuring several acoustic parameters using function spectro_analysis summarizing Principal Component Analysis (z-transforming parameters) using function prcomp. rationale signal closest average signal structure likely share structural features signals across acoustic space signal periphery space. 1 template required function returns closest acoustic space centroid. 1 templated required additional signals returned representative acoustic space. , function defines sub-spaces equal-size slices circle centered centroid acoustic space. column 'template' included output selection table identifies template. Custom acoustic spaces can supplied argument 'acoustic.space'.","code":""},{"path":"https://marce10.github.io/ohun/reference/get_templates.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Find templates more similar to other signals in a reference table — get_templates","text":"Araya-Salas, M. (2021), ohun: automatic detection acoustic signals. R package version 0.1.0.","code":""},{"path":[]},{"path":"https://marce10.github.io/ohun/reference/get_templates.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Find templates more similar to other signals in a reference table — get_templates","text":"Marcelo Araya-Salas (marcelo.araya@ucr.ac.cr). Implements modified version timer function seewave.","code":""},{"path":"https://marce10.github.io/ohun/reference/get_templates.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Find templates more similar to other signals in a reference table — get_templates","text":"","code":"{ # Save example files into temporary working directory data(\"lbh1\", \"lbh2\", \"lbh_reference\") writeWave(lbh1, file.path(tempdir(), \"lbh1.wav\")) writeWave(lbh2, file.path(tempdir(), \"lbh2.wav\"))  # get a single mean template template <- get_templates(reference = lbh_reference, path = tempdir())  # get 3 templates template <- get_templates(reference = lbh_reference, n.sub.spaces = 3, path = tempdir()) }"},{"path":"https://marce10.github.io/ohun/reference/label_detection.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate the performance of a signal detection procedure — label_detection","title":"Evaluate the performance of a signal detection procedure — label_detection","text":"label_detection evaluates performance signal detection procedure comparing output selection table reference selection table","code":""},{"path":"https://marce10.github.io/ohun/reference/label_detection.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate the performance of a signal detection procedure — label_detection","text":"","code":"label_detection(reference, detection, parallel = 1, pb = TRUE)"},{"path":"https://marce10.github.io/ohun/reference/label_detection.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate the performance of a signal detection procedure — label_detection","text":"reference Data frame 'selection.table' (following warbleR package format) reference selections (start end signals) used evaluate performance detection, represented selections 'detection'. Must contained least following columns: \"sound.files\", \"selec\", \"start\" \"end\". must contain reference selections used detection optimization. detection Data frame 'selection.table' detections (start end signals) compared 'reference' selections. Must contained least following columns: \"sound.files\", \"selec\", \"start\" \"end\". can contain data additional sound files found 'references'. case routine assumes signals found files, detection files false positives. parallel Numeric. Controls whether parallel computing applied. specifies number cores used. Default 1 (.e. parallel computing). pb Logical argument control progress bar. Default TRUE.","code":""},{"path":"https://marce10.github.io/ohun/reference/label_detection.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate the performance of a signal detection procedure — label_detection","text":"data frame selection table ('detection' also selection table, warbleR package's format, see selection_table) including columns 'detection' plus 3 additional columns: detection.class: indicates class detection. Five possible labels: 'true.positive', 'false.positive', 'true.positive (split)', 'true.positive (merged)' 'true.positive (split/merged)'.  See diagnose_detection description. reference.row: contains index row 'reference' corresponds detected signal (supplied true positives). overlap: contains proportion reference signal overlapped time detection (supplied true positives).","code":""},{"path":"https://marce10.github.io/ohun/reference/label_detection.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Evaluate the performance of a signal detection procedure — label_detection","text":"function identifies rows output detection routine true false positives. achieved comparing data frame reference selection table signals interest selected.","code":""},{"path":"https://marce10.github.io/ohun/reference/label_detection.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Evaluate the performance of a signal detection procedure — label_detection","text":"Araya-Salas, M. (2021), ohun: automatic detection acoustic signals. R package version 0.1.0.","code":""},{"path":[]},{"path":"https://marce10.github.io/ohun/reference/label_detection.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Evaluate the performance of a signal detection procedure — label_detection","text":"Marcelo Araya-Salas marcelo.araya@ucr.ac.cr)","code":""},{"path":"https://marce10.github.io/ohun/reference/label_detection.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Evaluate the performance of a signal detection procedure — label_detection","text":"","code":"{ # load data data(\"lbh_reference\")  # an extra one in detection (1 false positive) label_detection(reference = lbh_reference[-1, ], detection = lbh_reference)  # missing one in detection (all true positives) label_detection(reference = lbh_reference, detection = lbh_reference[-1, ])  # perfect detection (all true positives) label_detection(reference = lbh_reference, detection = lbh_reference)  # and extra sound file in reference (all true positives) label_detection(reference = lbh_reference, detection = lbh_reference[lbh_reference$sound.files != \"lbh1.wav\", ])  # and extra sound file in detection (some false positives) label_detection(reference = lbh_reference[lbh_reference$sound.files != \"lbh1.wav\", ], detection = lbh_reference)  # duplicate 1 detection row (to get 2 splits) label_detection(reference = lbh_reference, detection = lbh_reference[c(1, 1:nrow(lbh_reference)), ])  # merge 2 detections (to get split and merge) Y <- lbh_reference Y$end[1] <- 1.2 label_detection(reference = lbh_reference, detection = Y)  # remove split to get only merge Y <- Y[-2, ] label_detection(reference = lbh_reference, detection = Y) }"},{"path":"https://marce10.github.io/ohun/reference/label_spectro.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot a labeled spectrogram — label_spectro","title":"Plot a labeled spectrogram — label_spectro","text":"label_spectro plot spectrogram along amplitude envelopes cross-corelation scores","code":""},{"path":"https://marce10.github.io/ohun/reference/label_spectro.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot a labeled spectrogram — label_spectro","text":"","code":"label_spectro(wave, reference = NULL, detection = NULL,  envelope = FALSE, threshold = NULL, smooth = 5, collevels = seq(-100, 0, 5),  palette = viridis::viridis, template.correlation = NULL,  line.x.position = 2, hop.size = NULL, ...)"},{"path":"https://marce10.github.io/ohun/reference/label_spectro.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot a labeled spectrogram — label_spectro","text":"wave 'wave' class object. reference Data frame 'selection.table' (following warbleR package format) reference selections (start end signals). Must contained least following columns: \"sound.files\", \"selec\", \"start\" \"end\". detection Data frame 'selection.table' detection (start end signals) Must contained least following columns: \"sound.files\", \"selec\", \"start\" \"end\". envelope Logical control whether amplitude envelope plotted. Default FALSE. threshold numeric vector length 1 indicated amplitude correlation threshold plot envelope correlation scores respectively. Default NULL. smooth numeric vector length 1 smooth amplitude envelope sum smooth function. controls time range (ms) amplitude samples smoothed (.e. averaged neighboring samples). Default 5. 0 means smoothing applied. collevels Numeric sequence negative numbers control color partitioning amplitude values shown (spectro). palette Function color palette used spectrogram (spectro) template.correlation List extracted output template_correlator containing correlation scores metadata specific sound file/template dyad. instance 'correlations[[1]]' 'correlations' output template_correlator call. supplied correlation also plotted. Default NULL. line.x.position Numeric vector length 1 position frequency axis (kHz) lines highlighting signals. Default 2. hop.size numeric vector length 1 specifying time window duration (ms). Default 11.6 ms, equivalent 512 'wl' 44.1 kHz sampling rate. ... Additional arguments passed  spectro spectrogram customization.","code":""},{"path":"https://marce10.github.io/ohun/reference/label_spectro.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot a labeled spectrogram — label_spectro","text":"spectrogram along lines highlighting position signals 'reference' /'detection'. supplied also plot amplitude envelope corelation scores spectroram.","code":""},{"path":"https://marce10.github.io/ohun/reference/label_spectro.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot a labeled spectrogram — label_spectro","text":"function plots spectrograms annotated position signals. Mostly created graphs included vignette. works single 'wave' object time.","code":""},{"path":"https://marce10.github.io/ohun/reference/label_spectro.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Plot a labeled spectrogram — label_spectro","text":"#' Araya-Salas, M. (2021), ohun: automatic detection acoustic signals. R package version 0.1.0.","code":""},{"path":[]},{"path":"https://marce10.github.io/ohun/reference/label_spectro.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Plot a labeled spectrogram — label_spectro","text":"Marcelo Araya-Salas (marcelo.araya@ucr.ac.cr).","code":""},{"path":"https://marce10.github.io/ohun/reference/label_spectro.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot a labeled spectrogram — label_spectro","text":"","code":"{ # load example data data(list = \"lbh1\", \"lbh_reference\")  # adding labels label_spectro(wave = lbh1, reference = lbh_reference[lbh_reference$sound.files == \"lbh1.wav\", ], wl = 200, ovlp = 50, flim = c(1, 10))  # adding envelope label_spectro(wave = lbh1, detection = lbh_reference[lbh_reference$sound.files == \"lbh1.wav\", ], wl = 200, ovlp = 50, flim = c(1, 10))  # see the package vignette for more examples }"},{"path":"https://marce10.github.io/ohun/reference/lbh1.html","id":null,"dir":"Reference","previous_headings":"","what":"Long-billed hermit recording — lbh1","title":"Long-billed hermit recording — lbh1","text":"lbh1 wave object long-billed hermit songs extracted xeno-cantos '154138' recording.","code":""},{"path":"https://marce10.github.io/ohun/reference/lbh1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Long-billed hermit recording — lbh1","text":"","code":"data(lbh1)"},{"path":"https://marce10.github.io/ohun/reference/lbh1.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Long-billed hermit recording — lbh1","text":"object class Wave length 110250.","code":""},{"path":"https://marce10.github.io/ohun/reference/lbh1.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Long-billed hermit recording — lbh1","text":"Marcelo Araya Salas, warbleR","code":""},{"path":"https://marce10.github.io/ohun/reference/lbh2.html","id":null,"dir":"Reference","previous_headings":"","what":"Long-billed hermit recording — lbh2","title":"Long-billed hermit recording — lbh2","text":"lbh2 wave object long-billed hermit songs extracted xeno-cantos '154129' recording.","code":""},{"path":"https://marce10.github.io/ohun/reference/lbh2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Long-billed hermit recording — lbh2","text":"","code":"data(lbh2)"},{"path":"https://marce10.github.io/ohun/reference/lbh2.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Long-billed hermit recording — lbh2","text":"object class Wave length 110250.","code":""},{"path":"https://marce10.github.io/ohun/reference/lbh2.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Long-billed hermit recording — lbh2","text":"Marcelo Araya Salas, warbleR","code":""},{"path":"https://marce10.github.io/ohun/reference/lbh_reference.html","id":null,"dir":"Reference","previous_headings":"","what":"Example data frame of a selection table including all signals of interests. — lbh_reference","title":"Example data frame of a selection table including all signals of interests. — lbh_reference","text":"lbh_reference data frame containing start, end, bottom top frequency songs 'lbh_1.wav' 'lbh_2.wav' recordings. #'","code":""},{"path":"https://marce10.github.io/ohun/reference/lbh_reference.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Example data frame of a selection table including all signals of interests. — lbh_reference","text":"","code":"data(lbh_reference)"},{"path":"https://marce10.github.io/ohun/reference/lbh_reference.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Example data frame of a selection table including all signals of interests. — lbh_reference","text":"data frame 19 rows 6 variables: sound.files recording names selec selection numbers within recording start start times selected signal end end times selected signal bottom.freq lower limit frequency range top.freq upper limit frequency range","code":""},{"path":"https://marce10.github.io/ohun/reference/lbh_reference.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Example data frame of a selection table including all signals of interests. — lbh_reference","text":"Marcelo Araya-Salas, ohun","code":""},{"path":"https://marce10.github.io/ohun/reference/lbh_reference.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Example data frame of a selection table including all signals of interests. — lbh_reference","text":"data frame containing start, end, low high frequency Phaethornis longirostris (Long-billed Hermit) songs 2 example sound files included package ('lbh_1' 'lbh_2'). two files clips extracted xeno-canto's '154138' '154129' recordings respectively.","code":""},{"path":"https://marce10.github.io/ohun/reference/merge_overlaps.html","id":null,"dir":"Reference","previous_headings":"","what":"Merge overlapping selections — merge_overlaps","title":"Merge overlapping selections — merge_overlaps","text":"merge_overlaps merges several overlapping selections single selection","code":""},{"path":"https://marce10.github.io/ohun/reference/merge_overlaps.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Merge overlapping selections — merge_overlaps","text":"","code":"merge_overlaps(X, pb = TRUE, parallel = 1)"},{"path":"https://marce10.github.io/ohun/reference/merge_overlaps.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Merge overlapping selections — merge_overlaps","text":"X Data frame 'selection.table' (following warbleR package format) selections (start end signals). Must contained least following columns: \"sound.files\", \"selec\", \"start\" \"end\". pb Logical argument control progress bar. Default TRUE. parallel Numeric. Controls whether parallel computing applied. specifies number cores used. Default 1 (.e. parallel computing).","code":""},{"path":"https://marce10.github.io/ohun/reference/merge_overlaps.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Merge overlapping selections — merge_overlaps","text":"time-overlapping selection found returns data frame overlapping selections collapse single selection.","code":""},{"path":"https://marce10.github.io/ohun/reference/merge_overlaps.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Merge overlapping selections — merge_overlaps","text":"function finds time-overlapping selection reference tables collapses single selection. can useful prepare reference tables used energy detection routine. cases overlapping selections expected detected single sound. Therefore, merging can useful prepare references format representing realistic expectation pefect energy detection routine look like.","code":""},{"path":"https://marce10.github.io/ohun/reference/merge_overlaps.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Merge overlapping selections — merge_overlaps","text":"Araya-Salas, M. (2021), ohun: automatic detection acoustic signals. R package version 0.1.0.","code":""},{"path":[]},{"path":"https://marce10.github.io/ohun/reference/merge_overlaps.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Merge overlapping selections — merge_overlaps","text":"Marcelo Araya-Salas marcelo.araya@ucr.ac.cr)","code":""},{"path":"https://marce10.github.io/ohun/reference/merge_overlaps.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Merge overlapping selections — merge_overlaps","text":"","code":"{ # load data data(\"lbh_reference\")  # nothing to merge merge_overlaps(lbh_reference)  # create artificial overlapping selections lbh_ref2 <- rbind(as.data.frame(lbh_reference[c(3, 10), ]), lbh_reference[c(3, 10), ])  lbh_ref2$selec <- 1:nrow(lbh_ref2)  merge_overlaps(lbh_ref2) }"},{"path":"https://marce10.github.io/ohun/reference/ohun.html","id":null,"dir":"Reference","previous_headings":"","what":"ohun: Optimizing acoustic signal detection — ohun","title":"ohun: Optimizing acoustic signal detection — ohun","text":"ohun intended facilitate automatic detection acoustic signals, providing functions diagnose optimize detection routines. Detections software can also explored optimized.","code":""},{"path":"https://marce10.github.io/ohun/reference/ohun.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"ohun: Optimizing acoustic signal detection — ohun","text":"main features package : use reference annotations detection optimization diagnostic use signal detection theory diagnostic parameters evaluate detection performance batch processing sound files improve computational performance package offers functions : Energy-based detection Template-based detection Diagnose detection precision Optimize detection routines based reference annotations functions allow parallelization tasks, distributes tasks among several processors improve computational efficiency. package works sound files '.wav', '.mp3', '.flac' '.wac' format. License: GPL (>= 2)","code":""},{"path":"https://marce10.github.io/ohun/reference/ohun.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"ohun: Optimizing acoustic signal detection — ohun","text":"Marcelo Araya-Salas Maintainer: Marcelo Araya-Salas (marcelo.araya@ucr.ac.cr)","code":""},{"path":"https://marce10.github.io/ohun/reference/optimize_energy_detector.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimize energy-based signal detection — optimize_energy_detector","title":"Optimize energy-based signal detection — optimize_energy_detector","text":"Optimize energy-based signal detection different correlation treshold values","code":""},{"path":"https://marce10.github.io/ohun/reference/optimize_energy_detector.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimize energy-based signal detection — optimize_energy_detector","text":"","code":"optimize_energy_detector(reference, files = NULL, threshold = 5, peak.amplitude = 0, hop.size = 11.6, wl = NULL, smooth = 5, hold.time = 0, min.duration = NULL, max.duration = NULL, thinning = 1, parallel = 1, pb = TRUE,  by.sound.file = FALSE, bp = NULL, path = \".\", previous.output = NULL)"},{"path":"https://marce10.github.io/ohun/reference/optimize_energy_detector.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimize energy-based signal detection — optimize_energy_detector","text":"reference Selection table (using warbleR package's format, see selection_table) data frame columns sound file name (sound.files), selection number (selec), start end time signal (start end). must contain reference selections used detection optimization. files Character vector indicating sound files analyzed. Optional.  supplied function work sound files 'reference'. can used include signals signals. threshold numeric vector specifying amplitude threshold detecting signals (%). Default 5. Several values can supplied optimization. peak.amplitude Numeric vector length 1 minimum peak amplitude value. detection value excluded. Peak amplitude maximum sound pressure level (decibels) across signal (see sound_pressure_level). can useful expecting higher peak amplitude target signals compared non-target signals keeping best examples target signals(.e. high precision low recall). Default 0. Several values can supplied optimization. hop.size numeric vector length 1 specifying time window duration (ms). Default 11.6 ms, equivalent 512 wl 44.1 kHz sampling rate. Ignored 'wl' supplied. wl numeric vector length 1 specifying window length spectrogram. Default NULL. supplied, 'hop.size' ignored. Used internally bandpass filtering (applied 'bp' supplied). smooth numeric vector smooth amplitude envelope sum smooth function. controls time range (ms) amplitude samples smoothed (.e. averaged neighboring samples). Default 5. 0 means smoothing applied. Note smoothing applied thinning (see 'thinning' argument). Several values can supplied optimization. hold.time Numeric vector length 1. Specifies time range (ms) selections merged (.e. 2 selections separated less specified 'hold.time' merged single selection). Default 0 (hold time applied). Several values can supplied optimization. min.duration Numeric vector giving shortest duration (ms) signals detected. removes signals threshold. Several values can supplied optimization. max.duration Numeric vector giving longest duration (ms) signals detected. removes signals threshold. Several values can supplied optimization. thinning Numeric vector range 0~1 indicating proportional reduction number samples used represent amplitude envelopes (.e. thinning envelopes). Usually amplitude envelopes many samples needed accurately represent amplitude variation time, affects size output (usually large R objects / files). Default  1 (thinning). Higher sampling rates may afford higher size reduction (e.g. lower thinning values). Reduction conducted interpolation using approx. Note thinning may decrease time precision, higher thinning less precise time detection. Several values can supplied optimization. parallel Numeric. Controls whether parallel computing applied. specifies number cores used. Default 1 (.e. parallel computing). pb Logical argument control progress bar messages. Default TRUE. .sound.file Logical argument control whether performance diagnostics summarized across sound files (.sound.file = FALSE 1 sound file included 'reference') shown separated sound file. Default FALSE. bp Numeric vector length 2 giving lower upper limits frequency bandpass filter (kHz). Default NULL.  argument used internally get_envelopes. used 'envelopes' supplied. path Character string containing directory path sound files located. current working directory used default. previous.output Data frame output previous run function. used include previous results new output avoid recalculating detection performance parameter combinations previously evaluated.","code":""},{"path":"https://marce10.github.io/ohun/reference/optimize_energy_detector.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimize energy-based signal detection — optimize_energy_detector","text":"data frame row shows result detection job particular combination tuning parameters (including data frame). also includes following diagnostic metrics: true.positives: number signals 'reference' correspond detection. Matching defined degree overlap time. perfect detection routine equal number rows 'reference'. false.positives: number detections match signals 'reference'. perfect detection routine 0. false.negatives: number signals 'reference' detected (found 'detection'. perfect detection routine 0. split.positives: number signals 'reference' overlapped 1 detection (.e. detections split). perfect detection routine 0. merged.positives: number signals 'detection' overlapped 1 detection (.e. signals merged). perfect detection routine 0. mean.duration.true.positives: mean duration true positives (s). included time.diagnostics = TRUE. mean.duration.false.positives: mean duration false positives (s). included time.diagnostics = TRUE. mean.duration.false.negatives: mean duration false negatives (s). included time.diagnostics = TRUE. overlap..true.positives: ratio time overlap true positives 'detection' corresponding reference signal duration reference signal. proportional.duration.true.positives: ratio duration true positives th duration signals 'reference'. perfect detection routine 1. Based true positives split merged. included time.diagnostics = TRUE. duty.cycle: proportion sound file sounds detected. included time.diagnostics = TRUE path supplied. recall: Proportion signals 'reference' detected. perfect detection routine 1. precision: Proportion detections correspond signals 'reference'. perfect detection routine 1.","code":""},{"path":"https://marce10.github.io/ohun/reference/optimize_energy_detector.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Optimize energy-based signal detection — optimize_energy_detector","text":"function takes selections data frame 'selection_table' ('reference') estimates detection performance energy detector different detection parameter combinations. done comparing position time detection reference selections 'reference'. function returns several diagnostic metrics allow user determine parameter values provide detection closely matches selections 'reference'. parameters can later used performing efficient detection using energy_detector.","code":""},{"path":"https://marce10.github.io/ohun/reference/optimize_energy_detector.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Optimize energy-based signal detection — optimize_energy_detector","text":"Araya-Salas, M. (2021), ohun: automatic detection acoustic signals. R package version 0.1.0.","code":""},{"path":"https://marce10.github.io/ohun/reference/optimize_energy_detector.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Optimize energy-based signal detection — optimize_energy_detector","text":"Marcelo Araya-Salas (marcelo.araya@ucr.ac.cr).","code":""},{"path":"https://marce10.github.io/ohun/reference/optimize_energy_detector.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimize energy-based signal detection — optimize_energy_detector","text":"","code":"{ # Save example files into temporary working directory data(\"lbh1\", \"lbh2\", \"lbh_reference\") writeWave(lbh1, file.path(tempdir(), \"lbh1.wav\")) writeWave(lbh2, file.path(tempdir(), \"lbh2.wav\"))  # using smoothing and minimum duration optimize_energy_detector(reference = lbh_reference, path = tempdir(), threshold = c(6, 10), smooth = 6.8, bp = c(2, 9), hop.size = 6.8, min.duration = 90)  # with thinning and smoothing optimize_energy_detector(reference = lbh_reference, path = tempdir(),  threshold = c(6, 10, 15), smooth = c(7, 10), thinning = c(0.1, 0.01),  bp = c(2, 9), hop.size = 6.8, min.duration = 90)  # by sound file (opt_ed <- optimize_energy_detector(reference = lbh_reference, path = tempdir(), threshold = c(6, 10, 15), smooth = 6.8, bp = c(2, 9), hop.size = 6.8, min.duration = 90, by.sound.file = TRUE))  # summarize summarize_diagnostic(opt_ed)  # using hold time (op_ed <- optimize_energy_detector(reference = lbh_reference, threshold = 10, hold.time = c(100, 150), bp = c(2, 9), hop.size = 6.8, path = tempdir()))  # including previous output in new call optimize_energy_detector(reference = lbh_reference, threshold = 10, hold.time = c(50, 200), previous.output = op_ed, smooth = 6.8, bp = c(2, 9), hop.size = 7, path = tempdir())  # having and extra file in files (simulating a file that should have no detetions) sub_reference <- lbh_reference[lbh_reference$sound.files != \"lbh1.wav\", ]  optimize_energy_detector(reference = sub_reference, files = unique(lbh_reference$sound.files), threshold = 10, hold.time = c(1, 150), bp = c(2, 9), smooth = 6.8, hop.size = 7, path = tempdir()) }"},{"path":"https://marce10.github.io/ohun/reference/optimize_template_detector.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimize acoustic template detection — optimize_template_detector","title":"Optimize acoustic template detection — optimize_template_detector","text":"optimize_template_detector optimizes acoustic template detection","code":""},{"path":"https://marce10.github.io/ohun/reference/optimize_template_detector.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimize acoustic template detection — optimize_template_detector","text":"","code":"optimize_template_detector(template.correlations, reference, threshold, parallel = 1, pb = TRUE, by.sound.file = FALSE, previous.output = NULL)"},{"path":"https://marce10.github.io/ohun/reference/optimize_template_detector.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimize acoustic template detection — optimize_template_detector","text":"template.correlations object class 'template_correlations' (generated template_correlator) optimize detections. Must contain data sound files 'reference'. can also contain data additional sound files. case routine assumes signals found files, detection files false positives. reference Data frame 'selection.table' (following warbleR package format) reference selections (start end signals) used evaluate performance detection, represented selections 'detection'. Must contained least following columns: \"sound.files\", \"selec\", \"start\" \"end\". must contain reference selections used detection optimization. threshold Numeric vector length > 1 values 0 1 specifying correlation threshold detecting signal occurrences (.e. correlation peaks). Must supplied. Several values supplied optimization. parallel Numeric. Controls whether parallel computing applied. specifies number cores used. Default 1 (.e. parallel computing). pb Logical argument control progress bar messages. Default TRUE. .sound.file Logical control diagnostics calculated sound file independently (TRUE) sound files combined (FALSE, default). previous.output Data frame output previous run function. used include previous results new output avoid recalculating detection performance parameter combinations previously evaluated.","code":""},{"path":"https://marce10.github.io/ohun/reference/optimize_template_detector.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimize acoustic template detection — optimize_template_detector","text":"data frame row shows result detection job cutoff value, including following diagnostic metrics: true.positives: number signals 'reference' correspond detection. Matching defined degree overlap time. perfect detection routine equal number rows 'reference'. false.positives: number detections match signals 'reference'. perfect detection routine 0. false.negatives: number signals 'reference' detected (found 'detection'. perfect detection routine 0. split.positives: number signals 'reference' overlapped 1 detection (.e. detections split). perfect detection routine 0. merged.positives: number signals 'detection' overlapped 1 detection (.e. signals merged). perfect detection routine 0. recall: Proportion signals 'reference' detected. perfect detection routine 1. precision: Proportion detections correspond signals 'reference' detected. perfect detection routine 1.","code":""},{"path":"https://marce10.github.io/ohun/reference/optimize_template_detector.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Optimize acoustic template detection — optimize_template_detector","text":"function takes reference data frame 'selection_table' ('X') output template_correlator estimates detection performance different detection parameter combinations. done comparing position time detection reference selections. function returns several diagnostic metrics allow user determine parameter values provide detection closely matches selections 'reference'. parameters can later used performing efficient detection using optimize_template_detector.","code":""},{"path":"https://marce10.github.io/ohun/reference/optimize_template_detector.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Optimize acoustic template detection — optimize_template_detector","text":"Araya-Salas, M. (2021), ohun: automatic detection acoustic signals. R package version 0.1.0.","code":""},{"path":[]},{"path":"https://marce10.github.io/ohun/reference/optimize_template_detector.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Optimize acoustic template detection — optimize_template_detector","text":"Marcelo Araya-Salas (marcelo.araya@ucr.ac.cr).","code":""},{"path":"https://marce10.github.io/ohun/reference/optimize_template_detector.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimize acoustic template detection — optimize_template_detector","text":"","code":"{ # Save sound files to temporary working directory data(\"lbh1\", \"lbh2\", \"lbh_reference\") writeWave(lbh1, file.path(tempdir(), \"lbh1.wav\")) writeWave(lbh2, file.path(tempdir(), \"lbh2.wav\"))  # template for the second sound file in 'lbh_reference' templ <- lbh_reference[11, ]  # generate template correlations tc <- template_correlator(templates = templ, path = tempdir(), files = \"lbh2.wav\")  # using 2 threshold optimize_template_detector(template.correlations = tc, reference = lbh_reference[lbh_reference$sound.files == \"lbh2.wav\", ], threshold = c(0.2, 0.5))  # using several thresholds optimize_template_detector(template.correlations = tc, reference = lbh_reference[lbh_reference$sound.files == \"lbh2.wav\", ],  threshold = seq(0.5, 0.9, by = 0.05))   # template for the first and second sound file in 'lbh_reference'  templ <- lbh_reference[c(1, 11), ]   # generate template correlations  tc <- template_correlator(templates = templ, path = tempdir(),  files = c(\"lbh1.wav\", \"lbh2.wav\"))  optimize_template_detector(template.correlations = tc, reference =   lbh_reference, threshold = seq(0.5, 0.7, by = 0.1))   # showing diagnostics by sound file  optimize_template_detector(template.correlations = tc, reference =  lbh_reference,  threshold = seq(0.5, 0.7, by = 0.1), by.sound.file = TRUE) }"},{"path":"https://marce10.github.io/ohun/reference/print.envelopes.html","id":null,"dir":"Reference","previous_headings":"","what":"Class 'envelopes': list of absolute amplitude envelopes — print.envelopes","title":"Class 'envelopes': list of absolute amplitude envelopes — print.envelopes","text":"Class absolute amplitude envelopes","code":""},{"path":"https://marce10.github.io/ohun/reference/print.envelopes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Class 'envelopes': list of absolute amplitude envelopes — print.envelopes","text":"","code":"# S3 method for envelopes print(x, ...)"},{"path":"https://marce10.github.io/ohun/reference/print.envelopes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Class 'envelopes': list of absolute amplitude envelopes — print.envelopes","text":"x Object class envelopes, generated get_envelopes. ... arguments passed methods. Ignored printing envelopes.","code":""},{"path":"https://marce10.github.io/ohun/reference/print.envelopes.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Class 'envelopes': list of absolute amplitude envelopes — print.envelopes","text":"object class envelopes created get_envelopes list sound files absolute amplitude envelopes metadata","code":""},{"path":[]},{"path":"https://marce10.github.io/ohun/reference/print.template_correlations.html","id":null,"dir":"Reference","previous_headings":"","what":"print method for class template_correlations — print.template_correlations","title":"print method for class template_correlations — print.template_correlations","text":"print method class template_correlations","code":""},{"path":"https://marce10.github.io/ohun/reference/print.template_correlations.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"print method for class template_correlations — print.template_correlations","text":"","code":"# S3 method for template_correlations print(x, ...)"},{"path":"https://marce10.github.io/ohun/reference/print.template_correlations.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"print method for class template_correlations — print.template_correlations","text":"x Object class template_correlations, generated template_correlator. ... arguments passed methods. Ignored printing 'template_correlations' class objects.","code":""},{"path":"https://marce10.github.io/ohun/reference/split_acoustic_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Splits sound files — split_acoustic_data","title":"Splits sound files — split_acoustic_data","text":"split_acoustic_data splits sound files (corresponding selection tables) shorter segments","code":""},{"path":"https://marce10.github.io/ohun/reference/split_acoustic_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Splits sound files — split_acoustic_data","text":"","code":"split_acoustic_data(path = \".\", sgmt.dur = 10, sgmts = NULL, files = NULL,  parallel = 1, pb = TRUE, only.sels = FALSE, X = NULL)"},{"path":"https://marce10.github.io/ohun/reference/split_acoustic_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Splits sound files — split_acoustic_data","text":"path Directory path sound files found. current working directory used default. sgmt.dur Numeric. Duration (s) segments sound files split. Sound files shorter 'sgmt.dur' split. Ignored 'sgmts' supplied. sgmts Numeric. Number segments split sound file. supplied 'sgmt.dur' ignored. files Character vector indicating subset files split. parallel Numeric. Controls whether parallel computing applied. specifies number cores used. Default 1 (.e. parallel computing). pb Logical argument control progress bar. Default TRUE. used .sels Logical argument control data frame returned (wave files saved). Default FALSE. X 'selection_table' object data frame columns sound file name (sound.files), selection number (selec), start end time signal (start end). supplied data frame/selection table modified reflect position selections new sound files. Note selections split 2 segments. deal , 'split.sels' column added data frame selection labeled 'split'. Default NULL.","code":""},{"path":"https://marce10.github.io/ohun/reference/split_acoustic_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Splits sound files — split_acoustic_data","text":"Wave files segment working directory (.sels = FALSE, named 'sound.file.name-#.wav') data frame R environment containing name original sound files (org.sound.files), name clips (sound.files) start end clips original files. Clips saved .wav format. 'X' supplied data frame position selections newly created clips returned instead.","code":""},{"path":"https://marce10.github.io/ohun/reference/split_acoustic_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Splits sound files — split_acoustic_data","text":"function aims reduce size sound files order simplify processes limited sound file size (big files can manipulated, e.g. energy_detector).","code":""},{"path":"https://marce10.github.io/ohun/reference/split_acoustic_data.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Splits sound files — split_acoustic_data","text":"Araya-Salas, M. (2021), ohun: automatic detection acoustic signals. R package version 0.1.0.","code":""},{"path":[]},{"path":"https://marce10.github.io/ohun/reference/split_acoustic_data.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Splits sound files — split_acoustic_data","text":"Marcelo Araya-Salas (marcelo.araya@ucr.ac.cr)","code":""},{"path":"https://marce10.github.io/ohun/reference/split_acoustic_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Splits sound files — split_acoustic_data","text":"","code":"{ #load data and save to temporary working directory data(\"lbh1\", \"lbh2\") writeWave(lbh1, file.path(tempdir(), \"lbh1.wav\")) writeWave(lbh2, file.path(tempdir(), \"lbh2.wav\"))  #split files in 1 s files split_acoustic_data(sgmt.dur = 1, path = tempdir())  # Check this folder tempdir() }"},{"path":"https://marce10.github.io/ohun/reference/summarize_diagnostic.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarize detection diagnostics — summarize_diagnostic","title":"Summarize detection diagnostics — summarize_diagnostic","text":"summarize_diagnostic summarizes detection diagnostics","code":""},{"path":"https://marce10.github.io/ohun/reference/summarize_diagnostic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarize detection diagnostics — summarize_diagnostic","text":"","code":"summarize_diagnostic(diagnostic, time.diagnostics = FALSE)"},{"path":"https://marce10.github.io/ohun/reference/summarize_diagnostic.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarize detection diagnostics — summarize_diagnostic","text":"diagnostic data frame reference selections (start end signals) used evaluate performance detection, represented selections 'detection'. Must contained least following columns: \"sound.files\", \"selec\", \"start\" \"end\". time.diagnostics Logical argument control diagnostics related duration signals (\"mean.duration.true.positives\", \"mean.duration.false.positives\", \"mean.duration.false.negatives\" \"proportional.duration.true.positives\") returned (TRUE). Default FALSE.","code":""},{"path":"https://marce10.github.io/ohun/reference/summarize_diagnostic.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarize detection diagnostics — summarize_diagnostic","text":"data frame, typically output detection optimization function (diagnose_detection, optimize_energy_detector, optimize_template_detector) including following detection performance diagnostics: true.positives: number signals 'reference' correspond detection. Matching defined degree overlap time. perfect detection routine equal number rows 'reference'. false.positives: number detections match signals 'reference'. perfect detection routine 0. false.negatives: number signals 'reference' detected (found 'detection'. perfect detection routine 0. split.positives: number signals 'reference' overlapped 1 detection (.e. detections split). perfect detection routine 0. merged.positives: number signals 'detection' overlapped 1 detection (.e. signals merged). perfect detection routine 0. mean.duration.true.positives: mean duration true positives (s). included time.diagnostics = TRUE. mean.duration.false.positives: mean duration false positives (s). included time.diagnostics = TRUE. mean.duration.false.negatives: mean duration false negatives (s). included time.diagnostics = TRUE. overlap..true.positives: ratio time overlap true positives 'detection' corresponding reference signal duration reference signal. proportional.duration.true.positives: ratio duration true positives th duration signals 'reference'. perfect detection routine 1. Based true positives split merged. included time.diagnostics = TRUE. recall: Proportion signals 'reference' detected. perfect detection routine 1. precision: Proportion detections correspond signals 'reference' detected. perfect detection routine 1. f1.score: Combines recall precision harmonic mean two. Provides single value evaluating performance. perfect detection routine 1.","code":""},{"path":"https://marce10.github.io/ohun/reference/summarize_diagnostic.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Summarize detection diagnostics — summarize_diagnostic","text":"function summarizes detection diagnostic data frame diagnostic parameters shown split (typically) categorical column, usually sound files. function used internally diagnose_detection.","code":""},{"path":"https://marce10.github.io/ohun/reference/summarize_diagnostic.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Summarize detection diagnostics — summarize_diagnostic","text":"Araya-Salas, M. (2021), ohun: automatic detection acoustic signals. R package version 0.1.0.","code":""},{"path":[]},{"path":"https://marce10.github.io/ohun/reference/summarize_diagnostic.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Summarize detection diagnostics — summarize_diagnostic","text":"Marcelo Araya-Salas marcelo.araya@ucr.ac.cr)","code":""},{"path":"https://marce10.github.io/ohun/reference/summarize_diagnostic.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarize detection diagnostics — summarize_diagnostic","text":"","code":"{ # load example selection tables  data(\"lbh_reference\")  # run diagnose_detection() by sound file diag <- diagnose_detection(reference = lbh_reference, detection = lbh_reference[-1, ], by.sound.file = TRUE)  # summarize summarize_diagnostic(diagnostic = diag)  # should be the same as this: diagnose_detection(reference = lbh_reference, detection = lbh_reference[-1, ], by.sound.file = FALSE) }"},{"path":"https://marce10.github.io/ohun/reference/template_correlator.html","id":null,"dir":"Reference","previous_headings":"","what":"Acoustic templates correlator using time-frequency cross-correlation — template_correlator","title":"Acoustic templates correlator using time-frequency cross-correlation — template_correlator","text":"template_correlator estimates templates cross-correlation across multiple sound files.","code":""},{"path":"https://marce10.github.io/ohun/reference/template_correlator.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Acoustic templates correlator using time-frequency cross-correlation — template_correlator","text":"","code":"template_correlator(templates, files = NULL, hop.size = 11.6, wl = NULL, ovlp = 0, wn ='hanning', cor.method = \"pearson\", parallel = 1, path = \".\", pb = TRUE, type = \"fourier\", fbtype = \"mel\", ...)"},{"path":"https://marce10.github.io/ohun/reference/template_correlator.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Acoustic templates correlator using time-frequency cross-correlation — template_correlator","text":"templates 'selection_table', 'extended_selection_table' (warbleR package's formats, see selection_table) data frame time frequency information signal(s) used templates (1 template per row). object must containing columns sound files (sound.files), selection number (selec), start end time signal (start end). frequency range columns included ('bottom.freq' 'top.freq', kHz) correlation run frequency ranges. templates must sampling rate templates 'files' (find templates) must also sampling rate. files Character vector selections 'X' used surveys cross-correlation detection. refer specific selections 'X' user must use format \"sound.file-selec\" (e.g. \"file1.wav-1\"). sound file name included entire sound file used survey. hop.size numeric vector length 1 specifying time window duration (ms). Default 11.6 ms, equivalent 512 wl 44.1 kHz sampling rate. Ignored 'wl' supplied. wl numeric vector length 1 specifying window length spectrogram. Default NULL. supplied, 'hop.size' ignored. ovlp Numeric vector length 1 specifying % overlap two consecutive windows, spectro. Default 0. High values ovlp slow function may produce accurate results. wn character vector length 1 specifying window name ftwindow. cor.method character vector length 1 specifying correlation method cor. parallel Numeric. Controls whether parallel computing applied. specifies number cores used. Default 1 (.e. parallel computing). path Character string containing directory path sound files located. current working directory used default. pb Logical argument control progress bar. Default TRUE. type character vector length 1 specifying type cross-correlation: \"fourier\" (.e. spectrographic cross-correlation using Fourier transform; internally using spectro; default), \"mfcc\" (auditory scale coefficient matrix cross-correlation; internally using melfcc) \"auditory-spectrum\" (cross-correlation auditory spectrum, .e. spectrum transformation auditory scale; internally using melfcc). argument 'fbtype' controls auditory scale used. Note last 2 methods widely used context can regarded experimental. fbtype Character vector indicating auditory frequency scale use: \"mel\", \"bark\", \"htkmel\", \"fcmel\". ... Additional arguments passed melfcc customization using auditory scales.","code":""},{"path":"https://marce10.github.io/ohun/reference/template_correlator.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Acoustic templates correlator using time-frequency cross-correlation — template_correlator","text":"function returns object class 'template_correlations' list correlation scores combination templates files. 'template_correlations' objects must used infer signal ocurrences using template_detector graphically explore template correlations across sound files using full_spectrograms.","code":""},{"path":"https://marce10.github.io/ohun/reference/template_correlator.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Acoustic templates correlator using time-frequency cross-correlation — template_correlator","text":"function calculates similarity acoustic templates across sound files means time-frequency cross-correlation. Fourier tranformation, time-frequency representations auditory scales (including ceptral coefficients) can used. Several templates can run several sound files. Note template-based detection divided two steps: template correlation (using function) template detection (peak detection infers detection based peak correlation scores, using function template_detector). output function (object 'template_correlations') must input template_detector infering signal ocurrences. optimize_template_detector can used optimize template detection.","code":""},{"path":"https://marce10.github.io/ohun/reference/template_correlator.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Acoustic templates correlator using time-frequency cross-correlation — template_correlator","text":"Araya-Salas, M. (2021), ohun: automatic detection acoustic signals. R package version 0.1.0.Khanna H., Gaunt S.L.L.  & McCallum D.. (1997). Digital spectrographic cross-correlation: tests recall. Bioacoustics 7(3): 209-234.Lyon, R. H., & Ordubadi, . (1982). Use cepstra acoustical signal analysis. Journal Mechanical Design, 104(2), 303-306.","code":""},{"path":[]},{"path":"https://marce10.github.io/ohun/reference/template_correlator.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Acoustic templates correlator using time-frequency cross-correlation — template_correlator","text":"Marcelo Araya-Salas marcelo.araya@ucr.ac.cr)","code":""},{"path":"https://marce10.github.io/ohun/reference/template_correlator.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Acoustic templates correlator using time-frequency cross-correlation — template_correlator","text":"","code":"{ #load example data data(\"lbh1\", \"lbh2\", \"lbh_reference\")  #save sound files writeWave(lbh1, file.path(tempdir(), \"lbh1.wav\")) writeWave(lbh2, file.path(tempdir(), \"lbh2.wav\"))  # create template templ <- lbh_reference[4,] templ2 <- selection_table(templ, extended = TRUE, confirm.extended = FALSE, path = tempdir())  # fourier spectrogram (tc_fr <- template_correlator(templates = templ, path = tempdir(), type = \"fourier\"))  # mel auditory spectrograms (tc_ma <- template_correlator(templates = templ, path = tempdir(), type = \"mel-auditory\"))  # mfcc spectrograms (tc_mfcc <- template_correlator(templates = templ, path = tempdir(), type = \"mfcc\"))  # similar results (but no exactly the same) are found with the 3 methods # these are the correlation of the correlation vectors # fourier vs mel-auditory cor(tc_fr$`lbh2.wav-4/lbh2.wav`$correlation.scores, tc_ma$`lbh2.wav-4/lbh2.wav`$correlation.scores)  # fourier vs mfcc cor(tc_fr$`lbh2.wav-4/lbh2.wav`$correlation.scores, tc_mfcc$`lbh2.wav-4/lbh2.wav`$correlation.scores)  # mel-auditory vs mfcc cor(tc_ma$`lbh2.wav-4/lbh2.wav`$correlation.scores, tc_mfcc$`lbh2.wav-4/lbh2.wav`$correlation.scores)  # using an extended selection table templ_est <- selection_table(templ, extended = TRUE, confirm.extended = FALSE, path = tempdir())  tc_fr_est <- template_correlator(templates = templ_est, path = tempdir(), type = \"fourier\")  # produces the same result as templates in a regular data frame cor(tc_fr$`lbh2.wav-4/lbh2.wav`$correlation.scores, tc_fr_est$`lbh2.wav_4-1/lbh2.wav`$correlation.scores) }"},{"path":"https://marce10.github.io/ohun/reference/template_detector.html","id":null,"dir":"Reference","previous_headings":"","what":"Acoustic template detection from time-frequency cross-correlations — template_detector","title":"Acoustic template detection from time-frequency cross-correlations — template_detector","text":"template_detector find signal occurrences cross-correlation vectors template_correlator","code":""},{"path":"https://marce10.github.io/ohun/reference/template_detector.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Acoustic template detection from time-frequency cross-correlations — template_detector","text":"","code":"template_detector(template.correlations, parallel = 1, threshold, pb = TRUE,  verbose = TRUE)"},{"path":"https://marce10.github.io/ohun/reference/template_detector.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Acoustic template detection from time-frequency cross-correlations — template_detector","text":"template.correlations object class 'template_correlations' generated template_correlator containing correlation score vectors. parallel Numeric. Controls whether parallel computing applied. specifies number cores used. Default 1 (.e. parallel computing). threshold Numeric vector length 1 value 0 1 specifying correlation threshold detecting signal occurrences (.e. correlation peaks). Must supplied. Correlation scores forced 0 1 (converting negative scores 0). 0 1 represent lowest highest similarity template respectively. pb Logical argument control progress bar. Default TRUE. verbose Logical argument control summary messages printed console.","code":""},{"path":"https://marce10.github.io/ohun/reference/template_detector.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Acoustic template detection from time-frequency cross-correlations — template_detector","text":"function returns 'selection_table' (warbleR package's formats, see selection_table) data frame (sound files found) start end correlation score detected signals.","code":""},{"path":"https://marce10.github.io/ohun/reference/template_detector.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Acoustic template detection from time-frequency cross-correlations — template_detector","text":"function infers signals occurrences cross-correlation scores along sound files. Correlation scores must generated first using template_correlator. output data frame (selection table sound files still found original path supplied template_correlator, using warbleR package's format, see selection_table) containing start end detected signals well cross-correlation score ('scores' column) detection.","code":""},{"path":"https://marce10.github.io/ohun/reference/template_detector.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Acoustic template detection from time-frequency cross-correlations — template_detector","text":"Araya-Salas, M. (2021), ohun: automatic detection acoustic signals. R package version 0.1.0.","code":""},{"path":[]},{"path":"https://marce10.github.io/ohun/reference/template_detector.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Acoustic template detection from time-frequency cross-correlations — template_detector","text":"Marcelo Araya-Salas marcelo.araya@ucr.ac.cr)","code":""},{"path":"https://marce10.github.io/ohun/reference/template_detector.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Acoustic template detection from time-frequency cross-correlations — template_detector","text":"","code":"{ # load example data data(\"lbh1\", \"lbh2\", \"lbh_reference\")  # save sound files writeWave(lbh1, file.path(tempdir(), \"lbh1.wav\")) writeWave(lbh2, file.path(tempdir(), \"lbh2.wav\"))  # template for the first sound file in 'lbh_reference' templ1 <- lbh_reference[1, ]  # generate template correlations tc <- template_correlator(templates = templ1, path = tempdir(), files = \"lbh1.wav\")  # template detection td <- template_detector(template.correlations = tc, threshold = 0.4)  # diagnose detection diagnose_detection(reference = lbh_reference[lbh_reference$sound.files == \"lbh1.wav\", ], detection = td)  # template for the second and third sound file in 'lbh_reference' # which have similar song types templ2 <- lbh_reference[4, ]  # generate template correlations tc <- template_correlator(templates = templ2, path = tempdir(), files = c(\"lbh1.wav\", \"lbh2.wav\"))  # template detection td <- template_detector(template.correlations = tc, threshold = 0.3)  # diagnose detection diagnose_detection(reference = lbh_reference, detection = td) }"}]
