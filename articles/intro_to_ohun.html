<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Optimizing sound event detection • ohun</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><link href="../extra.css" rel="stylesheet">
<meta property="og:title" content="Optimizing sound event detection">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">ohun</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">1.0.3</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><a class="dropdown-item" href="../articles/energy_based_detection.html">Energy-based detection</a></li>
    <li><a class="dropdown-item" href="../articles/intro_to_ohun.html">Optimizing sound event detection</a></li>
    <li><a class="dropdown-item" href="../articles/template_based_detection.html">Template-based detection</a></li>
  </ul>
</li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/ropensci/ohun/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Optimizing sound event detection</h1>
                        <h4 data-toc-skip class="author"><a href="https://marce10.github.io/" class="external-link">Marcelo
Araya-Salas, PhD</a></h4>
            
            <h4 data-toc-skip class="date">2025-07-26</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/ropensci/ohun/blob/master/vignettes/intro_to_ohun.Rmd" class="external-link"><code>vignettes/intro_to_ohun.Rmd</code></a></small>
      <div class="d-none name"><code>intro_to_ohun.Rmd</code></div>
    </div>

    
    
<p><img src="ohun_sticker.png" alt="ohun sticker" align="right" width="25%" height="25%"><br></p>
<p><a href="https://github.com/ropensci/ohun" class="external-link">ohun</a> is intended to
facilitate the automated detection of sound events, providing functions
to diagnose and optimize detection routines. Detections from other
software can also be explored and optimized. This vignette provides a
general overview of sound event optimization in <a href="https://github.com/ropensci/ohun" class="external-link">ohun</a> as well as basic
concepts from signal detection theory.</p>
<div class="alert alert-info">
<p><font size="4">The main features of the package are: </font></p>
<ul>
<li>The use of reference annotations for detection optimization and
diagnostic</li>
<li>The use of signal detection theory indices to evaluate detection
performance</li>
</ul>
<p><font size="4">The package offers functions for: </font></p>
<ul>
<li>Curate references and acoustic data sets</li>
<li>Diagnose detection performance</li>
<li>Optimize detection routines based on reference annotations</li>
<li>Energy-based detection</li>
<li>Template-based detection</li>
</ul>
</div>
<p>All functions allow the parallelization of tasks, which distributes
the tasks among several processors to improve computational efficiency.
The package works on sound files in ‘.wav’, ‘.mp3’, ‘.flac’ and ‘.wac’
format.</p>
<hr>
<p>The package can be installed from CRAN as follows:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># From CRAN would be</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/install.packages.html" class="external-link">install.packages</a></span><span class="op">(</span><span class="st">"ohun"</span><span class="op">)</span></span>
<span></span>
<span><span class="co">#load package</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://docs.ropensci.org/ohun/">ohun</a></span><span class="op">)</span></span></code></pre></div>
<p>To install the latest developmental version from <a href="https://github.com/" class="external-link">github</a> you will need the R package <a href="https://cran.r-project.org/package=devtools" class="external-link">remotes</a>:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># install package</span></span>
<span><span class="fu">remotes</span><span class="fu">::</span><span class="fu"><a href="https://remotes.r-lib.org/reference/install_github.html" class="external-link">install_github</a></span><span class="op">(</span><span class="st">"maRce10/ohun"</span><span class="op">)</span></span>
<span></span>
<span><span class="co">#load packages</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://docs.ropensci.org/ohun/">ohun</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://tuner.R-forge.R-project.org" class="external-link">tuneR</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://marce10.github.io/warbleR/" class="external-link">warbleR</a></span><span class="op">)</span></span></code></pre></div>
<hr>
<div class="section level2">
<h2 id="automatic-sound-event-detection">Automatic sound event detection<a class="anchor" aria-label="anchor" href="#automatic-sound-event-detection"></a>
</h2>
<p>Finding the position of sound events in a sound file is a challenging
task. <a href="https://github.com/ropensci/ohun" class="external-link">ohun</a> offers two
methods for automated sound event detection: template-based and
energy-based detection. These methods are better suited for highly
stereotyped or good signal-to-noise ratio (SNR) sounds, respectively. If
the target sound events don’t fit these requirements, more elaborated
methods (i.e. machine learning approaches) are warranted:</p>
<figure><center>
<img src="analysis_workflow.png" alt="automated signal detection diagram" width="500" height="450">
</center>
<figcaption><i>Diagram depicting how target sound event features can be used to tell
the most adequate sound event detection approach. Steps in which ‘ohun’
can be helpful are shown in color. (SNR = signal-to-noise ratio) </i>
</figcaption></figure><p>Also note that the presence of other sounds overlapping the target
sound events in time and frequency can strongly affect detection
performance for the two methods in <a href="https://github.com/ropensci/ohun" class="external-link">ohun</a>.</p>
<p>Still, a detection run using other software can be optimized with the
tools provided in <a href="https://github.com/ropensci/ohun" class="external-link">ohun</a>.</p>
</div>
<div class="section level2">
<h2 id="signal-detection-theory-applied-to-bioacoustics">Signal detection theory applied to bioacoustics<a class="anchor" aria-label="anchor" href="#signal-detection-theory-applied-to-bioacoustics"></a>
</h2>
<p>Broadly speaking, signal detection theory deals with the process of
recovering signals (i.e. target signals) from background noise (not
necessarily acoustic noise) and it’s widely used for optimizing this
decision making process in the presence of uncertainty. During a
detection routine, the detected ‘items’ can be classified into 4
classes:</p>
<ul>
<li>
<strong>True positives (TPs)</strong>: signals correctly identified
as ‘signal’</li>
<li>
<strong>False positives (FPs)</strong>: background noise incorrectly
identified as ‘signal’</li>
<li>
<strong>False negatives (FNs)</strong>: signals incorrectly
identified as ‘background noise’</li>
<li>
<strong>True negatives (TNs)</strong>: background noise correctly
identified as ‘background noise’</li>
</ul>
<p>Several additional indices derived from these indices are used to
evaluate the performance of a detection routine. These are three useful
indices in the context of sound event detection included in <a href="https://github.com/ropensci/ohun" class="external-link">ohun</a>:</p>
<ul>
<li>
<strong>Recall</strong>: correct detections relative to total
references (a.k.a. true positive rate or sensitivity; <em>TPs / (TPs +
FNs)</em>)</li>
<li>
<strong>Precision</strong>: correct detections relative to total
detections (<em>TPs / (TPs + FPs)</em>).</li>
<li>
<strong>F score</strong>: combines recall and precision as the
harmonic mean of these two, so it provides a single value for evaluating
performance (a.k.a. F-measure or Dice similarity coefficient).</li>
</ul>
<p><font size="2"><em>(Metrics that make use of ‘true negatives’
cannot be easily applied in the context of sound event detection as
noise cannot always be partitioned in discrete units)</em></font></p>
<p>A perfect detection will have no false positives or false negatives,
which will result in both recall and precision equal to 1. However,
perfect detection cannot always be reached and some compromise between
detecting all target signals plus some noise (recall = 1 &amp; precision
&lt; 1) and detecting only target signals but not all of them (recall
&lt; 1 &amp; precision = 1) is warranted. The right balance between
these two extremes will be given by the relative costs of missing
signals and mistaking noise for signals. Hence, these indices provide an
useful framework for diagnosing and optimizing the performance of a
detection routine.</p>
<p>The package <a href="https://github.com/ropensci/ohun" class="external-link">ohun</a>
provides a set of tools to evaluate the performance of an sound event
detection based on the indices described above. To accomplish this, the
result of a detection routine is compared against a reference table
containing the time position of all target sound events in the sound
files. The package comes with an example reference table containing
annotations of long-billed hermit hummingbird songs from two sound files
(also supplied as example data: ‘lbh1’ and ‘lbh2’), which can be used to
illustrate detection performance evaluation. The example data can be
explored as follows:</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># load example data</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html" class="external-link">data</a></span><span class="op">(</span><span class="st">"lbh1"</span>, <span class="st">"lbh2"</span>, <span class="st">"lbh_reference"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">lbh_reference</span></span></code></pre></div>
<pre><code> [30mObject of class  [1m'selection_table' [22m [39m</code></pre>
<pre><code> [90m* The output of the following call: [39m</code></pre>
<pre><code> [90m [3mwarbleR::selection_table(X = lbh_reference) [23m [39m</code></pre>
<pre><code> [90m [1m
Contains: [22m 
*  A selection table data frame with 19 rows and 6 columns: [39m</code></pre>
<pre><code> [90m|sound.files | selec|  start|    end| bottom.freq| top.freq| [39m</code></pre>
<pre><code> [90m|:-----------|-----:|------:|------:|-----------:|--------:| [39m</code></pre>
<pre><code> [90m|lbh2.wav    |     1| 0.1092| 0.2482|      2.2954|   8.9382| [39m</code></pre>
<pre><code> [90m|lbh2.wav    |     2| 0.6549| 0.7887|      2.2954|   9.0426| [39m</code></pre>
<pre><code> [90m|lbh2.wav    |     3| 1.2658| 1.3856|      2.2606|   9.0774| [39m</code></pre>
<pre><code> [90m|lbh2.wav    |     4| 1.8697| 2.0053|      2.1911|   8.9035| [39m</code></pre>
<pre><code> [90m|lbh2.wav    |     5| 2.4418| 2.5809|      2.1563|   8.6600| [39m</code></pre>
<pre><code> [90m|lbh2.wav    |     6| 3.0368| 3.1689|      2.2259|   8.9382| [39m</code></pre>
<pre><code> [90m... and 13 more row(s) [39m</code></pre>
<pre><code> [90m
* A data frame (check.results) with 19 rows generated by check_sels() (as an attribute) [39m</code></pre>
<pre><code> [90mcreated by warbleR 1.1.27 [39m</code></pre>
<p>This is a ‘selection table’, an object class provided by the package
<a href="https://CRAN.R-project.org/package=warbleR" class="external-link">warbleR</a> (see <a href="https://marce10.github.io/warbleR/reference/selection_table.html" class="external-link"><code>selection_table()</code></a>
for details). Selection tables are basically data frames in which the
contained information has been double-checked (using warbleR’s <a href="https://marce10.github.io/warbleR/reference/check_sels.html" class="external-link"><code>check_sels()</code></a>).
But they behave pretty much as data frames and can be easily converted
to data frames:</p>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># convert to data frame</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html" class="external-link">as.data.frame</a></span><span class="op">(</span><span class="va">lbh_reference</span><span class="op">)</span></span></code></pre></div>
<pre><code>   sound.files selec    start       end bottom.freq top.freq
1     lbh2.wav     1 0.109161 0.2482449      2.2954   8.9382
2     lbh2.wav     2 0.654921 0.7887232      2.2954   9.0426
3     lbh2.wav     3 1.265850 1.3855678      2.2606   9.0774
4     lbh2.wav     4 1.869705 2.0052678      2.1911   8.9035
5     lbh2.wav     5 2.441769 2.5808529      2.1563   8.6600
6     lbh2.wav     6 3.036825 3.1688667      2.2259   8.9382
7     lbh2.wav     7 3.628617 3.7465742      2.3302   8.6252
8     lbh2.wav     8 4.153288 4.2818085      2.2954   8.4861
9     lbh2.wav     9 4.723673 4.8609963      2.3650   8.6948
10    lbh1.wav    10 0.088118 0.2360047      1.9824   8.4861
11    lbh1.wav    11 0.572290 0.7201767      2.0520   9.5295
12    lbh1.wav    12 1.056417 1.1972614      2.0868   8.4861
13    lbh1.wav    13 1.711338 1.8680274      1.9824   8.5905
14    lbh1.wav    14 2.190249 2.3416568      2.0520   8.5209
15    lbh1.wav    15 2.697143 2.8538324      1.9824   9.2513
16    lbh1.wav    16 3.181315 3.3344833      1.9129   8.4861
17    lbh1.wav    17 3.663719 3.8133662      1.8781   8.6948
18    lbh1.wav    18 4.140816 4.3045477      1.8433   9.2165
19    lbh1.wav    19 4.626712 4.7851620      1.8085   8.9035</code></pre>
<p>All <a href="https://github.com/ropensci/ohun" class="external-link">ohun</a> functions
that work with this kind of data can take both selection tables and data
frames. Spectrograms with highlighted sound events from a selection
table can be plotted with the function <code><a href="../reference/label_spectro.html">label_spectro()</a></code>
(this function only plots one wave object at the time, not really useful
for long files):</p>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># save sound file</span></span>
<span><span class="fu">tuneR</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/tuneR/man/writeWave.html" class="external-link">writeWave</a></span><span class="op">(</span><span class="va">lbh1</span>, <span class="fu"><a href="https://rdrr.io/r/base/file.path.html" class="external-link">file.path</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/tempfile.html" class="external-link">tempdir</a></span><span class="op">(</span><span class="op">)</span>, <span class="st">"lbh1.wav"</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># save sound file</span></span>
<span><span class="fu">tuneR</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/tuneR/man/writeWave.html" class="external-link">writeWave</a></span><span class="op">(</span><span class="va">lbh2</span>, <span class="fu"><a href="https://rdrr.io/r/base/file.path.html" class="external-link">file.path</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/tempfile.html" class="external-link">tempdir</a></span><span class="op">(</span><span class="op">)</span>, <span class="st">"lbh2.wav"</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># print spectrogram</span></span>
<span><span class="fu"><a href="../reference/label_spectro.html">label_spectro</a></span><span class="op">(</span>wave <span class="op">=</span> <span class="va">lbh1</span>, reference <span class="op">=</span> <span class="va">lbh_reference</span><span class="op">[</span><span class="va">lbh_reference</span><span class="op">$</span><span class="va">sound.files</span> <span class="op">==</span> <span class="st">"lbh1.wav"</span>, <span class="op">]</span>, hop.size <span class="op">=</span> <span class="fl">10</span>, ovlp <span class="op">=</span> <span class="fl">50</span>, flim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">10</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p><img src="intro_to_ohun_files/figure-html/unnamed-chunk-5-1.png" width="100%" style="display: block; margin: auto;"></p>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># print spectrogram</span></span>
<span><span class="fu"><a href="../reference/label_spectro.html">label_spectro</a></span><span class="op">(</span>wave <span class="op">=</span> <span class="va">lbh2</span>, reference <span class="op">=</span> <span class="va">lbh_reference</span><span class="op">[</span><span class="va">lbh_reference</span><span class="op">$</span><span class="va">sound.files</span> <span class="op">==</span> <span class="st">"lbh2.wav"</span>, <span class="op">]</span>, hop.size <span class="op">=</span> <span class="fl">10</span>, ovlp <span class="op">=</span> <span class="fl">50</span>, flim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">10</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p><img src="intro_to_ohun_files/figure-html/unnamed-chunk-5-2.png" width="100%" style="display: block; margin: auto;"></p>
<p>The function <code><a href="../reference/diagnose_detection.html">diagnose_detection()</a></code> evaluates the
performance of a detection routine by comparing it to a reference table.
For instance, a perfect detection is given by comparing
<code>lbh_reference</code> to itself:</p>
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">lbh1_reference</span> <span class="op">&lt;-</span></span>
<span>  <span class="va">lbh_reference</span><span class="op">[</span><span class="va">lbh_reference</span><span class="op">$</span><span class="va">sound.files</span> <span class="op">==</span> <span class="st">"lbh1.wav"</span>,<span class="op">]</span></span>
<span></span>
<span><span class="co"># diagnose</span></span>
<span><span class="fu"><a href="../reference/diagnose_detection.html">diagnose_detection</a></span><span class="op">(</span>reference <span class="op">=</span> <span class="va">lbh1_reference</span>, detection <span class="op">=</span> <span class="va">lbh1_reference</span><span class="op">)</span><span class="op">[</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">3</span>, <span class="fl">7</span><span class="op">:</span><span class="fl">9</span><span class="op">)</span><span class="op">]</span></span></code></pre></div>
<pre><code> [30mlabeling detections (step 0 of 0): [39m</code></pre>
<pre><code>  detections true.positives false.positives overlap recall precision
1         10             10               0       1      1         1</code></pre>
<p>We will work mostly with a single sound file for convenience but the
functions can work on several sound files at the time. The files should
be found in a single working directory. Although the above example is a
bit silly, it shows the basic diagnostic indices, which include basic
detection theory indices (‘true.positives’, ‘false.positives’,
‘false.negatives’, ‘recall’ and ‘precision’) mentioned above. We can
play around with the reference table to see how these indices can be
used to spot imperfect detection routines (and hopefully improve them!).
For instance, we can remove some sound events to see how this is
reflected in the diagnostics. Getting rid of some rows in ‘detection’,
simulating a detection with some false negatives, will affect the recall
but not the precision:</p>
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># create new table</span></span>
<span><span class="va">lbh1_detection</span> <span class="op">&lt;-</span> <span class="va">lbh1_reference</span><span class="op">[</span><span class="fl">3</span><span class="op">:</span><span class="fl">9</span>,<span class="op">]</span></span>
<span></span>
<span><span class="co"># print spectrogram</span></span>
<span><span class="fu"><a href="../reference/label_spectro.html">label_spectro</a></span><span class="op">(</span></span>
<span>  wave <span class="op">=</span> <span class="va">lbh1</span>,</span>
<span>  reference <span class="op">=</span> <span class="va">lbh1_reference</span>,</span>
<span>  detection <span class="op">=</span> <span class="va">lbh1_detection</span>,</span>
<span>  hop.size <span class="op">=</span> <span class="fl">10</span>,</span>
<span>  ovlp <span class="op">=</span> <span class="fl">50</span>,</span>
<span>  flim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">10</span><span class="op">)</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p><img src="intro_to_ohun_files/figure-html/unnamed-chunk-7-1.png" width="100%" style="display: block; margin: auto;"></p>
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># diagnose</span></span>
<span><span class="fu"><a href="../reference/diagnose_detection.html">diagnose_detection</a></span><span class="op">(</span>reference <span class="op">=</span> <span class="va">lbh1_reference</span>, detection <span class="op">=</span> <span class="va">lbh1_detection</span><span class="op">)</span><span class="op">[</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">3</span>, <span class="fl">7</span><span class="op">:</span><span class="fl">9</span><span class="op">)</span><span class="op">]</span></span></code></pre></div>
<pre><code>  detections true.positives false.positives overlap recall precision
1          7              7               0       1    0.7         1</code></pre>
<p>Having some additional sound events not in reference will do the
opposite, reducing precision but not recall. We can do this simply by
switching the tables:</p>
<div class="sourceCode" id="cb29"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># print spectrogram</span></span>
<span><span class="fu"><a href="../reference/label_spectro.html">label_spectro</a></span><span class="op">(</span></span>
<span>  wave <span class="op">=</span> <span class="va">lbh1</span>,</span>
<span>  detection <span class="op">=</span> <span class="va">lbh1_reference</span>,</span>
<span>  reference <span class="op">=</span> <span class="va">lbh1_detection</span>,</span>
<span>  hop.size <span class="op">=</span> <span class="fl">10</span>,</span>
<span>  ovlp <span class="op">=</span> <span class="fl">50</span>,</span>
<span>  flim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">10</span><span class="op">)</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p><img src="intro_to_ohun_files/figure-html/unnamed-chunk-8-1.png" width="100%" style="display: block; margin: auto;"></p>
<div class="sourceCode" id="cb30"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># diagnose</span></span>
<span><span class="fu"><a href="../reference/diagnose_detection.html">diagnose_detection</a></span><span class="op">(</span>reference <span class="op">=</span> <span class="va">lbh1_detection</span>, detection <span class="op">=</span> <span class="va">lbh1_reference</span><span class="op">)</span><span class="op">[</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">3</span>, <span class="fl">7</span><span class="op">:</span><span class="fl">9</span><span class="op">)</span><span class="op">]</span></span></code></pre></div>
<pre><code>  detections true.positives false.positives overlap recall precision
1         10              7               3       1      1       0.7</code></pre>
<p>The function offers three additional diagnose metrics:</p>
<ul>
<li>
<strong>Splits</strong>: detections that share overlapping reference
sounds with other detections<br>
</li>
<li>
<strong>Merges</strong>: detections that overlap with two or more
reference sounds</li>
<li>
<strong>Proportional overlap of true positives</strong>: ratio of
the time overlap of true positives with its corresponding sound event in
the reference table</li>
</ul>
<p>In a perfect detection routine split and merged positives should be 0
while proportional overlap should be 1. We can shift the start of sound
events a bit to reflect a detection in which there is some mismatch to
the reference table regarding to the time location of sound events:</p>
<div class="sourceCode" id="cb32"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># create new table</span></span>
<span><span class="va">lbh1_detection</span> <span class="op">&lt;-</span> <span class="va">lbh1_reference</span></span>
<span></span>
<span><span class="co"># add 'noise' to start</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">18</span><span class="op">)</span></span>
<span><span class="va">lbh1_detection</span><span class="op">$</span><span class="va">start</span> <span class="op">&lt;-</span></span>
<span>  <span class="va">lbh1_detection</span><span class="op">$</span><span class="va">start</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">lbh1_detection</span><span class="op">)</span>, mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">0.1</span><span class="op">)</span></span>
<span></span>
<span><span class="co">## print spectrogram</span></span>
<span><span class="fu"><a href="../reference/label_spectro.html">label_spectro</a></span><span class="op">(</span></span>
<span>  wave <span class="op">=</span> <span class="va">lbh1</span>,</span>
<span>  reference <span class="op">=</span> <span class="va">lbh1_reference</span>,</span>
<span>  detection <span class="op">=</span> <span class="va">lbh1_detection</span>,</span>
<span>  hop.size <span class="op">=</span> <span class="fl">10</span>,</span>
<span>  ovlp <span class="op">=</span> <span class="fl">50</span>,</span>
<span>  flim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">10</span><span class="op">)</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p><img src="intro_to_ohun_files/figure-html/unnamed-chunk-9-1.png" width="100%" style="display: block; margin: auto;"></p>
<div class="sourceCode" id="cb33"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># diagnose</span></span>
<span><span class="fu"><a href="../reference/diagnose_detection.html">diagnose_detection</a></span><span class="op">(</span>reference <span class="op">=</span> <span class="va">lbh1_reference</span>, detection <span class="op">=</span> <span class="va">lbh1_detection</span><span class="op">)</span></span></code></pre></div>
<pre><code>  detections true.positives false.positives false.negatives splits merges   overlap
1         10              5               5               5      0      0 0.7849767
  recall precision f.score
1    0.5       0.5     0.5</code></pre>
<p>In addition, the following diagnostics related to the duration of the
sound events can also be returned by setting
<code>time.diagnostics = TRUE</code>. Here we tweak the reference and
detection data just to have some false positives and false
negatives:</p>
<div class="sourceCode" id="cb35"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># diagnose with time diagnostics</span></span>
<span><span class="fu"><a href="../reference/diagnose_detection.html">diagnose_detection</a></span><span class="op">(</span>reference <span class="op">=</span> <span class="va">lbh1_reference</span><span class="op">[</span><span class="op">-</span><span class="fl">1</span>, <span class="op">]</span>, detection <span class="op">=</span> <span class="va">lbh1_detection</span><span class="op">[</span><span class="op">-</span><span class="fl">10</span>, <span class="op">]</span>, time.diagnostics <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<pre><code>  detections true.positives false.positives false.negatives splits merges
1          9              5               4               4      0      0
  mean.duration.true.positives mean.duration.false.positives
1                          187                            58
  mean.duration.false.negatives   overlap proportional.duration.true.positives    recall
1                           149 0.7849767                             1.194993 0.5555556
  precision   f.score
1 0.5555556 0.5555556</code></pre>
<p>These additional metrics can be used to further filter out undesired
sound events based on their duration (for instance in a energy-based
detection as in <code><a href="../reference/energy_detector.html">energy_detector()</a></code>, explained below).</p>
<p>Diagnostics can also be detailed by sound file:</p>
<div class="sourceCode" id="cb37"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># diagnose by sound file</span></span>
<span><span class="va">diagnostic</span> <span class="op">&lt;-</span></span>
<span>  <span class="fu"><a href="../reference/diagnose_detection.html">diagnose_detection</a></span><span class="op">(</span>reference <span class="op">=</span> <span class="va">lbh1_reference</span>,</span>
<span>                     detection <span class="op">=</span> <span class="va">lbh1_detection</span>,</span>
<span>                     by.sound.file <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span></span>
<span><span class="va">diagnostic</span></span></code></pre></div>
<pre><code>  sound.files detections true.positives false.positives false.negatives splits merges
1    lbh1.wav         10              5               5               5      0      0
    overlap recall precision f.score
1 0.7849767    0.5       0.5     0.5</code></pre>
<p>These diagnostics can be summarized (as in the default
<code><a href="../reference/diagnose_detection.html">diagnose_detection()</a></code> output) with the function
<code><a href="../reference/summarize_diagnostic.html">summarize_diagnostic()</a></code>:</p>
<div class="sourceCode" id="cb39"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># summarize</span></span>
<span><span class="fu"><a href="../reference/summarize_diagnostic.html">summarize_diagnostic</a></span><span class="op">(</span><span class="va">diagnostic</span><span class="op">)</span></span></code></pre></div>
<pre><code>  detections true.positives false.positives false.negatives splits merges   overlap
1         10              5               5               5      0      0 0.7849767
  recall precision f.score
1    0.5       0.5     0.5</code></pre>
<p>The match between reference and detection annotations can also be
visually inspected using the function <code><a href="../reference/plot_detection.html">plot_detection()</a></code>:</p>
<div class="sourceCode" id="cb41"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># ggplot detection and reference</span></span>
<span><span class="fu"><a href="../reference/plot_detection.html">plot_detection</a></span><span class="op">(</span>reference <span class="op">=</span> <span class="va">lbh1_reference</span>, detection <span class="op">=</span> <span class="va">lbh1_detection</span><span class="op">)</span></span></code></pre></div>
<p><img src="intro_to_ohun_files/figure-html/unnamed-chunk-13-1.png" width="100%" style="display: block; margin: auto;"></p>
<p>This function is more flexible than <code><a href="../reference/label_spectro.html">label_spectro()</a></code> as
it can easily plot annotations from several sound files (include those
from long sound files):</p>
<div class="sourceCode" id="cb42"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># ggplot detection and reference</span></span>
<span><span class="fu"><a href="../reference/plot_detection.html">plot_detection</a></span><span class="op">(</span>reference <span class="op">=</span> <span class="va">lbh_reference</span>, detection <span class="op">=</span> <span class="va">lbh_reference</span><span class="op">)</span></span></code></pre></div>
<p><img src="intro_to_ohun_files/figure-html/unnamed-chunk-14-1.png" width="100%" style="display: block; margin: auto;"></p>
<hr>
</div>
<div class="section level2">
<h2 id="improving-detection-speed">Improving detection speed<a class="anchor" aria-label="anchor" href="#improving-detection-speed"></a>
</h2>
<p>Detection routines can take a long time when working with large
amounts of acoustic data (e.g. large sound files and/or many sound
files). These are some useful points to keep in mine when trying to make
a routine more time-efficient:</p>
<ul>
<li>Always test procedures on small data subsets</li>
<li>
<code><a href="../reference/template_detector.html">template_detector()</a></code> is faster than
<code><a href="../reference/energy_detector.html">energy_detector()</a></code>
</li>
<li>Parallelization (see <code>parallel</code> argument in most
functions) can significantly speed-up routines, but works better on
Unix-based operating systems (linux and mac OS)</li>
<li>Sampling rate matters: detecting sound events on low sampling rate
files goes faster, so we should avoid having nyquist frequencies
(sampling rate / 2) way higher than the highest frequency of the target
sound events (sound files can be downsampled using warbleR’s <a href="https://marce10.github.io/warbleR/reference/selection_table.html" class="external-link"><code>fix_sound_files()</code></a>)</li>
<li>Large sound files can make the routine crash, use
<code><a href="../reference/split_acoustic_data.html">split_acoustic_data()</a></code> to split both reference tables and
files into shorter clips.</li>
<li>Think about using a computer with lots of RAM memory or a computer
cluster for working on large amounts of data</li>
<li>
<code>thinning</code> argument (which reduces the size of the
amplitude envelope) can also speed-up
<code><a href="../reference/energy_detector.html">energy_detector()</a></code>
</li>
</ul>
</div>
<div class="section level2">
<h2 id="additional-tips">Additional tips<a class="anchor" aria-label="anchor" href="#additional-tips"></a>
</h2>
<ul>
<li>Use your knowledge about the sound event structure to determine the
initial range for the tuning parameters in a detection optimization
routine</li>
<li>If people have a hard time figuring out where a target sound event
occurs in a recording, detection algorithms will also have a hard
time</li>
<li>Several templates representing the range of variation in sound event
structure can be used to detect semi-stereotyped sound events</li>
<li>Make sure reference tables contain all target sound events and only
the target sound events. The performance of the detection cannot be
better than the reference itself.</li>
<li>Avoid having overlapping sound events or several sound events as a
single one (like a multi-syllable vocalization) in the reference table
when running an energy-based detector</li>
<li>Low-precision can be improved by training a classification model
(e.g. random forest) to tell sound events from noise</li>
</ul>
<hr>
<div class="alert alert-info">
<p>Please cite <a href="https://github.com/ropensci/ohun" class="external-link">ohun</a> like
this:</p>
<p>Araya-Salas, M. (2021), <em>ohun: diagnosing and optimizing automated
sound event detection</em>. R package version 0.1.0.</p>
</div>
<div class="section level3">
<h3 id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h3>
<ol style="list-style-type: decimal">
<li>Araya-Salas, M. (2021), ohun: diagnosing and optimizing automated
sound event detection. R package version 0.1.0.</li>
<li>Araya-Salas M, Smith-Vidaurre G (2017) warbleR: An R package to
streamline analysis of animal acoustic signals. Methods in Ecology and
Evolution, 8:184-191.</li>
<li>Khanna H., Gaunt S.L.L. &amp; McCallum D.A. (1997). Digital
spectrographic cross-correlation: tests of sensitivity. Bioacoustics
7(3): 209-234.</li>
<li>Knight, E.C., Hannah, K.C., Foley, G.J., Scott, C.D., Brigham, R.M.
&amp; Bayne, E. (2017). Recommendations for acoustic recognizer
performance assessment with application to five common automated signal
recognition programs. Avian Conservation and Ecology,</li>
<li>Macmillan, N. A., &amp; Creelman, C.D. (2004). Detection theory: A
user’s guide. Psychology press.</li>
</ol>
<hr>
<p><font size="4">Session information</font></p>
<pre><code>R version 4.5.1 (2025-06-13)
Platform: aarch64-apple-darwin20
Running under: macOS Sonoma 14.7.6

Matrix products: default
BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib 
LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

time zone: UTC
tzcode source: internal

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] ggplot2_3.5.2      warbleR_1.1.35     NatureSounds_1.0.5 knitr_1.50        
[5] seewave_2.2.3      tuneR_1.4.7        ohun_1.0.3        

loaded via a namespace (and not attached):
 [1] gtable_0.3.6       rjson_0.2.23       xfun_0.52          bslib_0.9.0       
 [5] vctrs_0.6.5        tools_4.5.1        bitops_1.0-9       curl_6.4.0        
 [9] parallel_4.5.1     tibble_3.3.0       proxy_0.4-27       pkgconfig_2.0.3   
[13] KernSmooth_2.23-26 checkmate_2.3.2    RColorBrewer_1.1-3 desc_1.4.3        
[17] lifecycle_1.0.4    compiler_4.5.1     farver_2.1.2       textshaping_1.0.1 
[21] brio_1.1.5         htmltools_0.5.8.1  class_7.3-23       sass_0.4.10       
[25] RCurl_1.98-1.17    yaml_2.3.10        pkgdown_2.1.3      pillar_1.11.0     
[29] jquerylib_0.1.4    MASS_7.3-65        classInt_0.4-11    cachem_1.1.0      
[33] viridis_0.6.5      digest_0.6.37      sf_1.0-21          labeling_0.4.3    
[37] fastmap_1.2.0      grid_4.5.1         cli_3.6.5          magrittr_2.0.3    
[41] e1071_1.7-16       withr_3.0.2        scales_1.4.0       backports_1.5.0   
[45] rmarkdown_2.29     httr_1.4.7         signal_1.8-1       igraph_2.1.4      
[49] gridExtra_2.3      ragg_1.4.0         pbapply_1.7-4      evaluate_1.0.4    
[53] dtw_1.23-1         fftw_1.0-9         testthat_3.2.3     viridisLite_0.4.2 
[57] rlang_1.1.6        Rcpp_1.1.0         glue_1.8.0         DBI_1.2.3         
[61] jsonlite_2.0.0     R6_2.6.1           systemfonts_1.2.3  fs_1.6.6          
[65] units_0.8-7       </code></pre>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Marcelo Araya-Salas.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.3.</p>
</div>

    </footer>
</div>





  </body>
</html>
